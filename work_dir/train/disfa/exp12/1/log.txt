[11.27.22|22:02:26] Parameters:
{'work_dir': './work_dir/train/disfa/exp12/1', 'config': './config/exp12/train1.yaml', 'phase': 'train', 'save_result': False, 'start_epoch': 0, 'num_epoch': 20, 'use_gpu': True, 'device': [0], 'log_interval': 1000, 'save_interval': 5, 'eval_interval': 1, 'save_log': True, 'print_log': True, 'pavi_log': False, 'feeder': 'feeder.feeder_image_causal.Feeder', 'num_worker': 0, 'train_feeder_args': {'label_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/train1_label.pkl', 'image_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/train1_imagepath.pkl', 'image_size': 256, 'istrain': True, 'debug': False}, 'test_feeder_args': {'label_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/test1_label.pkl', 'image_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/test1_imagepath.pkl', 'image_size': 256, 'istrain': False, 'debug': False}, 'batch_size': 4, 'test_batch_size': 4, 'debug': False, 'model': 'net.causal_net.CAUSAL_NET', 'model_args': {'num_class': 8, 'backbone': 'resnet34', 'temporal_model': 'single', 'subject': True, 'pooling': True, 'd_in': 512, 'd_m': 256, 'd_out': 512}, 'weights': None, 'ignore_weights': [], 'seed': 42, 'base_lr': 0.001, 'step': [], 'optimizer': 'SGD', 'nesterov': True, 'weight_decay': 0.0005, 'lr_decay': 0.3, 'loss': 'clf', 'loss_weight': [0.05796583600359621, 0.0502662578667097, 0.14906982641370248, 0.0780216233661449, 0.04824915281587865, 0.12274372392171327, 0.2655778141497038, 0.08540999100947463], 'resume': '', 'pretrain': True, 'clf_only_epoch': 1, 'branch_loss_weight': 0.33, 'loss_class_weight': [0.06761407943209014, 0.058632929091935786, 0.1738820619000242, 0.0910080937911748, 0.056280082820188766, 0.14317405684476592, 0.3097824625561322, 0.09962623356368819], 'loss_inner_weight': [[0.0, 0.0, 0.001454873827321527, 0.0, 0.0, 0.024212212925048958, 0.0068695340304025165, 0.016127633746640075], [0.0233630494927759, 0.029411764705882353, 0.0005016806301108714, 0.0031955069235983344, 0.00694317558925635, 0.016200818942495993, 0.0295472728777554, 0.1456689499696523], [0.07623731939747926, 0.0031892274982282067, 0.08789444639542467, 0.13527645976566283, 0.2077471222364334, 0.03732716159278381, 0.0490247468756035, 0.07031995144368335], [0.16692284045496464, 0.2067682494684621, 0.07755982541514073, 0.04812627094025371, 0.07929837383519094, 0.0453978992344668, 0.02311915468866389, 0.006156247290384115], [0.003996311097448509, 0.0007087172218284905, 0.012291175437716349, 0.01423453084148349, 0.0, 0.008308112278203075, 0.020443071150715923, 0.04196653082459031], [0.0, 0.0, 0.016003612100536798, 0.08337368064297472, 0.019550520738169194, 0.06005578303958222, 0.04361740281954369, 0.007283447498482615], [0.013679680295112203, 0.011162296243798725, 0.0025585712135654443, 0.04638326716374552, 0.057007125890736345, 0.041777936027535455, 0.011697519794741634, 0.008844186248157462], [0.030126037503842608, 0.03756201275690999, 0.031304871318918376, 0.053936283528614314, 0.06395030147999269, 0.01275888671295472, 0.007476480812205148, 0.004422093124078731], [0.0, 0.0, 0.0012542015752771785, 0.0, 0.0, 0.026229897335469706, 0.009628383038596297, 0.0016474464579901153], [0.001537042729787888, 0.00815024805102764, 0.004615461797020017, 0.014137697298344146, 0.0, 0.02492433683460922, 0.012773470907937208, 0.0], [0.05395019981555487, 0.019312544294826366, 0.16324687703807755, 0.045318098189212744, 0.004750593824228029, 0.032223606907601926, 0.03832041272381163, 0.009191017081418538], [0.03796495542576084, 0.0024805102763997165, 0.02137159484272312, 0.0, 0.05024666544856569, 0.04017565723102486, 0.07440615775098629, 0.03251539061822596], [0.0, 0.0, 0.012241007374705263, 0.08434201607436816, 0.022656678238625983, 0.058690878879591714, 0.03241647584627693, 0.008410647706581115], [0.0756225023055641, 0.09886605244507442, 0.14734360106356292, 0.016268035247409704, 0.0, 0.019820782149427334, 0.03716169614037024, 0.038324807075349], [0.006762988011066708, 0.00815024805102764, 0.007976722018762856, 0.08627868693715503, 0.030330714416225105, 0.07542579075425791, 0.025850415206775734, 0.01777508020463019], [0.07808177067322472, 0.08203401842664777, 0.061656549440626096, 0.017526871308221167, 0.07929837383519094, 0.05156963978398908, 0.030926697381852292, 0.028353420619093038], [0.011220411927451584, 0.0007087172218284905, 0.03983344203080319, 0.018785707369032633, 0.005846884706742189, 0.014657883805115424, 0.03128534775291748, 0.003901846874187115], [0.03888718106363357, 0.03206945428773919, 0.07424873325640897, 0.001452503147090152, 0.06267129545039284, 0.03815797282060412, 0.07184042817336607, 0.02809329749414723], [0.041039040885336615, 0.041814316087880936, 0.0029599157176541414, 0.012685194151253994, 0.014799926913941166, 0.019939469467687376, 0.02273291582751676, 0.0025145235411428075], [0.0, 0.0, 0.002909747654643054, 0.019850876343565412, 0.0051160241183994155, 0.06925405020473563, 0.11631307418544982, 0.0371976068672505], [0.0003074085459575776, 0.0, 0.0021572267094767473, 0.059068461314999515, 0.061392289420792986, 0.02694202124502997, 0.018898115706127403, 0.005029047082285615], [0.04226867506916692, 0.0, 0.025334871820599007, 0.002420838578483587, 0.008953042207198976, 0.046347397780547146, 0.057025408999365465, 0.009624555622994885], [0.0, 0.00407512402551382, 0.007274369136607636, 0.04570543236177012, 0.02101224191485474, 0.021304373627677883, 0.04072061136094022, 0.13743171767970172], [0.15493390716261912, 0.34532246633593194, 0.11267746952290172, 0.021400213033794906, 0.036177599122967294, 0.03720847427452377, 0.010566391701382183, 0.002687938957773346], [0.005840762373193975, 0.03065201984408221, 0.02031806551949029, 0.09654304250992544, 0.030878859857482184, 0.046466085098807196, 0.04281733660716749, 0.021937050203763114], [0.003535198278512143, 0.005315379163713678, 0.009180755531028947, 0.03679674639295052, 0.016992508678969488, 0.06854192629517536, 0.04990757855822551, 0.12789386976502212], [0.13372271749154627, 0.032246633593196315, 0.0538303316108965, 0.03689357993608986, 0.11437968207564407, 0.03608094475105335, 0.08461389908130328, 0.18668169600277465]]}

[11.27.22|22:02:26] Training epoch: 0
[11.27.22|22:04:51] Parameters:
{'work_dir': './work_dir/train/disfa/exp12/1', 'config': './config/exp12/train1.yaml', 'phase': 'train', 'save_result': False, 'start_epoch': 0, 'num_epoch': 20, 'use_gpu': True, 'device': [0], 'log_interval': 1000, 'save_interval': 5, 'eval_interval': 1, 'save_log': True, 'print_log': True, 'pavi_log': False, 'feeder': 'feeder.feeder_image_causal.Feeder', 'num_worker': 0, 'train_feeder_args': {'label_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/train1_label.pkl', 'image_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/train1_imagepath.pkl', 'image_size': 256, 'istrain': True, 'debug': False}, 'test_feeder_args': {'label_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/test1_label.pkl', 'image_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/test1_imagepath.pkl', 'image_size': 256, 'istrain': False, 'debug': False}, 'batch_size': 4, 'test_batch_size': 4, 'debug': False, 'model': 'net.causal_net.CAUSAL_NET', 'model_args': {'num_class': 8, 'backbone': 'resnet34', 'temporal_model': 'single', 'subject': True, 'pooling': True, 'd_in': 512, 'd_m': 256, 'd_out': 512}, 'weights': None, 'ignore_weights': [], 'seed': 42, 'base_lr': 0.001, 'step': [], 'optimizer': 'SGD', 'nesterov': True, 'weight_decay': 0.0005, 'lr_decay': 0.3, 'loss': 'clf', 'loss_weight': [0.05796583600359621, 0.0502662578667097, 0.14906982641370248, 0.0780216233661449, 0.04824915281587865, 0.12274372392171327, 0.2655778141497038, 0.08540999100947463], 'resume': '', 'pretrain': True, 'clf_only_epoch': 1, 'branch_loss_weight': 0.33, 'loss_class_weight': [0.06761407943209014, 0.058632929091935786, 0.1738820619000242, 0.0910080937911748, 0.056280082820188766, 0.14317405684476592, 0.3097824625561322, 0.09962623356368819], 'loss_inner_weight': [[0.0, 0.0, 0.001454873827321527, 0.0, 0.0, 0.024212212925048958, 0.0068695340304025165, 0.016127633746640075], [0.0233630494927759, 0.029411764705882353, 0.0005016806301108714, 0.0031955069235983344, 0.00694317558925635, 0.016200818942495993, 0.0295472728777554, 0.1456689499696523], [0.07623731939747926, 0.0031892274982282067, 0.08789444639542467, 0.13527645976566283, 0.2077471222364334, 0.03732716159278381, 0.0490247468756035, 0.07031995144368335], [0.16692284045496464, 0.2067682494684621, 0.07755982541514073, 0.04812627094025371, 0.07929837383519094, 0.0453978992344668, 0.02311915468866389, 0.006156247290384115], [0.003996311097448509, 0.0007087172218284905, 0.012291175437716349, 0.01423453084148349, 0.0, 0.008308112278203075, 0.020443071150715923, 0.04196653082459031], [0.0, 0.0, 0.016003612100536798, 0.08337368064297472, 0.019550520738169194, 0.06005578303958222, 0.04361740281954369, 0.007283447498482615], [0.013679680295112203, 0.011162296243798725, 0.0025585712135654443, 0.04638326716374552, 0.057007125890736345, 0.041777936027535455, 0.011697519794741634, 0.008844186248157462], [0.030126037503842608, 0.03756201275690999, 0.031304871318918376, 0.053936283528614314, 0.06395030147999269, 0.01275888671295472, 0.007476480812205148, 0.004422093124078731], [0.0, 0.0, 0.0012542015752771785, 0.0, 0.0, 0.026229897335469706, 0.009628383038596297, 0.0016474464579901153], [0.001537042729787888, 0.00815024805102764, 0.004615461797020017, 0.014137697298344146, 0.0, 0.02492433683460922, 0.012773470907937208, 0.0], [0.05395019981555487, 0.019312544294826366, 0.16324687703807755, 0.045318098189212744, 0.004750593824228029, 0.032223606907601926, 0.03832041272381163, 0.009191017081418538], [0.03796495542576084, 0.0024805102763997165, 0.02137159484272312, 0.0, 0.05024666544856569, 0.04017565723102486, 0.07440615775098629, 0.03251539061822596], [0.0, 0.0, 0.012241007374705263, 0.08434201607436816, 0.022656678238625983, 0.058690878879591714, 0.03241647584627693, 0.008410647706581115], [0.0756225023055641, 0.09886605244507442, 0.14734360106356292, 0.016268035247409704, 0.0, 0.019820782149427334, 0.03716169614037024, 0.038324807075349], [0.006762988011066708, 0.00815024805102764, 0.007976722018762856, 0.08627868693715503, 0.030330714416225105, 0.07542579075425791, 0.025850415206775734, 0.01777508020463019], [0.07808177067322472, 0.08203401842664777, 0.061656549440626096, 0.017526871308221167, 0.07929837383519094, 0.05156963978398908, 0.030926697381852292, 0.028353420619093038], [0.011220411927451584, 0.0007087172218284905, 0.03983344203080319, 0.018785707369032633, 0.005846884706742189, 0.014657883805115424, 0.03128534775291748, 0.003901846874187115], [0.03888718106363357, 0.03206945428773919, 0.07424873325640897, 0.001452503147090152, 0.06267129545039284, 0.03815797282060412, 0.07184042817336607, 0.02809329749414723], [0.041039040885336615, 0.041814316087880936, 0.0029599157176541414, 0.012685194151253994, 0.014799926913941166, 0.019939469467687376, 0.02273291582751676, 0.0025145235411428075], [0.0, 0.0, 0.002909747654643054, 0.019850876343565412, 0.0051160241183994155, 0.06925405020473563, 0.11631307418544982, 0.0371976068672505], [0.0003074085459575776, 0.0, 0.0021572267094767473, 0.059068461314999515, 0.061392289420792986, 0.02694202124502997, 0.018898115706127403, 0.005029047082285615], [0.04226867506916692, 0.0, 0.025334871820599007, 0.002420838578483587, 0.008953042207198976, 0.046347397780547146, 0.057025408999365465, 0.009624555622994885], [0.0, 0.00407512402551382, 0.007274369136607636, 0.04570543236177012, 0.02101224191485474, 0.021304373627677883, 0.04072061136094022, 0.13743171767970172], [0.15493390716261912, 0.34532246633593194, 0.11267746952290172, 0.021400213033794906, 0.036177599122967294, 0.03720847427452377, 0.010566391701382183, 0.002687938957773346], [0.005840762373193975, 0.03065201984408221, 0.02031806551949029, 0.09654304250992544, 0.030878859857482184, 0.046466085098807196, 0.04281733660716749, 0.021937050203763114], [0.003535198278512143, 0.005315379163713678, 0.009180755531028947, 0.03679674639295052, 0.016992508678969488, 0.06854192629517536, 0.04990757855822551, 0.12789386976502212], [0.13372271749154627, 0.032246633593196315, 0.0538303316108965, 0.03689357993608986, 0.11437968207564407, 0.03608094475105335, 0.08461389908130328, 0.18668169600277465]]}

[11.27.22|22:04:51] Training epoch: 0
[11.27.22|22:06:58] Parameters:
{'work_dir': './work_dir/train/disfa/exp12/1', 'config': './config/exp12/train1.yaml', 'phase': 'train', 'save_result': False, 'start_epoch': 0, 'num_epoch': 20, 'use_gpu': True, 'device': [0], 'log_interval': 1000, 'save_interval': 5, 'eval_interval': 1, 'save_log': True, 'print_log': True, 'pavi_log': False, 'feeder': 'feeder.feeder_image_causal.Feeder', 'num_worker': 0, 'train_feeder_args': {'label_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/train1_label.pkl', 'image_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/train1_imagepath.pkl', 'image_size': 256, 'istrain': True, 'debug': False}, 'test_feeder_args': {'label_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/test1_label.pkl', 'image_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/test1_imagepath.pkl', 'image_size': 256, 'istrain': False, 'debug': False}, 'batch_size': 4, 'test_batch_size': 4, 'debug': False, 'model': 'net.causal_net.CAUSAL_NET', 'model_args': {'num_class': 8, 'backbone': 'resnet34', 'temporal_model': 'single', 'subject': True, 'pooling': True, 'd_in': 512, 'd_m': 256, 'd_out': 512}, 'weights': None, 'ignore_weights': [], 'seed': 42, 'base_lr': 0.001, 'step': [], 'optimizer': 'SGD', 'nesterov': True, 'weight_decay': 0.0005, 'lr_decay': 0.3, 'loss': 'clf', 'loss_weight': [0.05796583600359621, 0.0502662578667097, 0.14906982641370248, 0.0780216233661449, 0.04824915281587865, 0.12274372392171327, 0.2655778141497038, 0.08540999100947463], 'resume': '', 'pretrain': True, 'clf_only_epoch': 1, 'branch_loss_weight': 0.33, 'loss_class_weight': [0.06761407943209014, 0.058632929091935786, 0.1738820619000242, 0.0910080937911748, 0.056280082820188766, 0.14317405684476592, 0.3097824625561322, 0.09962623356368819], 'loss_inner_weight': [[0.0, 0.0, 0.001454873827321527, 0.0, 0.0, 0.024212212925048958, 0.0068695340304025165, 0.016127633746640075], [0.0233630494927759, 0.029411764705882353, 0.0005016806301108714, 0.0031955069235983344, 0.00694317558925635, 0.016200818942495993, 0.0295472728777554, 0.1456689499696523], [0.07623731939747926, 0.0031892274982282067, 0.08789444639542467, 0.13527645976566283, 0.2077471222364334, 0.03732716159278381, 0.0490247468756035, 0.07031995144368335], [0.16692284045496464, 0.2067682494684621, 0.07755982541514073, 0.04812627094025371, 0.07929837383519094, 0.0453978992344668, 0.02311915468866389, 0.006156247290384115], [0.003996311097448509, 0.0007087172218284905, 0.012291175437716349, 0.01423453084148349, 0.0, 0.008308112278203075, 0.020443071150715923, 0.04196653082459031], [0.0, 0.0, 0.016003612100536798, 0.08337368064297472, 0.019550520738169194, 0.06005578303958222, 0.04361740281954369, 0.007283447498482615], [0.013679680295112203, 0.011162296243798725, 0.0025585712135654443, 0.04638326716374552, 0.057007125890736345, 0.041777936027535455, 0.011697519794741634, 0.008844186248157462], [0.030126037503842608, 0.03756201275690999, 0.031304871318918376, 0.053936283528614314, 0.06395030147999269, 0.01275888671295472, 0.007476480812205148, 0.004422093124078731], [0.0, 0.0, 0.0012542015752771785, 0.0, 0.0, 0.026229897335469706, 0.009628383038596297, 0.0016474464579901153], [0.001537042729787888, 0.00815024805102764, 0.004615461797020017, 0.014137697298344146, 0.0, 0.02492433683460922, 0.012773470907937208, 0.0], [0.05395019981555487, 0.019312544294826366, 0.16324687703807755, 0.045318098189212744, 0.004750593824228029, 0.032223606907601926, 0.03832041272381163, 0.009191017081418538], [0.03796495542576084, 0.0024805102763997165, 0.02137159484272312, 0.0, 0.05024666544856569, 0.04017565723102486, 0.07440615775098629, 0.03251539061822596], [0.0, 0.0, 0.012241007374705263, 0.08434201607436816, 0.022656678238625983, 0.058690878879591714, 0.03241647584627693, 0.008410647706581115], [0.0756225023055641, 0.09886605244507442, 0.14734360106356292, 0.016268035247409704, 0.0, 0.019820782149427334, 0.03716169614037024, 0.038324807075349], [0.006762988011066708, 0.00815024805102764, 0.007976722018762856, 0.08627868693715503, 0.030330714416225105, 0.07542579075425791, 0.025850415206775734, 0.01777508020463019], [0.07808177067322472, 0.08203401842664777, 0.061656549440626096, 0.017526871308221167, 0.07929837383519094, 0.05156963978398908, 0.030926697381852292, 0.028353420619093038], [0.011220411927451584, 0.0007087172218284905, 0.03983344203080319, 0.018785707369032633, 0.005846884706742189, 0.014657883805115424, 0.03128534775291748, 0.003901846874187115], [0.03888718106363357, 0.03206945428773919, 0.07424873325640897, 0.001452503147090152, 0.06267129545039284, 0.03815797282060412, 0.07184042817336607, 0.02809329749414723], [0.041039040885336615, 0.041814316087880936, 0.0029599157176541414, 0.012685194151253994, 0.014799926913941166, 0.019939469467687376, 0.02273291582751676, 0.0025145235411428075], [0.0, 0.0, 0.002909747654643054, 0.019850876343565412, 0.0051160241183994155, 0.06925405020473563, 0.11631307418544982, 0.0371976068672505], [0.0003074085459575776, 0.0, 0.0021572267094767473, 0.059068461314999515, 0.061392289420792986, 0.02694202124502997, 0.018898115706127403, 0.005029047082285615], [0.04226867506916692, 0.0, 0.025334871820599007, 0.002420838578483587, 0.008953042207198976, 0.046347397780547146, 0.057025408999365465, 0.009624555622994885], [0.0, 0.00407512402551382, 0.007274369136607636, 0.04570543236177012, 0.02101224191485474, 0.021304373627677883, 0.04072061136094022, 0.13743171767970172], [0.15493390716261912, 0.34532246633593194, 0.11267746952290172, 0.021400213033794906, 0.036177599122967294, 0.03720847427452377, 0.010566391701382183, 0.002687938957773346], [0.005840762373193975, 0.03065201984408221, 0.02031806551949029, 0.09654304250992544, 0.030878859857482184, 0.046466085098807196, 0.04281733660716749, 0.021937050203763114], [0.003535198278512143, 0.005315379163713678, 0.009180755531028947, 0.03679674639295052, 0.016992508678969488, 0.06854192629517536, 0.04990757855822551, 0.12789386976502212], [0.13372271749154627, 0.032246633593196315, 0.0538303316108965, 0.03689357993608986, 0.11437968207564407, 0.03608094475105335, 0.08461389908130328, 0.18668169600277465]]}

[11.27.22|22:06:58] Training epoch: 0
[11.27.22|22:08:10] Parameters:
{'work_dir': './work_dir/train/disfa/exp12/1', 'config': './config/exp12/train1.yaml', 'phase': 'train', 'save_result': False, 'start_epoch': 0, 'num_epoch': 20, 'use_gpu': True, 'device': [0], 'log_interval': 1000, 'save_interval': 5, 'eval_interval': 1, 'save_log': True, 'print_log': True, 'pavi_log': False, 'feeder': 'feeder.feeder_image_causal.Feeder', 'num_worker': 0, 'train_feeder_args': {'label_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/train1_label.pkl', 'image_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/train1_imagepath.pkl', 'image_size': 256, 'istrain': True, 'debug': False}, 'test_feeder_args': {'label_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/test1_label.pkl', 'image_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/test1_imagepath.pkl', 'image_size': 256, 'istrain': False, 'debug': False}, 'batch_size': 4, 'test_batch_size': 4, 'debug': False, 'model': 'net.causal_net.CAUSAL_NET', 'model_args': {'num_class': 8, 'backbone': 'resnet34', 'temporal_model': 'single', 'subject': True, 'pooling': True, 'd_in': 512, 'd_m': 256, 'd_out': 512}, 'weights': None, 'ignore_weights': [], 'seed': 42, 'base_lr': 0.001, 'step': [], 'optimizer': 'SGD', 'nesterov': True, 'weight_decay': 0.0005, 'lr_decay': 0.3, 'loss': 'clf', 'loss_weight': [0.05796583600359621, 0.0502662578667097, 0.14906982641370248, 0.0780216233661449, 0.04824915281587865, 0.12274372392171327, 0.2655778141497038, 0.08540999100947463], 'resume': '', 'pretrain': True, 'clf_only_epoch': 1, 'branch_loss_weight': 0.33, 'loss_class_weight': [0.06761407943209014, 0.058632929091935786, 0.1738820619000242, 0.0910080937911748, 0.056280082820188766, 0.14317405684476592, 0.3097824625561322, 0.09962623356368819], 'loss_inner_weight': [[0.0, 0.0, 0.001454873827321527, 0.0, 0.0, 0.024212212925048958, 0.0068695340304025165, 0.016127633746640075], [0.0233630494927759, 0.029411764705882353, 0.0005016806301108714, 0.0031955069235983344, 0.00694317558925635, 0.016200818942495993, 0.0295472728777554, 0.1456689499696523], [0.07623731939747926, 0.0031892274982282067, 0.08789444639542467, 0.13527645976566283, 0.2077471222364334, 0.03732716159278381, 0.0490247468756035, 0.07031995144368335], [0.16692284045496464, 0.2067682494684621, 0.07755982541514073, 0.04812627094025371, 0.07929837383519094, 0.0453978992344668, 0.02311915468866389, 0.006156247290384115], [0.003996311097448509, 0.0007087172218284905, 0.012291175437716349, 0.01423453084148349, 0.0, 0.008308112278203075, 0.020443071150715923, 0.04196653082459031], [0.0, 0.0, 0.016003612100536798, 0.08337368064297472, 0.019550520738169194, 0.06005578303958222, 0.04361740281954369, 0.007283447498482615], [0.013679680295112203, 0.011162296243798725, 0.0025585712135654443, 0.04638326716374552, 0.057007125890736345, 0.041777936027535455, 0.011697519794741634, 0.008844186248157462], [0.030126037503842608, 0.03756201275690999, 0.031304871318918376, 0.053936283528614314, 0.06395030147999269, 0.01275888671295472, 0.007476480812205148, 0.004422093124078731], [0.0, 0.0, 0.0012542015752771785, 0.0, 0.0, 0.026229897335469706, 0.009628383038596297, 0.0016474464579901153], [0.001537042729787888, 0.00815024805102764, 0.004615461797020017, 0.014137697298344146, 0.0, 0.02492433683460922, 0.012773470907937208, 0.0], [0.05395019981555487, 0.019312544294826366, 0.16324687703807755, 0.045318098189212744, 0.004750593824228029, 0.032223606907601926, 0.03832041272381163, 0.009191017081418538], [0.03796495542576084, 0.0024805102763997165, 0.02137159484272312, 0.0, 0.05024666544856569, 0.04017565723102486, 0.07440615775098629, 0.03251539061822596], [0.0, 0.0, 0.012241007374705263, 0.08434201607436816, 0.022656678238625983, 0.058690878879591714, 0.03241647584627693, 0.008410647706581115], [0.0756225023055641, 0.09886605244507442, 0.14734360106356292, 0.016268035247409704, 0.0, 0.019820782149427334, 0.03716169614037024, 0.038324807075349], [0.006762988011066708, 0.00815024805102764, 0.007976722018762856, 0.08627868693715503, 0.030330714416225105, 0.07542579075425791, 0.025850415206775734, 0.01777508020463019], [0.07808177067322472, 0.08203401842664777, 0.061656549440626096, 0.017526871308221167, 0.07929837383519094, 0.05156963978398908, 0.030926697381852292, 0.028353420619093038], [0.011220411927451584, 0.0007087172218284905, 0.03983344203080319, 0.018785707369032633, 0.005846884706742189, 0.014657883805115424, 0.03128534775291748, 0.003901846874187115], [0.03888718106363357, 0.03206945428773919, 0.07424873325640897, 0.001452503147090152, 0.06267129545039284, 0.03815797282060412, 0.07184042817336607, 0.02809329749414723], [0.041039040885336615, 0.041814316087880936, 0.0029599157176541414, 0.012685194151253994, 0.014799926913941166, 0.019939469467687376, 0.02273291582751676, 0.0025145235411428075], [0.0, 0.0, 0.002909747654643054, 0.019850876343565412, 0.0051160241183994155, 0.06925405020473563, 0.11631307418544982, 0.0371976068672505], [0.0003074085459575776, 0.0, 0.0021572267094767473, 0.059068461314999515, 0.061392289420792986, 0.02694202124502997, 0.018898115706127403, 0.005029047082285615], [0.04226867506916692, 0.0, 0.025334871820599007, 0.002420838578483587, 0.008953042207198976, 0.046347397780547146, 0.057025408999365465, 0.009624555622994885], [0.0, 0.00407512402551382, 0.007274369136607636, 0.04570543236177012, 0.02101224191485474, 0.021304373627677883, 0.04072061136094022, 0.13743171767970172], [0.15493390716261912, 0.34532246633593194, 0.11267746952290172, 0.021400213033794906, 0.036177599122967294, 0.03720847427452377, 0.010566391701382183, 0.002687938957773346], [0.005840762373193975, 0.03065201984408221, 0.02031806551949029, 0.09654304250992544, 0.030878859857482184, 0.046466085098807196, 0.04281733660716749, 0.021937050203763114], [0.003535198278512143, 0.005315379163713678, 0.009180755531028947, 0.03679674639295052, 0.016992508678969488, 0.06854192629517536, 0.04990757855822551, 0.12789386976502212], [0.13372271749154627, 0.032246633593196315, 0.0538303316108965, 0.03689357993608986, 0.11437968207564407, 0.03608094475105335, 0.08461389908130328, 0.18668169600277465]]}

[11.27.22|22:08:10] Training epoch: 0
[11.27.22|22:53:08] Parameters:
{'work_dir': './work_dir/train/disfa/exp12/1', 'config': './config/exp12/train1.yaml', 'phase': 'train', 'save_result': False, 'start_epoch': 0, 'num_epoch': 20, 'use_gpu': True, 'device': [0], 'log_interval': 1000, 'save_interval': 5, 'eval_interval': 1, 'save_log': True, 'print_log': True, 'pavi_log': False, 'feeder': 'feeder.feeder_image_causal.Feeder', 'num_worker': 0, 'train_feeder_args': {'label_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/train1_label.pkl', 'image_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/train1_imagepath.pkl', 'image_size': 256, 'istrain': True, 'debug': False}, 'test_feeder_args': {'label_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/test1_label.pkl', 'image_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/test1_imagepath.pkl', 'image_size': 256, 'istrain': False, 'debug': False}, 'batch_size': 4, 'test_batch_size': 4, 'debug': False, 'model': 'net.causal_net.CAUSAL_NET', 'model_args': {'num_class': 8, 'backbone': 'resnet34', 'temporal_model': 'single', 'subject': True, 'pooling': True, 'd_in': 512, 'd_m': 256, 'd_out': 512}, 'weights': None, 'ignore_weights': [], 'seed': 42, 'base_lr': 0.001, 'step': [], 'optimizer': 'SGD', 'nesterov': True, 'weight_decay': 0.0005, 'lr_decay': 0.3, 'loss': 'clf', 'loss_weight': [0.05796583600359621, 0.0502662578667097, 0.14906982641370248, 0.0780216233661449, 0.04824915281587865, 0.12274372392171327, 0.2655778141497038, 0.08540999100947463], 'resume': '', 'pretrain': True, 'clf_only_epoch': 1, 'branch_loss_weight': 0.33, 'loss_class_weight': [0.06761407943209014, 0.058632929091935786, 0.1738820619000242, 0.0910080937911748, 0.056280082820188766, 0.14317405684476592, 0.3097824625561322, 0.09962623356368819], 'loss_inner_weight': [[0.0, 0.0, 0.001454873827321527, 0.0, 0.0, 0.024212212925048958, 0.0068695340304025165, 0.016127633746640075], [0.0233630494927759, 0.029411764705882353, 0.0005016806301108714, 0.0031955069235983344, 0.00694317558925635, 0.016200818942495993, 0.0295472728777554, 0.1456689499696523], [0.07623731939747926, 0.0031892274982282067, 0.08789444639542467, 0.13527645976566283, 0.2077471222364334, 0.03732716159278381, 0.0490247468756035, 0.07031995144368335], [0.16692284045496464, 0.2067682494684621, 0.07755982541514073, 0.04812627094025371, 0.07929837383519094, 0.0453978992344668, 0.02311915468866389, 0.006156247290384115], [0.003996311097448509, 0.0007087172218284905, 0.012291175437716349, 0.01423453084148349, 0.0, 0.008308112278203075, 0.020443071150715923, 0.04196653082459031], [0.0, 0.0, 0.016003612100536798, 0.08337368064297472, 0.019550520738169194, 0.06005578303958222, 0.04361740281954369, 0.007283447498482615], [0.013679680295112203, 0.011162296243798725, 0.0025585712135654443, 0.04638326716374552, 0.057007125890736345, 0.041777936027535455, 0.011697519794741634, 0.008844186248157462], [0.030126037503842608, 0.03756201275690999, 0.031304871318918376, 0.053936283528614314, 0.06395030147999269, 0.01275888671295472, 0.007476480812205148, 0.004422093124078731], [0.0, 0.0, 0.0012542015752771785, 0.0, 0.0, 0.026229897335469706, 0.009628383038596297, 0.0016474464579901153], [0.001537042729787888, 0.00815024805102764, 0.004615461797020017, 0.014137697298344146, 0.0, 0.02492433683460922, 0.012773470907937208, 0.0], [0.05395019981555487, 0.019312544294826366, 0.16324687703807755, 0.045318098189212744, 0.004750593824228029, 0.032223606907601926, 0.03832041272381163, 0.009191017081418538], [0.03796495542576084, 0.0024805102763997165, 0.02137159484272312, 0.0, 0.05024666544856569, 0.04017565723102486, 0.07440615775098629, 0.03251539061822596], [0.0, 0.0, 0.012241007374705263, 0.08434201607436816, 0.022656678238625983, 0.058690878879591714, 0.03241647584627693, 0.008410647706581115], [0.0756225023055641, 0.09886605244507442, 0.14734360106356292, 0.016268035247409704, 0.0, 0.019820782149427334, 0.03716169614037024, 0.038324807075349], [0.006762988011066708, 0.00815024805102764, 0.007976722018762856, 0.08627868693715503, 0.030330714416225105, 0.07542579075425791, 0.025850415206775734, 0.01777508020463019], [0.07808177067322472, 0.08203401842664777, 0.061656549440626096, 0.017526871308221167, 0.07929837383519094, 0.05156963978398908, 0.030926697381852292, 0.028353420619093038], [0.011220411927451584, 0.0007087172218284905, 0.03983344203080319, 0.018785707369032633, 0.005846884706742189, 0.014657883805115424, 0.03128534775291748, 0.003901846874187115], [0.03888718106363357, 0.03206945428773919, 0.07424873325640897, 0.001452503147090152, 0.06267129545039284, 0.03815797282060412, 0.07184042817336607, 0.02809329749414723], [0.041039040885336615, 0.041814316087880936, 0.0029599157176541414, 0.012685194151253994, 0.014799926913941166, 0.019939469467687376, 0.02273291582751676, 0.0025145235411428075], [0.0, 0.0, 0.002909747654643054, 0.019850876343565412, 0.0051160241183994155, 0.06925405020473563, 0.11631307418544982, 0.0371976068672505], [0.0003074085459575776, 0.0, 0.0021572267094767473, 0.059068461314999515, 0.061392289420792986, 0.02694202124502997, 0.018898115706127403, 0.005029047082285615], [0.04226867506916692, 0.0, 0.025334871820599007, 0.002420838578483587, 0.008953042207198976, 0.046347397780547146, 0.057025408999365465, 0.009624555622994885], [0.0, 0.00407512402551382, 0.007274369136607636, 0.04570543236177012, 0.02101224191485474, 0.021304373627677883, 0.04072061136094022, 0.13743171767970172], [0.15493390716261912, 0.34532246633593194, 0.11267746952290172, 0.021400213033794906, 0.036177599122967294, 0.03720847427452377, 0.010566391701382183, 0.002687938957773346], [0.005840762373193975, 0.03065201984408221, 0.02031806551949029, 0.09654304250992544, 0.030878859857482184, 0.046466085098807196, 0.04281733660716749, 0.021937050203763114], [0.003535198278512143, 0.005315379163713678, 0.009180755531028947, 0.03679674639295052, 0.016992508678969488, 0.06854192629517536, 0.04990757855822551, 0.12789386976502212], [0.13372271749154627, 0.032246633593196315, 0.0538303316108965, 0.03689357993608986, 0.11437968207564407, 0.03608094475105335, 0.08461389908130328, 0.18668169600277465]]}

[11.27.22|22:53:08] Training epoch: 0
[11.27.22|22:53:09] 	Iter 0 Done. | loss: 0.0260 | lr: 0.001000
[11.27.22|22:54:04] 	Iter 1000 Done. | loss: 0.0030 | lr: 0.001000
[11.27.22|22:54:58] 	Iter 2000 Done. | loss: 0.0349 | lr: 0.001000
[11.27.22|22:55:53] 	Iter 3000 Done. | loss: 0.0272 | lr: 0.001000
[11.27.22|22:56:50] 	Iter 4000 Done. | loss: 0.0156 | lr: 0.001000
[11.27.22|22:57:45] 	Iter 5000 Done. | loss: 0.0289 | lr: 0.001000
[11.27.22|22:58:40] 	Iter 6000 Done. | loss: 0.0005 | lr: 0.001000
[11.27.22|22:59:35] 	Iter 7000 Done. | loss: 0.0015 | lr: 0.001000
[11.27.22|23:00:32] 	Iter 8000 Done. | loss: 0.0258 | lr: 0.001000
[11.27.22|23:01:27] 	Iter 9000 Done. | loss: 0.0481 | lr: 0.001000
[11.27.22|23:02:22] 	Iter 10000 Done. | loss: 0.0011 | lr: 0.001000
[11.27.22|23:03:19] 	Iter 11000 Done. | loss: 0.0328 | lr: 0.001000
[11.27.22|23:04:15] 	Iter 12000 Done. | loss: 0.0204 | lr: 0.001000
[11.27.22|23:05:10] 	Iter 13000 Done. | loss: 0.0019 | lr: 0.001000
[11.27.22|23:06:07] 	Iter 14000 Done. | loss: 0.0007 | lr: 0.001000
[11.27.22|23:07:03] 	Iter 15000 Done. | loss: 0.0259 | lr: 0.001000
[11.27.22|23:07:59] 	Iter 16000 Done. | loss: 0.0309 | lr: 0.001000
[11.27.22|23:08:56] 	Iter 17000 Done. | loss: 0.0014 | lr: 0.001000
[11.27.22|23:09:51] 	Iter 18000 Done. | loss: 0.0262 | lr: 0.001000
[11.27.22|23:10:46] 	Iter 19000 Done. | loss: 0.0011 | lr: 0.001000
[11.27.22|23:11:43] 	Iter 20000 Done. | loss: 0.0159 | lr: 0.001000
[11.27.22|23:12:39] 	Iter 21000 Done. | loss: 0.0008 | lr: 0.001000
[11.27.22|23:13:18] 	mean_loss: 0.014362449082947794
[11.27.22|23:13:18] Time consumption:
===> loss: 0.014362449082947794
===> f1: [0.24093293 0.2362035  0.50771713 0.36195331 0.23143811 0.42867228
 0.77093291 0.35321189]
===> acc: [0.70447001 0.7346927  0.77538153 0.75922126 0.74132049 0.73982203
 0.86258011 0.74760247]
===> TP: [ 4069.  3559. 10049.  5925.  3379.  8468. 20062.  5979.]
===> TN: [57048. 60180. 57220. 59942. 60935. 55716. 54772. 58880.]
===> FN: [ 960.  802. 2884.  844.  806. 2181. 2979. 1431.]
===> FP: [24679. 22215. 16603. 20045. 21636. 20391.  8943. 20466.]
===> rec: [0.80910718 0.81609723 0.77700456 0.87531393 0.80740741 0.79519204
 0.87070874 0.80688259]
===> prec: [0.14154028 0.13808489 0.37704487 0.22814786 0.13507895 0.29342666
 0.69167385 0.22609189]
===> average f1: 0.39138275653064386
===> average acc: 0.758136324865139
[11.27.22|23:13:22] Done.
[11.27.22|23:13:22] Eval epoch: 0
[11.28.22|18:36:52] Parameters:
{'work_dir': './work_dir/train/disfa/exp12/1', 'config': './config/exp12/train1.yaml', 'phase': 'train', 'save_result': False, 'start_epoch': 0, 'num_epoch': 20, 'use_gpu': True, 'device': [0], 'log_interval': 1000, 'save_interval': 5, 'eval_interval': 1, 'save_log': True, 'print_log': True, 'pavi_log': False, 'feeder': 'feeder.feeder_image_causal.Feeder', 'num_worker': 0, 'train_feeder_args': {'label_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/train1_label.pkl', 'image_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/train1_imagepath.pkl', 'image_size': 256, 'istrain': True, 'debug': False}, 'test_feeder_args': {'label_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/test1_label.pkl', 'image_path': '/home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/test1_imagepath.pkl', 'image_size': 256, 'istrain': False, 'debug': False}, 'batch_size': 4, 'test_batch_size': 4, 'debug': False, 'model': 'net.causal_net.CAUSAL_NET', 'model_args': {'num_class': 8, 'backbone': 'resnet34', 'temporal_model': 'single', 'subject': True, 'pooling': True, 'd_in': 512, 'd_m': 256, 'd_out': 512}, 'weights': None, 'ignore_weights': [], 'seed': 42, 'base_lr': 0.001, 'step': [], 'optimizer': 'SGD', 'nesterov': True, 'weight_decay': 0.0005, 'lr_decay': 0.3, 'loss': 'clf', 'loss_weight': [0.05796583600359621, 0.0502662578667097, 0.14906982641370248, 0.0780216233661449, 0.04824915281587865, 0.12274372392171327, 0.2655778141497038, 0.08540999100947463], 'resume': '', 'pretrain': True, 'clf_only_epoch': 1, 'branch_loss_weight': 0.33, 'loss_class_weight': [0.06761407943209014, 0.058632929091935786, 0.1738820619000242, 0.0910080937911748, 0.056280082820188766, 0.14317405684476592, 0.3097824625561322, 0.09962623356368819], 'loss_inner_weight': [[0.0, 0.0, 0.001454873827321527, 0.0, 0.0, 0.024212212925048958, 0.0068695340304025165, 0.016127633746640075], [0.0233630494927759, 0.029411764705882353, 0.0005016806301108714, 0.0031955069235983344, 0.00694317558925635, 0.016200818942495993, 0.0295472728777554, 0.1456689499696523], [0.07623731939747926, 0.0031892274982282067, 0.08789444639542467, 0.13527645976566283, 0.2077471222364334, 0.03732716159278381, 0.0490247468756035, 0.07031995144368335], [0.16692284045496464, 0.2067682494684621, 0.07755982541514073, 0.04812627094025371, 0.07929837383519094, 0.0453978992344668, 0.02311915468866389, 0.006156247290384115], [0.003996311097448509, 0.0007087172218284905, 0.012291175437716349, 0.01423453084148349, 0.0, 0.008308112278203075, 0.020443071150715923, 0.04196653082459031], [0.0, 0.0, 0.016003612100536798, 0.08337368064297472, 0.019550520738169194, 0.06005578303958222, 0.04361740281954369, 0.007283447498482615], [0.013679680295112203, 0.011162296243798725, 0.0025585712135654443, 0.04638326716374552, 0.057007125890736345, 0.041777936027535455, 0.011697519794741634, 0.008844186248157462], [0.030126037503842608, 0.03756201275690999, 0.031304871318918376, 0.053936283528614314, 0.06395030147999269, 0.01275888671295472, 0.007476480812205148, 0.004422093124078731], [0.0, 0.0, 0.0012542015752771785, 0.0, 0.0, 0.026229897335469706, 0.009628383038596297, 0.0016474464579901153], [0.001537042729787888, 0.00815024805102764, 0.004615461797020017, 0.014137697298344146, 0.0, 0.02492433683460922, 0.012773470907937208, 0.0], [0.05395019981555487, 0.019312544294826366, 0.16324687703807755, 0.045318098189212744, 0.004750593824228029, 0.032223606907601926, 0.03832041272381163, 0.009191017081418538], [0.03796495542576084, 0.0024805102763997165, 0.02137159484272312, 0.0, 0.05024666544856569, 0.04017565723102486, 0.07440615775098629, 0.03251539061822596], [0.0, 0.0, 0.012241007374705263, 0.08434201607436816, 0.022656678238625983, 0.058690878879591714, 0.03241647584627693, 0.008410647706581115], [0.0756225023055641, 0.09886605244507442, 0.14734360106356292, 0.016268035247409704, 0.0, 0.019820782149427334, 0.03716169614037024, 0.038324807075349], [0.006762988011066708, 0.00815024805102764, 0.007976722018762856, 0.08627868693715503, 0.030330714416225105, 0.07542579075425791, 0.025850415206775734, 0.01777508020463019], [0.07808177067322472, 0.08203401842664777, 0.061656549440626096, 0.017526871308221167, 0.07929837383519094, 0.05156963978398908, 0.030926697381852292, 0.028353420619093038], [0.011220411927451584, 0.0007087172218284905, 0.03983344203080319, 0.018785707369032633, 0.005846884706742189, 0.014657883805115424, 0.03128534775291748, 0.003901846874187115], [0.03888718106363357, 0.03206945428773919, 0.07424873325640897, 0.001452503147090152, 0.06267129545039284, 0.03815797282060412, 0.07184042817336607, 0.02809329749414723], [0.041039040885336615, 0.041814316087880936, 0.0029599157176541414, 0.012685194151253994, 0.014799926913941166, 0.019939469467687376, 0.02273291582751676, 0.0025145235411428075], [0.0, 0.0, 0.002909747654643054, 0.019850876343565412, 0.0051160241183994155, 0.06925405020473563, 0.11631307418544982, 0.0371976068672505], [0.0003074085459575776, 0.0, 0.0021572267094767473, 0.059068461314999515, 0.061392289420792986, 0.02694202124502997, 0.018898115706127403, 0.005029047082285615], [0.04226867506916692, 0.0, 0.025334871820599007, 0.002420838578483587, 0.008953042207198976, 0.046347397780547146, 0.057025408999365465, 0.009624555622994885], [0.0, 0.00407512402551382, 0.007274369136607636, 0.04570543236177012, 0.02101224191485474, 0.021304373627677883, 0.04072061136094022, 0.13743171767970172], [0.15493390716261912, 0.34532246633593194, 0.11267746952290172, 0.021400213033794906, 0.036177599122967294, 0.03720847427452377, 0.010566391701382183, 0.002687938957773346], [0.005840762373193975, 0.03065201984408221, 0.02031806551949029, 0.09654304250992544, 0.030878859857482184, 0.046466085098807196, 0.04281733660716749, 0.021937050203763114], [0.003535198278512143, 0.005315379163713678, 0.009180755531028947, 0.03679674639295052, 0.016992508678969488, 0.06854192629517536, 0.04990757855822551, 0.12789386976502212], [0.13372271749154627, 0.032246633593196315, 0.0538303316108965, 0.03689357993608986, 0.11437968207564407, 0.03608094475105335, 0.08461389908130328, 0.18668169600277465]]}

[11.28.22|18:36:52] Training epoch: 0
[11.28.22|18:36:52] 	Iter 0 Done. | loss: 0.0789 | lr: 0.001000
[11.28.22|18:37:45] 	Iter 1000 Done. | loss: 0.0408 | lr: 0.001000
[11.28.22|18:38:41] 	Iter 2000 Done. | loss: 0.0688 | lr: 0.001000
[11.28.22|18:39:37] 	Iter 3000 Done. | loss: 0.0637 | lr: 0.001000
[11.28.22|18:40:32] 	Iter 4000 Done. | loss: 0.0292 | lr: 0.001000
[11.28.22|18:41:28] 	Iter 5000 Done. | loss: 0.0760 | lr: 0.001000
[11.28.22|18:42:23] 	Iter 6000 Done. | loss: 0.0467 | lr: 0.001000
[11.28.22|18:43:18] 	Iter 7000 Done. | loss: 0.0216 | lr: 0.001000
[11.28.22|18:44:14] 	Iter 8000 Done. | loss: 0.0475 | lr: 0.001000
[11.28.22|18:45:11] 	Iter 9000 Done. | loss: 0.0650 | lr: 0.001000
[11.28.22|18:46:09] 	Iter 10000 Done. | loss: 0.0234 | lr: 0.001000
[11.28.22|18:47:04] 	Iter 11000 Done. | loss: 0.0810 | lr: 0.001000
[11.28.22|18:48:02] 	Iter 12000 Done. | loss: 0.0364 | lr: 0.001000
[11.28.22|18:48:57] 	Iter 13000 Done. | loss: 0.0367 | lr: 0.001000
[11.28.22|18:49:53] 	Iter 14000 Done. | loss: 0.0177 | lr: 0.001000
[11.28.22|18:50:50] 	Iter 15000 Done. | loss: 0.0590 | lr: 0.001000
[11.28.22|18:51:45] 	Iter 16000 Done. | loss: 0.0552 | lr: 0.001000
[11.28.22|18:52:41] 	Iter 17000 Done. | loss: 0.0146 | lr: 0.001000
[11.28.22|18:53:39] 	Iter 18000 Done. | loss: 0.0476 | lr: 0.001000
[11.28.22|18:54:36] 	Iter 19000 Done. | loss: 0.0122 | lr: 0.001000
[11.28.22|18:55:31] 	Iter 20000 Done. | loss: 0.0278 | lr: 0.001000
[11.28.22|18:56:29] 	Iter 21000 Done. | loss: 0.0214 | lr: 0.001000
[11.28.22|18:57:07] 	mean_loss: 0.03983651312722336
[11.28.22|18:57:07] Time consumption:
===> loss: 0.03983651312722336
===> f1: [0.24346533 0.22640345 0.48413616 0.33350104 0.22679061 0.4241288
 0.76421536 0.34093695]
===> acc: [0.71274609 0.73415095 0.75448384 0.72564434 0.7368597  0.74064042
 0.85384296 0.74291115]
===> TP: [ 4010.  3375.  9995.  5955.  3348.  8286. 20549.  5769.]
===> TN: [57825. 60317. 55461. 56999. 60579. 55969. 53527. 58683.]
===> FN: [1019.  986. 2938.  814.  837. 2363. 2492. 1641.]
===> FP: [23902. 22078. 18362. 22988. 21992. 20138. 10188. 20663.]
===> rec: [0.79737522 0.77390507 0.7728292  0.8797459  0.8        0.77810123
 0.89184497 0.77854251]
===> prec: [0.14366581 0.13259734 0.35247029 0.20574923 0.13212313 0.29151421
 0.6685428  0.21825817]
===> average f1: 0.38044721383710073
===> average acc: 0.7501599313015814
[11.28.22|18:57:11] Done.
[11.28.22|18:57:11] Eval epoch: 0
[11.28.22|18:59:54] 	mean_loss: 0.05443774295262374
===> loss: 0.05443774295262374
===> f1: [0.18834144 0.06802232 0.3205044  0.47153773 0.17109501 0.57794781
 0.8711137  0.40807091]
===> acc: [0.81063664 0.57643794 0.60237593 0.8213696  0.72956609 0.79809192
 0.91470966 0.75309605]
===> TP: [  958.   674.  4089.  3475.  1217.  6028. 12568.  3711.]
===> TN: [34389. 24461. 22177. 32340. 30595. 28772. 27317. 29127.]
===> FN: [ 511.  204. 2564.   83.   70.  159.  637.  412.]
===> FP: [ 7746. 18265. 14774.  7706. 11722.  8645.  3082. 10354.]
===> rec: [0.65214432 0.76765376 0.61460995 0.97667229 0.94560995 0.97430095
 0.9517607  0.90007276]
===> prec: [0.11006434 0.03558794 0.21677358 0.3107951  0.09405673 0.4108226
 0.80306709 0.26384643]
===> average f1: 0.38457916378895196
===> average acc: 0.7507854783964774
[11.28.22|18:59:56] Done.
[11.28.22|18:59:56] Training epoch: 1
[11.28.22|19:00:13] 	Iter 22000 Done. | loss: 0.0286 | lr: 0.001000
[11.28.22|19:01:09] 	Iter 23000 Done. | loss: 0.0615 | lr: 0.001000
[11.28.22|19:02:05] 	Iter 24000 Done. | loss: 0.0511 | lr: 0.001000
[11.28.22|19:03:00] 	Iter 25000 Done. | loss: 0.0226 | lr: 0.001000
[11.28.22|19:03:55] 	Iter 26000 Done. | loss: 0.0135 | lr: 0.001000
[11.28.22|19:04:50] 	Iter 27000 Done. | loss: 0.0213 | lr: 0.001000
[11.28.22|19:05:46] 	Iter 28000 Done. | loss: 0.0465 | lr: 0.001000
[11.28.22|19:06:42] 	Iter 29000 Done. | loss: 0.0234 | lr: 0.001000
[11.28.22|19:07:38] 	Iter 30000 Done. | loss: 0.0038 | lr: 0.001000
[11.28.22|19:08:35] 	Iter 31000 Done. | loss: 0.0274 | lr: 0.001000
[11.28.22|19:09:30] 	Iter 32000 Done. | loss: 0.0061 | lr: 0.001000
[11.28.22|19:10:26] 	Iter 33000 Done. | loss: 0.0133 | lr: 0.001000
[11.28.22|19:11:22] 	Iter 34000 Done. | loss: 0.0419 | lr: 0.001000
[11.28.22|19:12:21] 	Iter 35000 Done. | loss: 0.0037 | lr: 0.001000
[11.28.22|19:13:28] 	Iter 36000 Done. | loss: 0.0551 | lr: 0.001000
[11.28.22|19:14:28] 	Iter 37000 Done. | loss: 0.0052 | lr: 0.001000
[11.28.22|19:15:27] 	Iter 38000 Done. | loss: 0.0206 | lr: 0.001000
[11.28.22|19:16:26] 	Iter 39000 Done. | loss: 0.0383 | lr: 0.001000
[11.28.22|19:17:26] 	Iter 40000 Done. | loss: 0.0061 | lr: 0.001000
[11.28.22|19:18:25] 	Iter 41000 Done. | loss: 0.0024 | lr: 0.001000
[11.28.22|19:19:23] 	Iter 42000 Done. | loss: 0.0099 | lr: 0.001000
[11.28.22|19:20:20] 	Iter 43000 Done. | loss: 0.0076 | lr: 0.001000
[11.28.22|19:20:42] 	mean_loss: 0.020901255993608325
[11.28.22|19:20:42] Time consumption:
===> loss: 0.020901255993608325
===> f1: [0.36558656 0.40926524 0.73160099 0.52582315 0.42171464 0.61042251
 0.91564452 0.50309075]
===> acc: [0.8254991  0.87066024 0.89877357 0.86909263 0.8834778  0.86187699
 0.95217622 0.85454608]
===> TP: [ 4362.  3887. 11969.  6297.  3686.  9388. 22518.  6388.]
===> TN: [67255. 71648. 66005. 69102. 72961. 65385. 60089. 67749.]
===> FN: [ 667.  474.  964.  472.  500. 1261.  522. 1021.]
===> FP: [14472. 10747.  7818. 10885.  9609. 10722.  3627. 11598.]
===> rec: [0.86736926 0.89130933 0.925462   0.93027035 0.88055423 0.88158513
 0.97734375 0.86219463]
===> prec: [0.23160242 0.26561432 0.6048921  0.36648819 0.27724709 0.46683242
 0.86127367 0.35516513]
===> average f1: 0.5603935446296118
===> average acc: 0.8770128290838675
[11.28.22|19:20:46] Done.
[11.28.22|19:20:46] Eval epoch: 1
[11.28.22|19:23:32] 	mean_loss: 0.04321734291145316
===> loss: 0.04321734291145316
===> f1: [0.19449267 0.11864901 0.45379884 0.4595068  0.14836678 0.63934211
 0.88653199 0.42723792]
===> acc: [0.73500138 0.72947436 0.64292267 0.81036143 0.66273736 0.84198697
 0.92539675 0.76775067]
===> TP: [ 1395.   794.  6468.  3515.  1281.  6107. 12708.  3777.]
===> TN: [30654. 31014. 21566. 31820. 27617. 30607. 27643. 29700.]
===> FN: [ 74.  84. 185.  43.   6.  80. 497. 346.]
===> FP: [11481. 11712. 15385.  8226. 14700.  6810.  2756.  9781.]
===> rec: [0.9496256  0.90432802 0.972193   0.98791456 0.995338   0.98706966
 0.96236274 0.91608052]
===> prec: [0.1083411  0.06348953 0.29597767 0.29937825 0.08015769 0.4727878
 0.82177962 0.27858091]
===> average f1: 0.4159907663867596
===> average acc: 0.7644539491789744
[11.28.22|19:23:34] Done.
[11.28.22|19:23:34] Training epoch: 2
[11.28.22|19:24:11] 	Iter 44000 Done. | loss: 0.0099 | lr: 0.001000
[11.28.22|19:25:12] 	Iter 45000 Done. | loss: 0.0072 | lr: 0.001000
[11.28.22|19:26:13] 	Iter 46000 Done. | loss: 0.0053 | lr: 0.001000
[11.28.22|19:27:16] 	Iter 47000 Done. | loss: 0.0611 | lr: 0.001000
[11.28.22|19:28:17] 	Iter 48000 Done. | loss: 0.0419 | lr: 0.001000
[11.28.22|19:29:15] 	Iter 49000 Done. | loss: 0.0318 | lr: 0.001000
[11.28.22|19:30:14] 	Iter 50000 Done. | loss: 0.0333 | lr: 0.001000
[11.28.22|19:31:13] 	Iter 51000 Done. | loss: 0.0869 | lr: 0.001000
[11.28.22|19:32:13] 	Iter 52000 Done. | loss: 0.0067 | lr: 0.001000
[11.28.22|19:33:14] 	Iter 53000 Done. | loss: 0.0327 | lr: 0.001000
[11.28.22|19:34:13] 	Iter 54000 Done. | loss: 0.0137 | lr: 0.001000
[11.28.22|19:35:14] 	Iter 55000 Done. | loss: 0.0022 | lr: 0.001000
[11.28.22|19:36:14] 	Iter 56000 Done. | loss: 0.0048 | lr: 0.001000
[11.28.22|19:37:12] 	Iter 57000 Done. | loss: 0.0331 | lr: 0.001000
[11.28.22|19:38:11] 	Iter 58000 Done. | loss: 0.0131 | lr: 0.001000
[11.28.22|19:39:10] 	Iter 59000 Done. | loss: 0.0091 | lr: 0.001000
[11.28.22|19:40:09] 	Iter 60000 Done. | loss: 0.0047 | lr: 0.001000
[11.28.22|19:41:06] 	Iter 61000 Done. | loss: 0.0177 | lr: 0.001000
[11.28.22|19:42:06] 	Iter 62000 Done. | loss: 0.0086 | lr: 0.001000
[11.28.22|19:43:04] 	Iter 63000 Done. | loss: 0.0017 | lr: 0.001000
[11.28.22|19:44:02] 	Iter 64000 Done. | loss: 0.0051 | lr: 0.001000
[11.28.22|19:45:01] 	Iter 65000 Done. | loss: 0.0031 | lr: 0.001000
[11.28.22|19:45:05] 	mean_loss: 0.014133160792816233
[11.28.22|19:45:05] Time consumption:
===> loss: 0.014133160792816233
===> f1: [0.56960986 0.55468025 0.85072879 0.6306672  0.58008102 0.7425554
 0.95075572 0.64687618]
===> acc: [0.91814975 0.92372862 0.95010143 0.91296279 0.93463276 0.92007469
 0.97301628 0.91457651]
===> TP: [ 4699.  4121. 12336.  6447.  3917. 10000. 22599.  6788.]
===> TN: [74956. 76018. 70091. 72758. 77168. 69822. 61816. 72557.]
===> FN: [330. 240. 597. 322. 269. 648. 441. 621.]
===> FP: [6771. 6377. 3732. 7229. 5402. 6286. 1900. 6790.]
===> rec: [0.93438059 0.94496675 0.95383902 0.9524302  0.93573817 0.9391435
 0.98085937 0.91618302]
===> prec: [0.40967742 0.39255096 0.76773712 0.47140977 0.42032407 0.61402432
 0.92244581 0.49992635]
===> average f1: 0.6907443030197749
===> average acc: 0.9309053552492046
[11.28.22|19:45:09] Done.
[11.28.22|19:45:09] Eval epoch: 2
[11.28.22|19:48:02] 	mean_loss: 0.05866487584213175
===> loss: 0.05866487584213175
===> f1: [0.1015694  0.06950122 0.30393674 0.4233398  0.09516395 0.71167306
 0.90200275 0.41649377]
===> acc: [0.44862857 0.48908357 0.33097881 0.77969911 0.4395927  0.89078984
 0.93773507 0.76731493]
===> TP: [ 1359.   832.  6369.  3526.  1285.  5877. 12495.  3621.]
===> TN: [18203. 20494.  8063. 30472. 17883. 32965. 28394. 29837.]
===> FN: [110.  46. 284.  32.   2. 310. 710. 502.]
===> FP: [23932. 22232. 28888.  9574. 24434.  4452.  2005.  9644.]
===> rec: [0.92511913 0.9476082  0.95731249 0.99100618 0.998446   0.94989494
 0.94623249 0.878244  ]
===> prec: [0.05373453 0.03607353 0.18064498 0.26916031 0.04996306 0.56898054
 0.86172414 0.27297399]
===> average f1: 0.37796008717249735
===> average acc: 0.6354778231354922
[11.28.22|19:48:05] Done.
[11.28.22|19:48:05] Training epoch: 3
[11.28.22|19:48:59] 	Iter 66000 Done. | loss: 0.0025 | lr: 0.001000
[11.28.22|19:49:58] 	Iter 67000 Done. | loss: 0.0115 | lr: 0.001000
[11.28.22|19:50:57] 	Iter 68000 Done. | loss: 0.0058 | lr: 0.001000
[11.28.22|19:51:55] 	Iter 69000 Done. | loss: 0.0072 | lr: 0.001000
[11.28.22|19:52:59] 	Iter 70000 Done. | loss: 0.0097 | lr: 0.001000
[11.28.22|19:53:55] 	Iter 71000 Done. | loss: 0.0011 | lr: 0.001000
[11.28.22|19:54:56] 	Iter 72000 Done. | loss: 0.0058 | lr: 0.001000
[11.28.22|19:55:54] 	Iter 73000 Done. | loss: 0.0125 | lr: 0.001000
[11.28.22|19:56:58] 	Iter 74000 Done. | loss: 0.0077 | lr: 0.001000
[11.28.22|19:57:59] 	Iter 75000 Done. | loss: 0.0078 | lr: 0.001000
[11.28.22|19:58:59] 	Iter 76000 Done. | loss: 0.0182 | lr: 0.001000
[11.28.22|19:59:57] 	Iter 77000 Done. | loss: 0.0007 | lr: 0.001000
[11.28.22|20:00:58] 	Iter 78000 Done. | loss: 0.0031 | lr: 0.001000
[11.28.22|20:01:54] 	Iter 79000 Done. | loss: 0.0095 | lr: 0.001000
[11.28.22|20:02:53] 	Iter 80000 Done. | loss: 0.0026 | lr: 0.001000
[11.28.22|20:03:54] 	Iter 81000 Done. | loss: 0.0071 | lr: 0.001000
[11.28.22|20:04:54] 	Iter 82000 Done. | loss: 0.0292 | lr: 0.001000
[11.28.22|20:05:51] 	Iter 83000 Done. | loss: 0.0449 | lr: 0.001000
[11.28.22|20:06:49] 	Iter 84000 Done. | loss: 0.0011 | lr: 0.001000
[11.28.22|20:07:45] 	Iter 85000 Done. | loss: 0.0136 | lr: 0.001000
[11.28.22|20:08:49] 	Iter 86000 Done. | loss: 0.0068 | lr: 0.001000
[11.28.22|20:09:33] 	mean_loss: 0.010812081183961694
[11.28.22|20:09:33] Time consumption:
===> loss: 0.010812081183961694
===> f1: [0.65718518 0.65467245 0.8905696  0.68712131 0.64057743 0.81709517
 0.96310258 0.73098537]
===> acc: [0.94192909 0.94889114 0.96482088 0.93206234 0.94780764 0.94741574
 0.97998986 0.94108765]
===> TP: [ 4829.  4203. 12419.  6472.  4035. 10190. 22657.  6944.]
===> TN: [76889. 78119. 71285. 74390. 78193. 72004. 62363. 74701.]
===> FN: [200. 158. 513. 297. 151. 459. 383. 465.]
===> FP: [4838. 4276. 2539. 5597. 4377. 4103. 1353. 4646.]
===> rec: [0.96023066 0.96376978 0.96033096 0.9561235  0.96392738 0.95689736
 0.98337674 0.93723849]
===> prec: [0.4995345  0.49569525 0.83025806 0.5362499  0.4796719  0.7129364
 0.94364848 0.59913719]
===> average f1: 0.7551636358767766
===> average acc: 0.9505005417492738
[11.28.22|20:09:37] Done.
[11.28.22|20:09:37] Eval epoch: 3
[11.28.22|20:12:20] 	mean_loss: 0.03938935631126397
===> loss: 0.03938935631126397
===> f1: [0.26177018 0.15608581 0.61497468 0.44527454 0.20355643 0.67317836
 0.90488514 0.4154761 ]
===> acc: [0.83494634 0.80458215 0.85070177 0.79914687 0.78841391 0.86418677
 0.94039538 0.77098431]
===> TP: [ 1276.   788.  5199.  3515.  1179.  6099. 12363.  3549.]
===> TN: [35131. 34295. 31895. 31331. 33199. 31583. 28642. 30069.]
===> FN: [ 193.   90. 1454.   43.  108.   88.  842.  574.]
===> FP: [7004. 8431. 5056. 8715. 9118. 5834. 1757. 9412.]
===> rec: [0.86861811 0.89749431 0.78145198 0.98791456 0.91608392 0.98577663
 0.93623627 0.86078098]
===> prec: [0.15410628 0.08547565 0.50697221 0.28740801 0.11449937 0.51110366
 0.87556657 0.27382146]
===> average f1: 0.4594001555888407
===> average acc: 0.831669686267315
[11.28.22|20:12:22] Done.
[11.28.22|20:12:22] Training epoch: 4
[11.28.22|20:12:34] 	Iter 87000 Done. | loss: 0.0091 | lr: 0.001000
[11.28.22|20:13:24] 	Iter 88000 Done. | loss: 0.0029 | lr: 0.001000
[11.28.22|20:14:14] 	Iter 89000 Done. | loss: 0.0008 | lr: 0.001000
[11.28.22|20:15:10] 	Iter 90000 Done. | loss: 0.0279 | lr: 0.001000
[11.28.22|20:16:07] 	Iter 91000 Done. | loss: 0.0029 | lr: 0.001000
[11.28.22|20:17:04] 	Iter 92000 Done. | loss: 0.0037 | lr: 0.001000
[11.28.22|20:18:03] 	Iter 93000 Done. | loss: 0.0172 | lr: 0.001000
[11.28.22|20:18:59] 	Iter 94000 Done. | loss: 0.0007 | lr: 0.001000
[11.28.22|20:19:56] 	Iter 95000 Done. | loss: 0.0014 | lr: 0.001000
[11.28.22|20:20:54] 	Iter 96000 Done. | loss: 0.0094 | lr: 0.001000
[11.28.22|20:21:53] 	Iter 97000 Done. | loss: 0.0054 | lr: 0.001000
[11.28.22|20:22:51] 	Iter 98000 Done. | loss: 0.0090 | lr: 0.001000
[11.28.22|20:23:50] 	Iter 99000 Done. | loss: 0.0023 | lr: 0.001000
[11.28.22|20:24:47] 	Iter 100000 Done. | loss: 0.0085 | lr: 0.001000
[11.28.22|20:25:47] 	Iter 101000 Done. | loss: 0.0077 | lr: 0.001000
[11.28.22|20:26:45] 	Iter 102000 Done. | loss: 0.0023 | lr: 0.001000
[11.28.22|20:27:44] 	Iter 103000 Done. | loss: 0.0017 | lr: 0.001000
[11.28.22|20:28:46] 	Iter 104000 Done. | loss: 0.0117 | lr: 0.001000
[11.28.22|20:29:46] 	Iter 105000 Done. | loss: 0.0058 | lr: 0.001000
