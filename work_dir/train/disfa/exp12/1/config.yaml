# command line: main.py train-causal-net -c ./config/exp12/train1.yaml

base_lr: 0.001
batch_size: 4
branch_loss_weight: 0.33
clf_only_epoch: 1
config: ./config/exp12/train1.yaml
debug: false
device:
- 0
eval_interval: 1
feeder: feeder.feeder_image_causal.Feeder
ignore_weights: []
log_interval: 1000
loss: clf
loss_class_weight:
- 0.06761407943209014
- 0.058632929091935786
- 0.1738820619000242
- 0.0910080937911748
- 0.056280082820188766
- 0.14317405684476592
- 0.3097824625561322
- 0.09962623356368819
loss_inner_weight:
-   - 0.0
    - 0.0
    - 0.001454873827321527
    - 0.0
    - 0.0
    - 0.024212212925048958
    - 0.0068695340304025165
    - 0.016127633746640075
-   - 0.0233630494927759
    - 0.029411764705882353
    - 0.0005016806301108714
    - 0.0031955069235983344
    - 0.00694317558925635
    - 0.016200818942495993
    - 0.0295472728777554
    - 0.1456689499696523
-   - 0.07623731939747926
    - 0.0031892274982282067
    - 0.08789444639542467
    - 0.13527645976566283
    - 0.2077471222364334
    - 0.03732716159278381
    - 0.0490247468756035
    - 0.07031995144368335
-   - 0.16692284045496464
    - 0.2067682494684621
    - 0.07755982541514073
    - 0.04812627094025371
    - 0.07929837383519094
    - 0.0453978992344668
    - 0.02311915468866389
    - 0.006156247290384115
-   - 0.003996311097448509
    - 0.0007087172218284905
    - 0.012291175437716349
    - 0.01423453084148349
    - 0.0
    - 0.008308112278203075
    - 0.020443071150715923
    - 0.04196653082459031
-   - 0.0
    - 0.0
    - 0.016003612100536798
    - 0.08337368064297472
    - 0.019550520738169194
    - 0.06005578303958222
    - 0.04361740281954369
    - 0.007283447498482615
-   - 0.013679680295112203
    - 0.011162296243798725
    - 0.0025585712135654443
    - 0.04638326716374552
    - 0.057007125890736345
    - 0.041777936027535455
    - 0.011697519794741634
    - 0.008844186248157462
-   - 0.030126037503842608
    - 0.03756201275690999
    - 0.031304871318918376
    - 0.053936283528614314
    - 0.06395030147999269
    - 0.01275888671295472
    - 0.007476480812205148
    - 0.004422093124078731
-   - 0.0
    - 0.0
    - 0.0012542015752771785
    - 0.0
    - 0.0
    - 0.026229897335469706
    - 0.009628383038596297
    - 0.0016474464579901153
-   - 0.001537042729787888
    - 0.00815024805102764
    - 0.004615461797020017
    - 0.014137697298344146
    - 0.0
    - 0.02492433683460922
    - 0.012773470907937208
    - 0.0
-   - 0.05395019981555487
    - 0.019312544294826366
    - 0.16324687703807755
    - 0.045318098189212744
    - 0.004750593824228029
    - 0.032223606907601926
    - 0.03832041272381163
    - 0.009191017081418538
-   - 0.03796495542576084
    - 0.0024805102763997165
    - 0.02137159484272312
    - 0.0
    - 0.05024666544856569
    - 0.04017565723102486
    - 0.07440615775098629
    - 0.03251539061822596
-   - 0.0
    - 0.0
    - 0.012241007374705263
    - 0.08434201607436816
    - 0.022656678238625983
    - 0.058690878879591714
    - 0.03241647584627693
    - 0.008410647706581115
-   - 0.0756225023055641
    - 0.09886605244507442
    - 0.14734360106356292
    - 0.016268035247409704
    - 0.0
    - 0.019820782149427334
    - 0.03716169614037024
    - 0.038324807075349
-   - 0.006762988011066708
    - 0.00815024805102764
    - 0.007976722018762856
    - 0.08627868693715503
    - 0.030330714416225105
    - 0.07542579075425791
    - 0.025850415206775734
    - 0.01777508020463019
-   - 0.07808177067322472
    - 0.08203401842664777
    - 0.061656549440626096
    - 0.017526871308221167
    - 0.07929837383519094
    - 0.05156963978398908
    - 0.030926697381852292
    - 0.028353420619093038
-   - 0.011220411927451584
    - 0.0007087172218284905
    - 0.03983344203080319
    - 0.018785707369032633
    - 0.005846884706742189
    - 0.014657883805115424
    - 0.03128534775291748
    - 0.003901846874187115
-   - 0.03888718106363357
    - 0.03206945428773919
    - 0.07424873325640897
    - 0.001452503147090152
    - 0.06267129545039284
    - 0.03815797282060412
    - 0.07184042817336607
    - 0.02809329749414723
-   - 0.041039040885336615
    - 0.041814316087880936
    - 0.0029599157176541414
    - 0.012685194151253994
    - 0.014799926913941166
    - 0.019939469467687376
    - 0.02273291582751676
    - 0.0025145235411428075
-   - 0.0
    - 0.0
    - 0.002909747654643054
    - 0.019850876343565412
    - 0.0051160241183994155
    - 0.06925405020473563
    - 0.11631307418544982
    - 0.0371976068672505
-   - 0.0003074085459575776
    - 0.0
    - 0.0021572267094767473
    - 0.059068461314999515
    - 0.061392289420792986
    - 0.02694202124502997
    - 0.018898115706127403
    - 0.005029047082285615
-   - 0.04226867506916692
    - 0.0
    - 0.025334871820599007
    - 0.002420838578483587
    - 0.008953042207198976
    - 0.046347397780547146
    - 0.057025408999365465
    - 0.009624555622994885
-   - 0.0
    - 0.00407512402551382
    - 0.007274369136607636
    - 0.04570543236177012
    - 0.02101224191485474
    - 0.021304373627677883
    - 0.04072061136094022
    - 0.13743171767970172
-   - 0.15493390716261912
    - 0.34532246633593194
    - 0.11267746952290172
    - 0.021400213033794906
    - 0.036177599122967294
    - 0.03720847427452377
    - 0.010566391701382183
    - 0.002687938957773346
-   - 0.005840762373193975
    - 0.03065201984408221
    - 0.02031806551949029
    - 0.09654304250992544
    - 0.030878859857482184
    - 0.046466085098807196
    - 0.04281733660716749
    - 0.021937050203763114
-   - 0.003535198278512143
    - 0.005315379163713678
    - 0.009180755531028947
    - 0.03679674639295052
    - 0.016992508678969488
    - 0.06854192629517536
    - 0.04990757855822551
    - 0.12789386976502212
-   - 0.13372271749154627
    - 0.032246633593196315
    - 0.0538303316108965
    - 0.03689357993608986
    - 0.11437968207564407
    - 0.03608094475105335
    - 0.08461389908130328
    - 0.18668169600277465
loss_weight:
- 0.05796583600359621
- 0.0502662578667097
- 0.14906982641370248
- 0.0780216233661449
- 0.04824915281587865
- 0.12274372392171327
- 0.2655778141497038
- 0.08540999100947463
lr_decay: 0.3
model: net.causal_net.CAUSAL_NET
model_args:
    backbone: resnet34
    d_in: 512
    d_m: 256
    d_out: 512
    num_class: 8
    pooling: true
    subject: true
    temporal_model: single
nesterov: true
num_epoch: 20
num_worker: 0
optimizer: SGD
pavi_log: false
phase: train
pretrain: true
print_log: true
resume: ''
save_interval: 5
save_log: true
save_result: false
seed: 42
start_epoch: 0
step: []
test_batch_size: 4
test_feeder_args:
    image_path: /home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/test1_imagepath.pkl
    image_size: 256
    istrain: false
    label_path: /home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/test1_label.pkl
train_feeder_args:
    image_path: /home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/train1_imagepath.pkl
    image_size: 256
    istrain: true
    label_path: /home/hfutzny/sda/casual_face/CIS/data/DISFA/list_random2/train1_label.pkl
use_gpu: true
weight_decay: 0.0005
weights: null
work_dir: ./work_dir/train/disfa/exp12/1
