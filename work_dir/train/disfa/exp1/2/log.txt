[11.05.22|21:45:29] Parameters:
{'work_dir': './work_dir/train/disfa/exp1/2', 'config': './config/exp1/train2.yaml', 'phase': 'train', 'save_result': False, 'start_epoch': 0, 'num_epoch': 15, 'use_gpu': True, 'device': [0], 'log_interval': 1000, 'save_interval': 5, 'eval_interval': 1, 'save_log': True, 'print_log': True, 'pavi_log': False, 'feeder': 'feeder.feeder_image_causal.Feeder', 'num_worker': 0, 'train_feeder_args': {'label_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/train2_label.pkl', 'image_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/train2_imagepath.pkl', 'image_size': 256, 'istrain': True, 'debug': False}, 'test_feeder_args': {'label_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/test2_label.pkl', 'image_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/test2_imagepath.pkl', 'image_size': 256, 'istrain': False, 'debug': False}, 'batch_size': 64, 'test_batch_size': 64, 'debug': False, 'model': 'net.CISNet.Model', 'model_args': {'num_class': 8, 'backbone': 'resnet34', 'temporal_model': 'single', 'subject': True, 'pooling': True, 'd_in': 512, 'd_m': 256, 'd_out': 512}, 'weights': None, 'ignore_weights': [], 'seed': 42, 'base_lr': 0.001, 'step': [], 'optimizer': 'SGD', 'nesterov': True, 'weight_decay': 0.0005, 'lr_decay': 0.3, 'loss': 'clf', 'loss_weight': [0.031722903592202936, 0.01977948853271532, 0.15360080770069182, 0.08390220396737073, 0.04059154897259095, 0.12787829419120936, 0.2613554227234658, 0.09429676116611788], 'resume': '', 'backbone_only': True, 'pretrain': True, 'clf_only_epoch': 1}

[11.05.22|21:45:29] Training epoch: 0
[11.06.22|05:35:56] Parameters:
{'work_dir': './work_dir/train/disfa/exp1/2', 'config': './config/exp1/train2.yaml', 'phase': 'train', 'save_result': False, 'start_epoch': 0, 'num_epoch': 15, 'use_gpu': True, 'device': [0], 'log_interval': 1000, 'save_interval': 5, 'eval_interval': 1, 'save_log': True, 'print_log': True, 'pavi_log': False, 'feeder': 'feeder.feeder_image_causal.Feeder', 'num_worker': 0, 'train_feeder_args': {'label_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/train2_label.pkl', 'image_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/train2_imagepath.pkl', 'image_size': 256, 'istrain': True, 'debug': False}, 'test_feeder_args': {'label_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/test2_label.pkl', 'image_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/test2_imagepath.pkl', 'image_size': 256, 'istrain': False, 'debug': False}, 'batch_size': 64, 'test_batch_size': 64, 'debug': False, 'model': 'net.CISNet.Model', 'model_args': {'num_class': 8, 'backbone': 'resnet34', 'temporal_model': 'single', 'subject': True, 'pooling': True, 'd_in': 512, 'd_m': 256, 'd_out': 512}, 'weights': None, 'ignore_weights': [], 'seed': 42, 'base_lr': 0.001, 'step': [], 'optimizer': 'SGD', 'nesterov': True, 'weight_decay': 0.0005, 'lr_decay': 0.3, 'loss': 'clf', 'loss_weight': [0.051906303648995865, 0.05309306264474427, 0.1530458227235543, 0.08511251166595615, 0.04454378910255671, 0.13273265661186068, 0.27112258183452204, 0.07982394487907732], 'resume': '', 'backbone_only': True, 'pretrain': True, 'clf_only_epoch': 1}

[11.06.22|05:35:56] Training epoch: 0
[11.06.22|05:35:57] 	Iter 0 Done. | loss: 0 | lr: 0.001000
[11.06.22|05:41:07] 	Iter 1000 Done. | loss: 0 | lr: 0.001000
[11.06.22|05:43:08] 	mean_loss: 0.0
[11.06.22|05:43:08] Time consumption:
===> loss: 0.0
===> f1: [0.10696092 0.10086401 0.28348509 0.08599583 0.08527064 0.00137906
 0.03351319 0.10898164]
===> acc: [0.46220501 0.05519451 0.33113247 0.78445336 0.04474327 0.86649613
 0.72152701 0.65387629]
===> TP: [2.7950e+03 4.5990e+03 1.1483e+04 8.8000e+02 3.8640e+03 8.0000e+00
 4.1900e+02 1.8370e+03]
===> TN: [3.7317e+04 1.9100e+02 1.7254e+04 6.7198e+04 1.9000e+01 7.5190e+04
 6.2198e+04 5.4909e+04]
===> FN: [1.7090e+03 8.0000e+00 1.7990e+03 6.5070e+03 2.0000e+00 1.1512e+04
 2.3112e+04 5.0910e+03]
===> FP: [4.4963e+04 8.1986e+04 5.6248e+04 1.2199e+04 8.2899e+04 7.4000e+01
 1.0550e+03 2.4947e+04]
===> rec: [6.20559503e-01 9.98263512e-01 8.64553531e-01 1.19128198e-01
 9.99482669e-01 6.94444444e-04 1.78062981e-02 2.65155889e-01]
===> prec: [0.05852423 0.05311544 0.16953832 0.06728343 0.04453511 0.09756097
 0.28426052 0.06858572]
===> average f1: 0.1008062970527206
===> average acc: 0.48995350525442477
[11.06.22|05:43:14] Done.
[11.06.22|05:43:14] Eval epoch: 0
[11.06.22|05:46:38] 	mean_loss: 0.6547287583351136
===> loss: 0.6547287583351136
===> f1: [9.64220508e-02 2.87191512e-02 2.45302809e-01 3.31466181e-02
 7.03675107e-02 3.64972394e-04 3.07456931e-03 3.76715660e-01]
===> acc: [0.38545496 0.03327206 0.28189338 0.88069853 0.03648897 0.87414982
 0.67219669 0.79136029]
===> TP: [1.427e+03 6.220e+02 5.079e+03 8.900e+01 1.587e+03 1.000e+00 2.200e+01
 2.744e+03]
===> TN: [1.5348e+04 8.2600e+02 7.1890e+03 3.8239e+04 1.0000e+00 3.8042e+04
 2.9232e+04 3.1696e+04]
===> FN: [5.6600e+02 1.0000e+01 1.2060e+03 2.8510e+03 0.0000e+00 5.3150e+03
 1.2642e+04 1.8090e+03]
===> FP: [26179. 42062. 30046.  2341. 41932.   162.  1624.  7271.]
===> rec: [7.16006021e-01 9.84177215e-01 8.08114558e-01 3.02721088e-02
 1.00000000e+00 1.88111362e-04 1.73720783e-03 6.02679552e-01]
===> prec: [0.05169166 0.01457221 0.14459786 0.03662551 0.03646683 0.00613497
 0.01336574 0.27398902]
===> average f1: 0.10676416778582287
===> average acc: 0.49443933823529407
[11.06.22|05:46:41] Done.
[11.06.22|05:46:41] Training epoch: 1
[11.06.22|05:51:30] 	Iter 2000 Done. | loss: 0.2345 | lr: 0.001000
[11.06.22|05:56:59] 	mean_loss: 0.24358432071838407
[11.06.22|05:56:59] Time consumption:
===> loss: 0.24358432071838407
===> f1: [0.         0.03171075 0.01302924 0.         0.03037839 0.
 0.09025417 0.00509911]
===> acc: [0.94778992 0.92892699 0.84288579 0.91489215 0.94189021 0.86726816
 0.73657587 0.91906342]
===> TP: [   0.  101.   90.    0.   79.    0. 1134.   18.]
===> TN: [82253. 80515. 73059. 79398. 81662. 75265. 62789. 79742.]
===> FN: [ 4504.  4506. 13191.  7386.  3785. 11519. 22393.  6909.]
===> FP: [  27. 1662.  444.    0. 1258.    0.  468.  115.]
===> rec: [0.         0.02192316 0.0067766  0.         0.02044513 0.
 0.04819994 0.00259853]
===> prec: [0.         0.05728871 0.16853933 0.         0.05908751 0.
 0.70786517 0.13533834]
===> average f1: 0.021308957540257533
===> average acc: 0.8874115620390856
[11.06.22|05:57:05] Done.
[11.06.22|05:57:05] Eval epoch: 1
[11.06.22|06:00:26] 	mean_loss: 0.23366850531550454
===> loss: 0.23366850531550454
===> f1: [0.         0.         0.         0.         0.         0.
 0.39762429 0.        ]
===> acc: [0.95420496 0.98547794 0.85558364 0.93244485 0.96353401 0.87784926
 0.78090533 0.89538143]
===> TP: [   0.    0.    0.    0.    0.    0. 3147.    0.]
===> TN: [41527. 42888. 37235. 40580. 41933. 38204. 30838. 38967.]
===> FN: [1993.  632. 6285. 2940. 1587. 5316. 9517. 4553.]
===> FP: [ 0.  0.  0.  0.  0.  0. 18.  0.]
===> rec: [0.         0.         0.         0.         0.         0.
 0.24849968 0.        ]
===> prec: [0.        0.        0.        0.        0.        0.        0.9943128
 0.       ]
===> average f1: 0.04970303663597298
===> average acc: 0.9056726792279411
[11.06.22|06:00:28] Done.
[11.06.22|06:00:28] Training epoch: 2
[11.06.22|06:02:37] 	Iter 3000 Done. | loss: 0.2053 | lr: 0.001000
[11.06.22|06:10:04] 	Iter 4000 Done. | loss: 0.1193 | lr: 0.001000
[11.06.22|06:10:35] 	mean_loss: 0.16632775906858016
[11.06.22|06:10:35] Time consumption:
===> loss: 0.16632775906858016
===> f1: [0.00000000e+00 0.00000000e+00 3.42972372e-01 5.39446314e-03
 5.17330057e-04 1.90724209e-01 8.60501453e-01 0.00000000e+00]
===> acc: [0.94810103 0.94691418 0.87642883 0.9150189  0.95547566 0.87835315
 0.92794755 0.92018114]
===> TP: [0.0000e+00 0.0000e+00 2.7990e+03 2.0000e+01 1.0000e+00 1.2440e+03
 1.9286e+04 0.0000e+00]
===> TN: [82280. 82177. 73261. 79389. 82919. 74983. 61245. 79857.]
===> FN: [ 4504.  4607. 10483.  7367.  3864. 10276.  4242.  6927.]
===> FP: [   0.    0.  241.    8.    0.  281. 2011.    0.]
===> rec: [0.00000000e+00 0.00000000e+00 2.10736335e-01 2.70745905e-03
 2.58732212e-04 1.07986111e-01 8.19704182e-01 0.00000000e+00]
===> prec: [0.         0.         0.92072368 0.71428569 0.999999   0.8157377
 0.90557355 0.        ]
===> average f1: 0.17501372840312393
===> average acc: 0.921052555770649
[11.06.22|06:10:40] Done.
[11.06.22|06:10:40] Eval epoch: 2
[11.06.22|06:14:02] 	mean_loss: 0.19131594773361404
===> loss: 0.19131594773361404
===> f1: [0.         0.         0.087523   0.00474737 0.         0.64966531
 0.91428969 0.        ]
===> acc: [0.95420496 0.98547794 0.84237132 0.93255974 0.96353401 0.92171415
 0.94972426 0.89538143]
===> TP: [0.000e+00 0.000e+00 3.290e+02 7.000e+00 0.000e+00 3.159e+03 1.167e+04
 0.000e+00]
===> TN: [41527. 42888. 36331. 40578. 41933. 36954. 29662. 38967.]
===> FN: [1993.  632. 5956. 2933. 1587. 2157.  994. 4553.]
===> FP: [   0.    0.  904.    2.    0. 1250. 1194.    0.]
===> rec: [0.         0.         0.05234686 0.00238095 0.         0.59424379
 0.92150979 0.        ]
===> prec: [0.         0.         0.26682887 0.77777769 0.         0.716489
 0.90718284 0.        ]
===> average f1: 0.20702817179412236
===> average acc: 0.9306209788602942
[11.06.22|06:14:04] Done.
[11.06.22|06:14:04] Training epoch: 3
[11.06.22|06:21:01] 	Iter 5000 Done. | loss: 0.1210 | lr: 0.001000
[11.06.22|06:24:14] 	mean_loss: 0.10988035924172243
[11.06.22|06:24:14] Time consumption:
===> loss: 0.10988035924172243
===> f1: [4.43852197e-04 8.67678091e-04 8.43282222e-01 6.55609618e-01
 2.94700282e-01 7.63807126e-01 9.51067345e-01 0.00000000e+00]
===> acc: [0.94810103 0.9469257  0.95302129 0.95310195 0.96227415 0.94278899
 0.97370483 0.92016962]
===> TP: [1.0000e+00 2.0000e+00 1.0969e+04 3.8740e+03 6.8400e+02 8.0280e+03
 2.2177e+04 0.0000e+00]
===> TN: [82279. 82176. 71738. 78840. 82826. 73791. 62325. 79856.]
===> FN: [4504. 4606. 2313. 3513. 3182. 3491. 1354. 6928.]
===> FP: [   0.    0. 1764.  557.   92. 1474.  928.    0.]
===> rec: [2.21975583e-04 4.34027778e-04 8.25854540e-01 5.24434818e-01
 1.76927056e-01 6.96935498e-01 9.42458884e-01 0.00000000e+00]
===> prec: [0.999999   0.9999995  0.86146234 0.87429474 0.8814433  0.84487476
 0.95983553 0.        ]
===> average f1: 0.4387222651546323
===> average acc: 0.9500109467182891
[11.06.22|06:24:19] Done.
[11.06.22|06:24:19] Eval epoch: 3
[11.06.22|06:27:43] 	mean_loss: 0.19313492718673148
===> loss: 0.19313492718673148
===> f1: [0.         0.         0.37363321 0.40567459 0.11220344 0.67653511
 0.90895036 0.        ]
===> acc: [0.95420496 0.98547794 0.78405331 0.91240809 0.96472886 0.92267923
 0.94568015 0.89538143]
===> TP: [    0.     0.  2803.  1301.    97.  3519. 11800.     0.]
===> TN: [41527. 42888. 31319. 38407. 41888. 36636. 29356. 38967.]
===> FN: [1993.  632. 3482. 1639. 1490. 1797.  864. 4553.]
===> FP: [   0.    0. 5916. 2173.   45. 1568. 1500.    0.]
===> rec: [0.         0.         0.4459825  0.44251701 0.06112161 0.66196388
 0.93177511 0.        ]
===> prec: [0.         0.         0.32148182 0.37449626 0.68309859 0.69176332
 0.88721805 0.        ]
===> average f1: 0.3096245881529369
===> average acc: 0.9205767463235294
[11.06.22|06:27:45] Done.
[11.06.22|06:27:45] Training epoch: 4
[11.06.22|06:32:05] 	Iter 6000 Done. | loss: 0.0989 | lr: 0.001000
[11.06.22|06:37:54] 	mean_loss: 0.0804064638643446
[11.06.22|06:37:54] Time consumption:
===> loss: 0.0804064638643446
===> f1: [0.24113178 0.38582371 0.92117766 0.81240238 0.6657851  0.83996806
 0.96381789 0.1798335 ]
===> acc: [0.954888   0.95946257 0.9760094  0.97078955 0.97668925 0.96011938
 0.98046875 0.9272677 ]
===> TP: [  622.  1105. 12166.  5489.  2015.  9083. 22576.   692.]
===> TN: [82247. 82161. 72536. 78760. 82746. 74240. 62513. 79780.]
===> FN: [3883. 3503. 1116. 1898. 1850. 2437.  952. 6233.]
===> FP: [  32.   15.  966.  637.  173. 1024.  743.   79.]
===> rec: [0.13806881 0.23980035 0.91597651 0.74306214 0.52134541 0.78845486
 0.95953757 0.0999278 ]
===> prec: [0.95107033 0.98660714 0.92643923 0.89601698 0.92093236 0.89868408
 0.96813757 0.89753567]
===> average f1: 0.626242509167062
===> average acc: 0.9632118247603245
[11.06.22|06:38:00] Done.
[11.06.22|06:38:00] The model has been saved as ./work_dir/train/disfa/exp1/2/epoch5_model.pt.
[11.06.22|06:38:00] Eval epoch: 4
[11.06.22|06:41:29] 	mean_loss: 0.2058343609366121
===> loss: 0.2058343609366121
===> f1: [0.07976926 0.33678727 0.42145298 0.45174284 0.29243387 0.68668654
 0.85034426 0.        ]
===> acc: [0.95599724 0.98823529 0.79402574 0.90027574 0.95852482 0.91753217
 0.9037454  0.89538143]
===> TP: [   83.   130.  3265.  1788.   373.  3933. 11901.     0.]
===> TN: [41522. 42878. 31291. 37392. 41342. 35998. 27430. 38967.]
===> FN: [1910.  502. 3020. 1152. 1214. 1383.  763. 4553.]
===> FP: [5.000e+00 1.000e+01 5.944e+03 3.188e+03 5.910e+02 2.206e+03 3.426e+03
 0.000e+00]
===> rec: [0.04164576 0.2056962  0.51949085 0.60816327 0.23503466 0.73984199
 0.93975047 0.        ]
===> prec: [0.94318181 0.92857142 0.35454447 0.35932476 0.38692946 0.64065809
 0.77647289 0.        ]
===> average f1: 0.3899021269364903
===> average acc: 0.9142147288602941
[11.06.22|06:41:31] Done.
[11.06.22|06:41:31] Training epoch: 5
[11.06.22|06:43:11] 	Iter 7000 Done. | loss: 0.0599 | lr: 0.001000
[11.06.22|06:50:40] 	Iter 8000 Done. | loss: 0.0429 | lr: 0.001000
[11.06.22|06:51:41] 	mean_loss: 0.05843789288554352
[11.06.22|06:51:41] Time consumption:
===> loss: 0.05843789288554352
===> f1: [0.74971175 0.85121902 0.94412384 0.86823429 0.75556199 0.8974079
 0.96661909 0.60614639]
===> acc: [0.97744976 0.98594211 0.9830153  0.97876337 0.98189758 0.97354351
 0.98202434 0.95215708]
===> TP: [ 2931.  3490. 12453.  6072.  2428. 10042. 22587.  3195.]
===> TN: [81896. 82074. 72857. 78869. 82785. 74446. 62637. 79437.]
===> FN: [1573. 1117.  828. 1315. 1437. 1477.  942. 3733.]
===> FP: [384. 103. 646. 528. 134. 819. 618. 419.]
===> rec: [0.65075488 0.75754287 0.9376553  0.82198457 0.62820181 0.87177706
 0.9599643  0.46117206]
===> prec: [0.8841629  0.97133315 0.95068326 0.92       0.94769711 0.92459258
 0.97336781 0.88406198]
===> average f1: 0.8298780340628475
===> average acc: 0.9768491311762537
[11.06.22|06:51:47] Done.
[11.06.22|06:51:47] Eval epoch: 5
[11.06.22|06:55:11] 	mean_loss: 0.2099436036807567
===> loss: 0.2099436036807567
===> f1: [0.20576102 0.38294265 0.43310883 0.44664607 0.33354026 0.70776571
 0.87093626 0.08613437]
===> acc: [0.95565257 0.98304228 0.75969669 0.89478401 0.95078125 0.92451746
 0.91971507 0.90004596]
===> TP: [  250.   229.  3995.  1848.   536.  3978. 11789.   205.]
===> TN: [41340. 42553. 29067. 37093. 40842. 36257. 28237. 38965.]
===> FN: [1743.  403. 2290. 1092. 1051. 1338.  875. 4348.]
===> FP: [1.870e+02 3.350e+02 8.168e+03 3.487e+03 1.091e+03 1.947e+03 2.619e+03
 2.000e+00]
===> rec: [0.12543904 0.36234177 0.63564041 0.62857143 0.33774417 0.748307
 0.93090651 0.04502526]
===> prec: [0.57208238 0.40602837 0.32845515 0.34639175 0.32944069 0.6713924
 0.81822599 0.99033816]
===> average f1: 0.43335439658337066
===> average acc: 0.9110294117647059
[11.06.22|06:55:13] Done.
[11.06.22|06:55:13] Training epoch: 6
[11.06.22|07:01:39] 	Iter 9000 Done. | loss: 0.0267 | lr: 0.001000
[11.06.22|07:05:19] 	mean_loss: 0.04551857813525187
[11.06.22|07:05:19] Time consumption:
===> loss: 0.04551857813525187
===> f1: [0.80652177 0.8855854  0.95246329 0.9079449  0.78328455 0.92272153
 0.96868793 0.77947477]
===> acc: [0.98167865 0.9885578  0.98551576 0.98484744 0.98362601 0.97992718
 0.98315358 0.96939528]
===> TP: [ 3314.  3843. 12593.  6485.  2568. 10400. 22615.  4694.]
===> TN: [81880. 81948. 72934. 78984. 82795. 74642. 62707. 79434.]
===> FN: [1190.  765.  690.  901. 1298. 1119.  915. 2234.]
===> FP: [400. 228. 567. 414. 123. 623. 547. 422.]
===> rec: [0.73579041 0.83398438 0.9480539  0.87801246 0.66425246 0.90285615
 0.96111347 0.67754042]
===> prec: [0.89229941 0.9439941  0.95691489 0.9399913  0.95429208 0.94348181
 0.97638373 0.91751368]
===> average f1: 0.8758355174092087
===> average acc: 0.982087712020649
[11.06.22|07:05:24] Done.
[11.06.22|07:05:24] Eval epoch: 6
[11.06.22|07:08:49] 	mean_loss: 0.21362249234936076
===> loss: 0.21362249234936076
===> f1: [0.2479879  0.37468306 0.41439398 0.43087968 0.35089884 0.71457071
 0.86809777 0.21458549]
===> acc: [0.95275735 0.97729779 0.74535846 0.88752298 0.95273438 0.92451746
 0.91771599 0.90546875]
===> TP: [  339.   296.  3921.  1853.   556.  4112. 11784.   562.]
===> TN: [41125. 42236. 28517. 36772. 40907. 36123. 28155. 38844.]
===> FN: [1654.  336. 2364. 1087. 1031. 1204.  880. 3991.]
===> FP: [ 402.  652. 8718. 3808. 1026. 2081. 2701.  123.]
===> rec: [0.17009533 0.46835443 0.62386635 0.63027211 0.35034657 0.77351392
 0.93051169 0.1234351 ]
===> prec: [0.45748988 0.31223629 0.31023024 0.32732733 0.35145386 0.66397546
 0.81353124 0.82043796]
===> average f1: 0.45201217912295577
===> average acc: 0.9079216452205883
[11.06.22|07:08:51] Done.
[11.06.22|07:08:51] Training epoch: 7
[11.06.22|07:12:38] 	Iter 10000 Done. | loss: 0.0287 | lr: 0.001000
[11.06.22|07:18:59] 	mean_loss: 0.037607760124655776
[11.06.22|07:18:59] Time consumption:
===> loss: 0.037607760124655776
===> f1: [0.83687209 0.89950378 0.95916394 0.92857093 0.79945954 0.93709891
 0.9714673  0.8552989 ]
===> acc: [0.98442109 0.98972161 0.98752074 0.98808536 0.98459393 0.98360297
 0.98467459 0.97880946]
===> TP: [ 3468.  3992. 12719.  6721.  2665. 10600. 22642.  5435.]
===> TN: [81964. 81900. 72982. 79029. 82782. 74761. 62812. 79510.]
===> FN: [1035.  615.  562.  665. 1200.  920.  886. 1493.]
===> FP: [317. 277. 521. 369. 137. 503. 444. 346.]
===> rec: [0.77015323 0.86650749 0.95768391 0.9099648  0.68952135 0.92013889
 0.96234274 0.78449769]
===> prec: [0.91624835 0.93511361 0.96064955 0.94795487 0.95110635 0.95469693
 0.98076756 0.94014876]
===> average f1: 0.8984294232654095
===> average acc: 0.985178719579646
[11.06.22|07:19:05] Done.
[11.06.22|07:19:05] Eval epoch: 7
[11.06.22|07:22:29] 	mean_loss: 0.21254002397746424
===> loss: 0.21254002397746424
===> f1: [0.25893828 0.40106903 0.42616209 0.43132785 0.31153189 0.71850178
 0.85752766 0.23225051]
===> acc: [0.95475643 0.97941176 0.77401195 0.88421415 0.94993107 0.92329963
 0.91017923 0.90657169]
===> TP: [  344.   300.  3652.  1911.   493.  4260. 11764.   615.]
===> TN: [41207. 42324. 30033. 36570. 40848. 35922. 27847. 38839.]
===> FN: [1649.  332. 2633. 1029. 1094. 1056.  900. 3938.]
===> FP: [ 320.  564. 7202. 4010. 1085. 2282. 3009.  128.]
===> rec: [0.17260411 0.47468354 0.58106603 0.65       0.31064902 0.8013544
 0.92893241 0.13507577]
===> prec: [0.51807229 0.34722222 0.33646582 0.32274954 0.31242079 0.65117701
 0.79631761 0.82772544]
===> average f1: 0.45466363573120966
===> average acc: 0.910296989889706
[11.06.22|07:22:31] Done.
[11.06.22|07:22:31] Training epoch: 8
[11.06.22|07:23:39] 	Iter 11000 Done. | loss: 0.0404 | lr: 0.001000
[11.06.22|07:31:09] 	Iter 12000 Done. | loss: 0.0270 | lr: 0.001000
[11.06.22|07:32:40] 	mean_loss: 0.03231744239021609
[11.06.22|07:32:40] Time consumption:
===> loss: 0.03231744239021609
===> f1: [0.85878636 0.91639714 0.96576377 0.94330518 0.8159022  0.94910869
 0.9732776  0.89952687]
===> acc: [0.98642607 0.99134633 0.98953724 0.99047059 0.98570013 0.98670262
 0.98565404 0.98481287]
===> TP: [ 3582.  4116. 12807.  6880.  2750. 10761. 22673.  5900.]
===> TN: [82024. 81917. 73069. 79077. 82793. 74869. 62866. 79566.]
===> FN: [ 923.  492.  476.  507. 1116.  759.  857. 1027.]
===> FP: [255. 259. 432. 320. 125. 395. 388. 291.]
===> rec: [0.79511654 0.89322917 0.96416472 0.93136591 0.71132954 0.93411458
 0.96357841 0.85173957]
===> prec: [0.93354183 0.9408     0.96736914 0.95555556 0.95652174 0.96459304
 0.98317506 0.95299628]
===> average f1: 0.9152584768607426
===> average acc: 0.9875812361725663
[11.06.22|07:32:46] Done.
[11.06.22|07:32:46] Eval epoch: 8
[11.06.22|07:36:10] 	mean_loss: 0.22867018766597433
===> loss: 0.22867018766597433
===> f1: [0.24348312 0.24811096 0.42146775 0.40616978 0.31507243 0.69811884
 0.85496412 0.27994881]
===> acc: [0.94331342 0.95654871 0.76767004 0.87173713 0.95144761 0.91443015
 0.90863971 0.90898437]
===> TP: [  397.   312.  3683.  1909.   486.  4306. 11719.   770.]
===> TN: [40656. 41317. 29726. 36029. 40921. 35490. 27825. 38789.]
===> FN: [1596.  320. 2602. 1031. 1101. 1010.  945. 3783.]
===> FP: [ 871. 1571. 7509. 4551. 1012. 2714. 3031.  178.]
===> rec: [0.19919719 0.49367089 0.58599841 0.64931973 0.30623819 0.81000752
 0.92537903 0.16911926]
===> prec: [0.31309148 0.16569304 0.32907434 0.29551084 0.32443258 0.61339031
 0.79450847 0.81223629]
===> average f1: 0.43341697688451797
===> average acc: 0.9028463924632353
[11.06.22|07:36:12] Done.
[11.06.22|07:36:12] Training epoch: 9
[11.06.22|07:42:09] 	Iter 13000 Done. | loss: 0.0389 | lr: 0.001000
[11.06.22|07:46:20] 	mean_loss: 0.028456884308218144
[11.06.22|07:46:20] Time consumption:
===> loss: 0.028456884308218144
===> f1: [0.87658103 0.92543858 0.97031896 0.95309672 0.82254218 0.95395151
 0.97605409 0.92543744]
===> acc: [0.98808536 0.99222207 0.99094303 0.99209532 0.98610343 0.98797013
 0.98714049 0.98852323]
===> TP: [ 3672.  4189. 12848.  6970.  2795. 10814. 22745.  6181.]
===> TN: [82078. 81920. 73150. 79128. 82783. 74926. 62923. 79607.]
===> FN: [ 832.  418.  433.  417. 1070.  706.  786.  746.]
===> FP: [202. 257. 353. 269. 136. 338. 330. 250.]
===> rec: [0.81527531 0.9092685  0.96739703 0.94354948 0.72315653 0.93871528
 0.96659725 0.89230547]
===> prec: [0.94785751 0.94219523 0.9732596  0.96284017 0.95359945 0.96969154
 0.98569881 0.9611258 ]
===> average f1: 0.9254275639632028
===> average acc: 0.9891353820980826
[11.06.22|07:46:26] Done.
[11.06.22|07:46:26] The model has been saved as ./work_dir/train/disfa/exp1/2/epoch10_model.pt.
[11.06.22|07:46:26] Eval epoch: 9
[11.06.22|07:49:49] 	mean_loss: 0.2264735734619856
===> loss: 0.2264735734619856
===> f1: [0.28909761 0.34200699 0.42918171 0.39888812 0.37913754 0.68254941
 0.8444677  0.33672051]
===> acc: [0.94620864 0.97153033 0.76376379 0.86578585 0.95431985 0.909375
 0.89970129 0.91001838]
===> TP: [  476.   322.  3865.  1938.   607.  4240. 11850.   994.]
===> TN: [40703. 41959. 29374. 35741. 40925. 35336. 27305. 38610.]
===> FN: [1517.  310. 2420. 1002.  980. 1076.  814. 3559.]
===> FP: [ 824.  929. 7861. 4839. 1008. 2868. 3551.  357.]
===> rec: [0.23883593 0.50949367 0.61495625 0.65918367 0.38248267 0.79759217
 0.93572331 0.21831759]
===> prec: [0.36615385 0.25739408 0.32960941 0.28596724 0.37585139 0.59651097
 0.76943056 0.73575129]
===> average f1: 0.4627562004638121
===> average acc: 0.902587890625
[11.06.22|07:49:51] Done.
[11.06.22|07:49:51] Training epoch: 10
[11.06.22|07:53:08] 	Iter 14000 Done. | loss: 0.0047 | lr: 0.001000
[11.06.22|07:59:58] 	mean_loss: 0.025374330707123794
[11.06.22|07:59:58] Time consumption:
===> loss: 0.025374330707123794
===> f1: [0.89434898 0.94254336 0.97262551 0.96054372 0.83632074 0.96060169
 0.97890263 0.93303555]
===> acc: [0.98974465 0.99396202 0.99164593 0.99331674 0.98705983 0.98968704
 0.9886615  0.9896179 ]
===> TP: [ 3767.  4298. 12880.  7060.  2869. 10911. 22829.  6277.]
===> TN: [82127. 81962. 73179. 79144. 82792. 74978. 62971. 79606.]
===> FN: [736. 308. 402. 327. 997. 608. 701. 651.]
===> FP: [154. 216. 323. 253. 126. 287. 283. 250.]
===> rec: [0.83655341 0.9331307  0.96973347 0.95573304 0.74211071 0.94721764
 0.97020824 0.90603349]
===> prec: [0.9607243  0.95214887 0.97553586 0.96540407 0.95792988 0.97437042
 0.98775528 0.96169756]
===> average f1: 0.9348652736291155
===> average acc: 0.9904619515117994
[11.06.22|08:00:04] Done.
[11.06.22|08:00:04] Eval epoch: 10
[11.06.22|08:03:29] 	mean_loss: 0.24035620349660508
===> loss: 0.24035620349660508
===> f1: [0.26666618 0.2810731  0.47420579 0.38025727 0.3933717  0.64763132
 0.83080056 0.29752314]
===> acc: [0.92265625 0.95321691 0.78196232 0.84967831 0.95457261 0.89110754
 0.89099265 0.90549173]
===> TP: [  612.   398.  4279.  2007.   641.  4355. 11647.   871.]
===> TN: [39542. 41086. 29752. 34971. 40902. 34426. 27129. 38536.]
===> FN: [1381.  234. 2006.  933.  946.  961. 1017. 3682.]
===> FP: [1985. 1802. 7483. 5609. 1031. 3778. 3727.  431.]
===> rec: [0.30707476 0.62974684 0.68082737 0.68265306 0.40390674 0.81922498
 0.91969362 0.19130244]
===> prec: [0.23565653 0.18090909 0.36379867 0.26352416 0.38337321 0.53547277
 0.75757773 0.66897081]
===> average f1: 0.4464411308138281
===> average acc: 0.8937097886029413
[11.06.22|08:03:31] Done.
[11.06.22|08:03:31] Training epoch: 11
[11.06.22|08:04:09] 	Iter 15000 Done. | loss: 0.0120 | lr: 0.001000
[11.06.22|08:11:39] 	Iter 16000 Done. | loss: 0.0207 | lr: 0.001000
[11.06.22|08:13:40] 	mean_loss: 0.022748087094629672
[11.06.22|08:13:40] Time consumption:
===> loss: 0.022748087094629672
===> f1: [0.91193596 0.9493375  0.97617917 0.9660044  0.84579661 0.9652678
 0.98150714 0.94350982]
===> acc: [0.99131176 0.99466492 0.9927406  0.99423857 0.98773968 0.99090846
 0.99004425 0.99117349]
===> TP: [ 3904.  4338. 12909.  7104.  2918. 10964. 22929.  6397.]
===> TN: [82126. 81983. 73245. 79180. 82802. 75031. 62991. 79621.]
===> FN: [601. 270. 373. 283. 948. 556. 602. 531.]
===> FP: [153. 193. 257. 217. 116. 233. 262. 235.]
===> rec: [0.86659267 0.94140625 0.97191688 0.96168945 0.75478531 0.95173611
 0.97441673 0.9233545 ]
===> prec: [0.9622874  0.95740455 0.98048002 0.97035924 0.96176664 0.97919085
 0.98870251 0.96456574]
===> average f1: 0.9424423013334233
===> average acc: 0.9916027147861357
[11.06.22|08:13:46] Done.
[11.06.22|08:13:46] Eval epoch: 11
[11.06.22|08:17:09] 	mean_loss: 0.23212932658207136
===> loss: 0.23212932658207136
===> f1: [0.23289745 0.2797971  0.449148   0.39680853 0.39686634 0.69908099
 0.85660287 0.29375687]
===> acc: [0.92038143 0.96403952 0.76440717 0.86622243 0.95753676 0.91794577
 0.90926011 0.90199908]
===> TP: [  526.   304.  4180.  1915.   608.  4148. 11795.   887.]
===> TN: [39529. 41651. 29087. 35783. 41064. 35801. 27776. 38368.]
===> FN: [1467.  328. 2105. 1025.  979. 1168.  869. 3666.]
===> FP: [1998. 1237. 8148. 4797.  869. 2403. 3080.  599.]
===> rec: [0.26392373 0.48101266 0.66507558 0.65136054 0.38311279 0.78028593
 0.93138029 0.1948166 ]
===> prec: [0.20839937 0.1972745  0.33906554 0.28530989 0.41164523 0.63318577
 0.79294118 0.59690444]
===> average f1: 0.4506197684637051
===> average acc: 0.9002240349264705
[11.06.22|08:17:11] Done.
[11.06.22|08:17:11] Training epoch: 12
[11.06.22|08:22:36] 	Iter 17000 Done. | loss: 0.0136 | lr: 0.001000
[11.06.22|08:27:15] 	mean_loss: 0.02050394476181896
[11.06.22|08:27:15] Time consumption:
===> loss: 0.02050394476181896
===> f1: [0.9224532  0.95683403 0.97791986 0.97093526 0.85098953 0.96842612
 0.9836495  0.95382081]
===> acc: [0.99227968 0.99543695 0.99325913 0.99506822 0.98811993 0.99173811
 0.99118501 0.99275212]
===> TP: [ 3985.  4389. 12955.  7149.  2944. 10996. 23012.  6496.]
===> TN: [82129. 81999. 73244. 79207. 82809. 75071. 63007. 79659.]
===> FN: [518. 217. 327. 237. 922. 523. 518. 431.]
===> FP: [152. 179. 258. 191. 109. 194. 247. 198.]
===> rec: [0.88496558 0.95288754 0.97538021 0.96791227 0.76151061 0.95459675
 0.97798555 0.9377797 ]
===> prec: [0.9632584  0.96081436 0.98047378 0.9739782  0.96429741 0.98266309
 0.98938045 0.97042127]
===> average f1: 0.9481285396012682
===> average acc: 0.9924798926069321
[11.06.22|08:27:21] Done.
[11.06.22|08:27:21] Eval epoch: 12
[11.06.22|08:30:44] 	mean_loss: 0.2337671583388863
===> loss: 0.2337671583388863
===> f1: [0.24130831 0.31475371 0.45253591 0.37532738 0.40839111 0.673601
 0.83974935 0.25367301]
===> acc: [0.91475184 0.96158088 0.78995864 0.86316636 0.96112132 0.90266544
 0.89813879 0.89846048]
===> TP: [  590.   384.  3778.  1789.   584.  4371. 11615.   751.]
===> TN: [39220. 41464. 30601. 35776. 41244. 34913. 27472. 38350.]
===> FN: [1403.  248. 2507. 1151. 1003.  945. 1049. 3802.]
===> FP: [2307. 1424. 6634. 4804.  689. 3291. 3384.  617.]
===> rec: [0.29603613 0.60759494 0.60111376 0.6085034  0.36798992 0.82223476
 0.91716677 0.16494619]
===> prec: [0.20365896 0.21238938 0.36285056 0.2713484  0.45875884 0.57047768
 0.77438496 0.54897661]
===> average f1: 0.44491747396596965
===> average acc: 0.89873046875
[11.06.22|08:30:46] Done.
[11.06.22|08:30:46] Training epoch: 13
[11.06.22|08:33:32] 	Iter 18000 Done. | loss: 0.0295 | lr: 0.001000
[11.06.22|08:40:51] 	mean_loss: 0.018664249946853655
[11.06.22|08:40:51] Time consumption:
===> loss: 0.018664249946853655
===> f1: [0.93609622 0.95992109 0.98060075 0.97520499 0.85697792 0.97277276
 0.98616753 0.95900808]
===> acc: [0.99360481 0.99575959 0.99408877 0.99579416 0.98854628 0.99286735
 0.99253319 0.99355872]
===> TP: [ 4065.  4407. 12966.  7178.  2978. 11058. 23100.  6539.]
===> TN: [82164. 82009. 73305. 79241. 82812. 75107. 63036. 79686.]
===> FN: [440. 201. 315. 208. 888. 460. 429. 388.]
===> FP: [115. 167. 198. 157. 106. 159. 219. 171.]
===> rec: [0.90233074 0.95638021 0.97628191 0.97183861 0.77030523 0.96006251
 0.98176718 0.9439873 ]
===> prec: [0.97248804 0.96348929 0.98495898 0.97859577 0.96562905 0.98582509
 0.99060852 0.97451565]
===> average f1: 0.9533436667841638
===> average acc: 0.993344107208702
[11.06.22|08:40:57] Done.
[11.06.22|08:40:57] Eval epoch: 13
[11.06.22|08:44:20] 	mean_loss: 0.2433608231934319
===> loss: 0.2433608231934319
===> f1: [0.20205369 0.33234671 0.45227387 0.37273893 0.43397474 0.66003989
 0.80973739 0.26122001]
===> acc: [0.90181526 0.96888787 0.78639706 0.85893842 0.96217831 0.89940257
 0.87357537 0.89901195]
===> TP: [  541.   337.  3838.  1824.   631.  4250. 11708.   777.]
===> TN: [38706. 41829. 30386. 35557. 41243. 34892. 26310. 38348.]
===> FN: [1452.  295. 2447. 1116.  956. 1066.  956. 3776.]
===> FP: [2821. 1059. 6849. 5023.  690. 3312. 4546.  619.]
===> rec: [0.27145008 0.53322785 0.6106603  0.62040816 0.39760555 0.79947329
 0.92451042 0.17065671]
===> prec: [0.16091612 0.24140401 0.35912791 0.26639404 0.47766843 0.56202063
 0.720315   0.55659026]
===> average f1: 0.44054815425330435
===> average acc: 0.8937758501838234
[11.06.22|08:44:23] Done.
[11.06.22|08:44:23] Training epoch: 14
[11.06.22|08:44:30] 	Iter 19000 Done. | loss: 0.0375 | lr: 0.001000
[11.06.22|08:51:58] 	Iter 20000 Done. | loss: 0.0156 | lr: 0.001000
[11.06.22|08:54:31] 	mean_loss: 0.017375424881771365
[11.06.22|08:54:31] Time consumption:
===> loss: 0.017375424881771365
===> f1: [0.94137842 0.96260715 0.98237069 0.97818799 0.86282314 0.97299146
 0.9887391  0.9627674 ]
===> acc: [0.99411182 0.99604766 0.99463035 0.99630116 0.98894958 0.99291344
 0.99391593 0.99413486]
===> TP: [ 4103.  4415. 12984.  7198.  3016. 11078. 23181.  6581.]
===> TN: [82170. 82026. 73334. 79265. 82809. 75091. 63075. 79694.]
===> FN: [402. 193. 297. 189. 850. 442. 348. 345.]
===> FP: [109. 150. 169. 132. 109. 173. 180. 164.]
===> rec: [0.91076582 0.95811632 0.97763723 0.97441451 0.78013451 0.96163194
 0.98520974 0.9501877 ]
===> prec: [0.97412156 0.96714129 0.98715122 0.98199181 0.96512    0.98462359
 0.99229485 0.97568569]
===> average f1: 0.9564831689520765
===> average acc: 0.9938755991887906
[11.06.22|08:54:36] Done.
[11.06.22|08:54:37] The model has been saved as ./work_dir/train/disfa/exp1/2/epoch15_model.pt.
[11.06.22|08:54:37] Eval epoch: 14
[11.06.22|08:58:03] 	mean_loss: 0.2211806394279098
===> loss: 0.2211806394279098
===> f1: [0.20813478 0.37354828 0.49198593 0.38201735 0.43179328 0.68243249
 0.88280229 0.27869927]
===> acc: [0.8966682  0.97148437 0.80772059 0.86417739 0.96353401 0.90990349
 0.92851562 0.90211397]
===> TP: [  591.   370.  4052.  1827.   603.  4213. 11717.   823.]
===> TN: [38432. 41909. 31100. 35782. 41330. 35386. 28692. 38437.]
===> FN: [1402.  262. 2233. 1113.  984. 1103.  947. 3730.]
===> FP: [3095.  979. 6135. 4798.  603. 2818. 2164.  530.]
===> rec: [0.29653788 0.58544304 0.64470963 0.62142857 0.37996219 0.79251317
 0.9252211  0.18075994]
===> prec: [0.16033641 0.27427724 0.39776185 0.27577358 0.5        0.59920353
 0.84410345 0.6082779 ]
===> average f1: 0.46642670819800447
===> average acc: 0.9055147058823529
[11.06.22|08:58:05] Done.
[11.24.22|12:58:31] odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'fc.weight', 'fc.bias'])
[11.24.22|13:12:23] dict_keys(['encoder.0.weight', 'encoder.1.weight', 'encoder.1.bias', 'encoder.1.running_mean', 'encoder.1.running_var', 'encoder.1.num_batches_tracked', 'encoder.4.0.conv1.weight', 'encoder.4.0.bn1.weight', 'encoder.4.0.bn1.bias', 'encoder.4.0.bn1.running_mean', 'encoder.4.0.bn1.running_var', 'encoder.4.0.bn1.num_batches_tracked', 'encoder.4.0.conv2.weight', 'encoder.4.0.bn2.weight', 'encoder.4.0.bn2.bias', 'encoder.4.0.bn2.running_mean', 'encoder.4.0.bn2.running_var', 'encoder.4.0.bn2.num_batches_tracked', 'encoder.4.1.conv1.weight', 'encoder.4.1.bn1.weight', 'encoder.4.1.bn1.bias', 'encoder.4.1.bn1.running_mean', 'encoder.4.1.bn1.running_var', 'encoder.4.1.bn1.num_batches_tracked', 'encoder.4.1.conv2.weight', 'encoder.4.1.bn2.weight', 'encoder.4.1.bn2.bias', 'encoder.4.1.bn2.running_mean', 'encoder.4.1.bn2.running_var', 'encoder.4.1.bn2.num_batches_tracked', 'encoder.4.2.conv1.weight', 'encoder.4.2.bn1.weight', 'encoder.4.2.bn1.bias', 'encoder.4.2.bn1.running_mean', 'encoder.4.2.bn1.running_var', 'encoder.4.2.bn1.num_batches_tracked', 'encoder.4.2.conv2.weight', 'encoder.4.2.bn2.weight', 'encoder.4.2.bn2.bias', 'encoder.4.2.bn2.running_mean', 'encoder.4.2.bn2.running_var', 'encoder.4.2.bn2.num_batches_tracked', 'encoder.5.0.conv1.weight', 'encoder.5.0.bn1.weight', 'encoder.5.0.bn1.bias', 'encoder.5.0.bn1.running_mean', 'encoder.5.0.bn1.running_var', 'encoder.5.0.bn1.num_batches_tracked', 'encoder.5.0.conv2.weight', 'encoder.5.0.bn2.weight', 'encoder.5.0.bn2.bias', 'encoder.5.0.bn2.running_mean', 'encoder.5.0.bn2.running_var', 'encoder.5.0.bn2.num_batches_tracked', 'encoder.5.0.downsample.0.weight', 'encoder.5.0.downsample.1.weight', 'encoder.5.0.downsample.1.bias', 'encoder.5.0.downsample.1.running_mean', 'encoder.5.0.downsample.1.running_var', 'encoder.5.0.downsample.1.num_batches_tracked', 'encoder.5.1.conv1.weight', 'encoder.5.1.bn1.weight', 'encoder.5.1.bn1.bias', 'encoder.5.1.bn1.running_mean', 'encoder.5.1.bn1.running_var', 'encoder.5.1.bn1.num_batches_tracked', 'encoder.5.1.conv2.weight', 'encoder.5.1.bn2.weight', 'encoder.5.1.bn2.bias', 'encoder.5.1.bn2.running_mean', 'encoder.5.1.bn2.running_var', 'encoder.5.1.bn2.num_batches_tracked', 'encoder.5.2.conv1.weight', 'encoder.5.2.bn1.weight', 'encoder.5.2.bn1.bias', 'encoder.5.2.bn1.running_mean', 'encoder.5.2.bn1.running_var', 'encoder.5.2.bn1.num_batches_tracked', 'encoder.5.2.conv2.weight', 'encoder.5.2.bn2.weight', 'encoder.5.2.bn2.bias', 'encoder.5.2.bn2.running_mean', 'encoder.5.2.bn2.running_var', 'encoder.5.2.bn2.num_batches_tracked', 'encoder.5.3.conv1.weight', 'encoder.5.3.bn1.weight', 'encoder.5.3.bn1.bias', 'encoder.5.3.bn1.running_mean', 'encoder.5.3.bn1.running_var', 'encoder.5.3.bn1.num_batches_tracked', 'encoder.5.3.conv2.weight', 'encoder.5.3.bn2.weight', 'encoder.5.3.bn2.bias', 'encoder.5.3.bn2.running_mean', 'encoder.5.3.bn2.running_var', 'encoder.5.3.bn2.num_batches_tracked', 'encoder.6.0.conv1.weight', 'encoder.6.0.bn1.weight', 'encoder.6.0.bn1.bias', 'encoder.6.0.bn1.running_mean', 'encoder.6.0.bn1.running_var', 'encoder.6.0.bn1.num_batches_tracked', 'encoder.6.0.conv2.weight', 'encoder.6.0.bn2.weight', 'encoder.6.0.bn2.bias', 'encoder.6.0.bn2.running_mean', 'encoder.6.0.bn2.running_var', 'encoder.6.0.bn2.num_batches_tracked', 'encoder.6.0.downsample.0.weight', 'encoder.6.0.downsample.1.weight', 'encoder.6.0.downsample.1.bias', 'encoder.6.0.downsample.1.running_mean', 'encoder.6.0.downsample.1.running_var', 'encoder.6.0.downsample.1.num_batches_tracked', 'encoder.6.1.conv1.weight', 'encoder.6.1.bn1.weight', 'encoder.6.1.bn1.bias', 'encoder.6.1.bn1.running_mean', 'encoder.6.1.bn1.running_var', 'encoder.6.1.bn1.num_batches_tracked', 'encoder.6.1.conv2.weight', 'encoder.6.1.bn2.weight', 'encoder.6.1.bn2.bias', 'encoder.6.1.bn2.running_mean', 'encoder.6.1.bn2.running_var', 'encoder.6.1.bn2.num_batches_tracked', 'encoder.6.2.conv1.weight', 'encoder.6.2.bn1.weight', 'encoder.6.2.bn1.bias', 'encoder.6.2.bn1.running_mean', 'encoder.6.2.bn1.running_var', 'encoder.6.2.bn1.num_batches_tracked', 'encoder.6.2.conv2.weight', 'encoder.6.2.bn2.weight', 'encoder.6.2.bn2.bias', 'encoder.6.2.bn2.running_mean', 'encoder.6.2.bn2.running_var', 'encoder.6.2.bn2.num_batches_tracked', 'encoder.6.3.conv1.weight', 'encoder.6.3.bn1.weight', 'encoder.6.3.bn1.bias', 'encoder.6.3.bn1.running_mean', 'encoder.6.3.bn1.running_var', 'encoder.6.3.bn1.num_batches_tracked', 'encoder.6.3.conv2.weight', 'encoder.6.3.bn2.weight', 'encoder.6.3.bn2.bias', 'encoder.6.3.bn2.running_mean', 'encoder.6.3.bn2.running_var', 'encoder.6.3.bn2.num_batches_tracked', 'encoder.6.4.conv1.weight', 'encoder.6.4.bn1.weight', 'encoder.6.4.bn1.bias', 'encoder.6.4.bn1.running_mean', 'encoder.6.4.bn1.running_var', 'encoder.6.4.bn1.num_batches_tracked', 'encoder.6.4.conv2.weight', 'encoder.6.4.bn2.weight', 'encoder.6.4.bn2.bias', 'encoder.6.4.bn2.running_mean', 'encoder.6.4.bn2.running_var', 'encoder.6.4.bn2.num_batches_tracked', 'encoder.6.5.conv1.weight', 'encoder.6.5.bn1.weight', 'encoder.6.5.bn1.bias', 'encoder.6.5.bn1.running_mean', 'encoder.6.5.bn1.running_var', 'encoder.6.5.bn1.num_batches_tracked', 'encoder.6.5.conv2.weight', 'encoder.6.5.bn2.weight', 'encoder.6.5.bn2.bias', 'encoder.6.5.bn2.running_mean', 'encoder.6.5.bn2.running_var', 'encoder.6.5.bn2.num_batches_tracked', 'encoder.7.0.conv1.weight', 'encoder.7.0.bn1.weight', 'encoder.7.0.bn1.bias', 'encoder.7.0.bn1.running_mean', 'encoder.7.0.bn1.running_var', 'encoder.7.0.bn1.num_batches_tracked', 'encoder.7.0.conv2.weight', 'encoder.7.0.bn2.weight', 'encoder.7.0.bn2.bias', 'encoder.7.0.bn2.running_mean', 'encoder.7.0.bn2.running_var', 'encoder.7.0.bn2.num_batches_tracked', 'encoder.7.0.downsample.0.weight', 'encoder.7.0.downsample.1.weight', 'encoder.7.0.downsample.1.bias', 'encoder.7.0.downsample.1.running_mean', 'encoder.7.0.downsample.1.running_var', 'encoder.7.0.downsample.1.num_batches_tracked', 'encoder.7.1.conv1.weight', 'encoder.7.1.bn1.weight', 'encoder.7.1.bn1.bias', 'encoder.7.1.bn1.running_mean', 'encoder.7.1.bn1.running_var', 'encoder.7.1.bn1.num_batches_tracked', 'encoder.7.1.conv2.weight', 'encoder.7.1.bn2.weight', 'encoder.7.1.bn2.bias', 'encoder.7.1.bn2.running_mean', 'encoder.7.1.bn2.running_var', 'encoder.7.1.bn2.num_batches_tracked', 'encoder.7.2.conv1.weight', 'encoder.7.2.bn1.weight', 'encoder.7.2.bn1.bias', 'encoder.7.2.bn1.running_mean', 'encoder.7.2.bn1.running_var', 'encoder.7.2.bn1.num_batches_tracked', 'encoder.7.2.conv2.weight', 'encoder.7.2.bn2.weight', 'encoder.7.2.bn2.bias', 'encoder.7.2.bn2.running_mean', 'encoder.7.2.bn2.running_var', 'encoder.7.2.bn2.num_batches_tracked'])
[11.24.22|13:17:11] odict_keys(['encoder.0.weight', 'encoder.1.weight', 'encoder.1.bias', 'encoder.1.running_mean', 'encoder.1.running_var', 'encoder.1.num_batches_tracked', 'encoder.4.0.conv1.weight', 'encoder.4.0.bn1.weight', 'encoder.4.0.bn1.bias', 'encoder.4.0.bn1.running_mean', 'encoder.4.0.bn1.running_var', 'encoder.4.0.bn1.num_batches_tracked', 'encoder.4.0.conv2.weight', 'encoder.4.0.bn2.weight', 'encoder.4.0.bn2.bias', 'encoder.4.0.bn2.running_mean', 'encoder.4.0.bn2.running_var', 'encoder.4.0.bn2.num_batches_tracked', 'encoder.4.1.conv1.weight', 'encoder.4.1.bn1.weight', 'encoder.4.1.bn1.bias', 'encoder.4.1.bn1.running_mean', 'encoder.4.1.bn1.running_var', 'encoder.4.1.bn1.num_batches_tracked', 'encoder.4.1.conv2.weight', 'encoder.4.1.bn2.weight', 'encoder.4.1.bn2.bias', 'encoder.4.1.bn2.running_mean', 'encoder.4.1.bn2.running_var', 'encoder.4.1.bn2.num_batches_tracked', 'encoder.4.2.conv1.weight', 'encoder.4.2.bn1.weight', 'encoder.4.2.bn1.bias', 'encoder.4.2.bn1.running_mean', 'encoder.4.2.bn1.running_var', 'encoder.4.2.bn1.num_batches_tracked', 'encoder.4.2.conv2.weight', 'encoder.4.2.bn2.weight', 'encoder.4.2.bn2.bias', 'encoder.4.2.bn2.running_mean', 'encoder.4.2.bn2.running_var', 'encoder.4.2.bn2.num_batches_tracked', 'encoder.5.0.conv1.weight', 'encoder.5.0.bn1.weight', 'encoder.5.0.bn1.bias', 'encoder.5.0.bn1.running_mean', 'encoder.5.0.bn1.running_var', 'encoder.5.0.bn1.num_batches_tracked', 'encoder.5.0.conv2.weight', 'encoder.5.0.bn2.weight', 'encoder.5.0.bn2.bias', 'encoder.5.0.bn2.running_mean', 'encoder.5.0.bn2.running_var', 'encoder.5.0.bn2.num_batches_tracked', 'encoder.5.0.downsample.0.weight', 'encoder.5.0.downsample.1.weight', 'encoder.5.0.downsample.1.bias', 'encoder.5.0.downsample.1.running_mean', 'encoder.5.0.downsample.1.running_var', 'encoder.5.0.downsample.1.num_batches_tracked', 'encoder.5.1.conv1.weight', 'encoder.5.1.bn1.weight', 'encoder.5.1.bn1.bias', 'encoder.5.1.bn1.running_mean', 'encoder.5.1.bn1.running_var', 'encoder.5.1.bn1.num_batches_tracked', 'encoder.5.1.conv2.weight', 'encoder.5.1.bn2.weight', 'encoder.5.1.bn2.bias', 'encoder.5.1.bn2.running_mean', 'encoder.5.1.bn2.running_var', 'encoder.5.1.bn2.num_batches_tracked', 'encoder.5.2.conv1.weight', 'encoder.5.2.bn1.weight', 'encoder.5.2.bn1.bias', 'encoder.5.2.bn1.running_mean', 'encoder.5.2.bn1.running_var', 'encoder.5.2.bn1.num_batches_tracked', 'encoder.5.2.conv2.weight', 'encoder.5.2.bn2.weight', 'encoder.5.2.bn2.bias', 'encoder.5.2.bn2.running_mean', 'encoder.5.2.bn2.running_var', 'encoder.5.2.bn2.num_batches_tracked', 'encoder.5.3.conv1.weight', 'encoder.5.3.bn1.weight', 'encoder.5.3.bn1.bias', 'encoder.5.3.bn1.running_mean', 'encoder.5.3.bn1.running_var', 'encoder.5.3.bn1.num_batches_tracked', 'encoder.5.3.conv2.weight', 'encoder.5.3.bn2.weight', 'encoder.5.3.bn2.bias', 'encoder.5.3.bn2.running_mean', 'encoder.5.3.bn2.running_var', 'encoder.5.3.bn2.num_batches_tracked', 'encoder.6.0.conv1.weight', 'encoder.6.0.bn1.weight', 'encoder.6.0.bn1.bias', 'encoder.6.0.bn1.running_mean', 'encoder.6.0.bn1.running_var', 'encoder.6.0.bn1.num_batches_tracked', 'encoder.6.0.conv2.weight', 'encoder.6.0.bn2.weight', 'encoder.6.0.bn2.bias', 'encoder.6.0.bn2.running_mean', 'encoder.6.0.bn2.running_var', 'encoder.6.0.bn2.num_batches_tracked', 'encoder.6.0.downsample.0.weight', 'encoder.6.0.downsample.1.weight', 'encoder.6.0.downsample.1.bias', 'encoder.6.0.downsample.1.running_mean', 'encoder.6.0.downsample.1.running_var', 'encoder.6.0.downsample.1.num_batches_tracked', 'encoder.6.1.conv1.weight', 'encoder.6.1.bn1.weight', 'encoder.6.1.bn1.bias', 'encoder.6.1.bn1.running_mean', 'encoder.6.1.bn1.running_var', 'encoder.6.1.bn1.num_batches_tracked', 'encoder.6.1.conv2.weight', 'encoder.6.1.bn2.weight', 'encoder.6.1.bn2.bias', 'encoder.6.1.bn2.running_mean', 'encoder.6.1.bn2.running_var', 'encoder.6.1.bn2.num_batches_tracked', 'encoder.6.2.conv1.weight', 'encoder.6.2.bn1.weight', 'encoder.6.2.bn1.bias', 'encoder.6.2.bn1.running_mean', 'encoder.6.2.bn1.running_var', 'encoder.6.2.bn1.num_batches_tracked', 'encoder.6.2.conv2.weight', 'encoder.6.2.bn2.weight', 'encoder.6.2.bn2.bias', 'encoder.6.2.bn2.running_mean', 'encoder.6.2.bn2.running_var', 'encoder.6.2.bn2.num_batches_tracked', 'encoder.6.3.conv1.weight', 'encoder.6.3.bn1.weight', 'encoder.6.3.bn1.bias', 'encoder.6.3.bn1.running_mean', 'encoder.6.3.bn1.running_var', 'encoder.6.3.bn1.num_batches_tracked', 'encoder.6.3.conv2.weight', 'encoder.6.3.bn2.weight', 'encoder.6.3.bn2.bias', 'encoder.6.3.bn2.running_mean', 'encoder.6.3.bn2.running_var', 'encoder.6.3.bn2.num_batches_tracked', 'encoder.6.4.conv1.weight', 'encoder.6.4.bn1.weight', 'encoder.6.4.bn1.bias', 'encoder.6.4.bn1.running_mean', 'encoder.6.4.bn1.running_var', 'encoder.6.4.bn1.num_batches_tracked', 'encoder.6.4.conv2.weight', 'encoder.6.4.bn2.weight', 'encoder.6.4.bn2.bias', 'encoder.6.4.bn2.running_mean', 'encoder.6.4.bn2.running_var', 'encoder.6.4.bn2.num_batches_tracked', 'encoder.6.5.conv1.weight', 'encoder.6.5.bn1.weight', 'encoder.6.5.bn1.bias', 'encoder.6.5.bn1.running_mean', 'encoder.6.5.bn1.running_var', 'encoder.6.5.bn1.num_batches_tracked', 'encoder.6.5.conv2.weight', 'encoder.6.5.bn2.weight', 'encoder.6.5.bn2.bias', 'encoder.6.5.bn2.running_mean', 'encoder.6.5.bn2.running_var', 'encoder.6.5.bn2.num_batches_tracked', 'encoder.7.0.conv1.weight', 'encoder.7.0.bn1.weight', 'encoder.7.0.bn1.bias', 'encoder.7.0.bn1.running_mean', 'encoder.7.0.bn1.running_var', 'encoder.7.0.bn1.num_batches_tracked', 'encoder.7.0.conv2.weight', 'encoder.7.0.bn2.weight', 'encoder.7.0.bn2.bias', 'encoder.7.0.bn2.running_mean', 'encoder.7.0.bn2.running_var', 'encoder.7.0.bn2.num_batches_tracked', 'encoder.7.0.downsample.0.weight', 'encoder.7.0.downsample.1.weight', 'encoder.7.0.downsample.1.bias', 'encoder.7.0.downsample.1.running_mean', 'encoder.7.0.downsample.1.running_var', 'encoder.7.0.downsample.1.num_batches_tracked', 'encoder.7.1.conv1.weight', 'encoder.7.1.bn1.weight', 'encoder.7.1.bn1.bias', 'encoder.7.1.bn1.running_mean', 'encoder.7.1.bn1.running_var', 'encoder.7.1.bn1.num_batches_tracked', 'encoder.7.1.conv2.weight', 'encoder.7.1.bn2.weight', 'encoder.7.1.bn2.bias', 'encoder.7.1.bn2.running_mean', 'encoder.7.1.bn2.running_var', 'encoder.7.1.bn2.num_batches_tracked', 'encoder.7.2.conv1.weight', 'encoder.7.2.bn1.weight', 'encoder.7.2.bn1.bias', 'encoder.7.2.bn1.running_mean', 'encoder.7.2.bn1.running_var', 'encoder.7.2.bn1.num_batches_tracked', 'encoder.7.2.conv2.weight', 'encoder.7.2.bn2.weight', 'encoder.7.2.bn2.bias', 'encoder.7.2.bn2.running_mean', 'encoder.7.2.bn2.running_var', 'encoder.7.2.bn2.num_batches_tracked', 'projector.weight', 'projector.bias', 'subject_attention.kmap.weight', 'subject_attention.kmap.bias', 'subject_attention.qmap.weight', 'subject_attention.qmap.bias', 'subject_attention.xmap.weight', 'subject_attention.xmap.bias', 'subject_attention.smap.weight', 'subject_attention.smap.bias', 'final.0.weight', 'final.0.bias', 'final.2.weight', 'final.2.bias'])
[11.24.22|13:47:21] Sequential(
  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (5): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (6): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (7): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (8): AdaptiveAvgPool2d(output_size=(1, 1))
)
[11.24.22|15:22:21] Parameters:
{'work_dir': './work_dir/train/disfa/exp1/2', 'config': './config/exp1/train2.yaml', 'phase': 'train', 'save_result': False, 'start_epoch': 0, 'num_epoch': 15, 'use_gpu': True, 'device': [0], 'log_interval': 1000, 'save_interval': 5, 'eval_interval': 1, 'save_log': True, 'print_log': True, 'pavi_log': False, 'feeder': 'feeder.feeder_image_causal.Feeder', 'num_worker': 0, 'train_feeder_args': {'label_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/train2_label.pkl', 'image_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/train2_imagepath.pkl', 'image_size': 256, 'istrain': True, 'debug': True}, 'test_feeder_args': {'label_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/test2_label.pkl', 'image_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/test2_imagepath.pkl', 'image_size': 256, 'istrain': False, 'debug': True}, 'batch_size': 4, 'test_batch_size': 4, 'debug': True, 'model': 'net.CISNet.Model', 'model_args': {'num_class': 8, 'backbone': 'resnet34', 'temporal_model': 'single', 'subject': True, 'pooling': True, 'd_in': 512, 'd_m': 256, 'd_out': 512}, 'weights': None, 'ignore_weights': [], 'seed': 42, 'base_lr': 0.001, 'step': [], 'optimizer': 'SGD', 'nesterov': True, 'weight_decay': 0.0005, 'lr_decay': 0.3, 'loss': 'clf', 'loss_weight': [0.051906303648995865, 0.05309306264474427, 0.1530458227235543, 0.08511251166595615, 0.04454378910255671, 0.13273265661186068, 0.27112258183452204, 0.07982394487907732], 'resume': '', 'pretrain': True, 'clf_only_epoch': 1}

[11.24.22|15:22:21] Training epoch: 0
[11.24.22|16:45:00] Parameters:
{'work_dir': './work_dir/train/disfa/exp1/2', 'config': './config/exp1/train2.yaml', 'phase': 'train', 'save_result': False, 'start_epoch': 0, 'num_epoch': 15, 'use_gpu': True, 'device': [0], 'log_interval': 1000, 'save_interval': 5, 'eval_interval': 1, 'save_log': True, 'print_log': True, 'pavi_log': False, 'feeder': 'feeder.feeder_image_causal.Feeder', 'num_worker': 0, 'train_feeder_args': {'label_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/train2_label.pkl', 'image_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/train2_imagepath.pkl', 'image_size': 256, 'istrain': True, 'debug': True}, 'test_feeder_args': {'label_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/test2_label.pkl', 'image_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random1/test2_imagepath.pkl', 'image_size': 256, 'istrain': False, 'debug': True}, 'batch_size': 4, 'test_batch_size': 4, 'debug': True, 'model': 'net.CISNet.Model', 'model_args': {'num_class': 8, 'backbone': 'resnet34', 'temporal_model': 'single', 'subject': True, 'pooling': True, 'd_in': 512, 'd_m': 256, 'd_out': 512}, 'weights': None, 'ignore_weights': [], 'seed': 42, 'base_lr': 0.001, 'step': [], 'optimizer': 'SGD', 'nesterov': True, 'weight_decay': 0.0005, 'lr_decay': 0.3, 'loss': 'clf', 'loss_weight': [0.051906303648995865, 0.05309306264474427, 0.1530458227235543, 0.08511251166595615, 0.04454378910255671, 0.13273265661186068, 0.27112258183452204, 0.07982394487907732], 'resume': '', 'pretrain': True, 'clf_only_epoch': 1}

[11.24.22|16:45:00] Training epoch: 0
