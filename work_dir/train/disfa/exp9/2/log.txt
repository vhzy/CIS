[11.26.22|01:40:15] Parameters:
{'work_dir': './work_dir/train/disfa/exp9/2', 'config': './config/exp9/train2.yaml', 'phase': 'train', 'save_result': False, 'start_epoch': 0, 'num_epoch': 15, 'use_gpu': True, 'device': [0], 'log_interval': 1000, 'save_interval': 5, 'eval_interval': 1, 'save_log': True, 'print_log': True, 'pavi_log': False, 'feeder': 'feeder.feeder_image_causal.Feeder', 'num_worker': 0, 'train_feeder_args': {'label_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random2.1/train2_label.pkl', 'image_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random2.1/train2_imagepath.pkl', 'image_size': 256, 'istrain': True, 'debug': False}, 'test_feeder_args': {'label_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random2.1/test2_label.pkl', 'image_path': '/home/hfut1609/Disk_sda/hzy/faceAU/CIS/data/DISFA/list_random2.1/test2_imagepath.pkl', 'image_size': 256, 'istrain': False, 'debug': False}, 'batch_size': 4, 'test_batch_size': 4, 'debug': False, 'model': 'net.causal_net.CAUSAL_NET', 'model_args': {'num_class': 8, 'backbone': 'resnet34', 'temporal_model': 'single', 'subject': True, 'pooling': True, 'd_in': 512, 'd_m': 256, 'd_out': 512}, 'weights': None, 'ignore_weights': [], 'seed': 42, 'base_lr': 0.001, 'step': [], 'optimizer': 'SGD', 'nesterov': True, 'weight_decay': 0.0005, 'lr_decay': 0.3, 'loss': 'clf', 'loss_weight': [0.05369158447783206, 0.0474237256890036, 0.16668586966540694, 0.09179417457830215, 0.04902525578394322, 0.14209835007834823, 0.2926191354041847, 0.07640105078809106], 'resume': '', 'pretrain': True, 'clf_only_epoch': 1, 'branch_loss_weight': 0.33}

[11.26.22|01:40:15] Training epoch: 0
[11.26.22|01:40:16] 	Iter 0 Done. | loss: 0.8811 | lr: 0.001000
[11.26.22|01:41:22] 	Iter 1000 Done. | loss: 0.3845 | lr: 0.001000
[11.26.22|01:42:27] 	Iter 2000 Done. | loss: 0.2487 | lr: 0.001000
[11.26.22|01:43:32] 	Iter 3000 Done. | loss: 0.1850 | lr: 0.001000
[11.26.22|01:44:37] 	Iter 4000 Done. | loss: 0.0744 | lr: 0.001000
[11.26.22|01:45:41] 	Iter 5000 Done. | loss: 0.0126 | lr: 0.001000
[11.26.22|01:46:46] 	Iter 6000 Done. | loss: 0.1767 | lr: 0.001000
[11.26.22|01:47:52] 	Iter 7000 Done. | loss: 0.2465 | lr: 0.001000
[11.26.22|01:48:56] 	Iter 8000 Done. | loss: 0.1307 | lr: 0.001000
[11.26.22|01:50:01] 	Iter 9000 Done. | loss: 0.0907 | lr: 0.001000
[11.26.22|01:51:06] 	Iter 10000 Done. | loss: 0.0098 | lr: 0.001000
[11.26.22|01:52:10] 	Iter 11000 Done. | loss: 0.0064 | lr: 0.001000
[11.26.22|01:53:16] 	Iter 12000 Done. | loss: 0.1433 | lr: 0.001000
[11.26.22|01:54:21] 	Iter 13000 Done. | loss: 0.0031 | lr: 0.001000
[11.26.22|01:55:25] 	Iter 14000 Done. | loss: 0.1154 | lr: 0.001000
[11.26.22|01:56:30] 	Iter 15000 Done. | loss: 0.0159 | lr: 0.001000
[11.26.22|01:57:35] 	Iter 16000 Done. | loss: 0.0585 | lr: 0.001000
[11.26.22|01:58:39] 	Iter 17000 Done. | loss: 0.0195 | lr: 0.001000
[11.26.22|01:59:44] 	Iter 18000 Done. | loss: 0.1113 | lr: 0.001000
[11.26.22|02:00:48] 	Iter 19000 Done. | loss: 0.0071 | lr: 0.001000
[11.26.22|02:01:52] 	Iter 20000 Done. | loss: 0.0045 | lr: 0.001000
[11.26.22|02:03:00] 	Iter 21000 Done. | loss: 0.0891 | lr: 0.001000
[11.26.22|02:03:46] 	mean_loss: 0.1407102312681601
[11.26.22|02:03:46] Time consumption:
===> loss: 0.1407102312681601
===> f1: [0.60510911 0.65972897 0.83681277 0.77548224 0.61716554 0.74290121
 0.93740799 0.56909098]
===> acc: [0.96491612 0.9736266  0.94921191 0.96155176 0.96952484 0.93542032
 0.9645359  0.94901604]
===> TP: [ 2333.  2219. 11302.  5763.  2132.  8098. 23049.  2922.]
===> TN: [81414. 82284. 71082. 77692. 82015. 73089. 60665. 79445.]
===> FN: [2327. 1897. 3165. 2204. 2123. 4235. 2348. 3709.]
===> FP: [ 718.  392. 1243. 1133.  522. 1370.  730.  716.]
===> rec: [0.50064378 0.53911565 0.78122624 0.72335886 0.50105758 0.65661234
 0.90754814 0.44065752]
===> prec: [0.76466732 0.84986595 0.9009167  0.83570186 0.80331575 0.85530207
 0.96930064 0.80318856]
===> average f1: 0.7179623527540511
===> average acc: 0.9584754355240115
[11.26.22|02:03:51] Done.
[11.26.22|02:03:51] Eval epoch: 0
[11.26.22|02:06:56] 	mean_loss: 0.14578911944590867
===> loss: 0.14578911944590867
===> f1: [0.31578899 0.20706904 0.57027453 0.45293323 0.38312453 0.72855085
 0.92959337 0.56817116]
===> acc: [0.95076662 0.92740084 0.87052424 0.94050679 0.95469152 0.95127158
 0.96669574 0.91131105]
===> TP: [ 495.  413. 3743. 1073.  613. 2849. 9579. 2542.]
===> TN: [40928. 39992. 34184. 39903. 40981. 38596. 32538. 37162.]
===> FN: [1340.  708. 1376. 1287.  605. 1654. 1271. 2360.]
===> FP: [ 805. 2455. 4265. 1305. 1369.  469.  180. 1504.]
===> rec: [0.26975477 0.36842105 0.7311975  0.45466102 0.50328407 0.63268932
 0.88285714 0.51856385]
===> prec: [0.38076923 0.14400279 0.46740759 0.45121951 0.30928355 0.85864979
 0.98155549 0.62827484]
===> average f1: 0.5194382111351962
===> average acc: 0.9341460475578406
[11.26.22|02:06:58] Done.
[11.26.22|02:06:58] Training epoch: 1
[11.26.22|02:07:17] 	Iter 22000 Done. | loss: 0.0602 | lr: 0.001000
[11.26.22|02:08:20] 	Iter 23000 Done. | loss: 0.2644 | lr: 0.001000
[11.26.22|02:09:22] 	Iter 24000 Done. | loss: 0.2043 | lr: 0.001000
[11.26.22|02:10:22] 	Iter 25000 Done. | loss: 0.0041 | lr: 0.001000
[11.26.22|02:11:25] 	Iter 26000 Done. | loss: 0.0275 | lr: 0.001000
[11.26.22|02:12:29] 	Iter 27000 Done. | loss: 0.0215 | lr: 0.001000
[11.26.22|02:13:34] 	Iter 28000 Done. | loss: 0.2261 | lr: 0.001000
[11.26.22|02:14:41] 	Iter 29000 Done. | loss: 0.0027 | lr: 0.001000
[11.26.22|02:15:45] 	Iter 30000 Done. | loss: 0.1696 | lr: 0.001000
[11.26.22|02:16:49] 	Iter 31000 Done. | loss: 0.1477 | lr: 0.001000
[11.26.22|02:17:55] 	Iter 32000 Done. | loss: 0.0032 | lr: 0.001000
[11.26.22|02:19:03] 	Iter 33000 Done. | loss: 0.2478 | lr: 0.001000
[11.26.22|02:20:08] 	Iter 34000 Done. | loss: 0.0262 | lr: 0.001000
[11.26.22|02:21:19] 	Iter 35000 Done. | loss: 0.0373 | lr: 0.001000
[11.26.22|02:22:26] 	Iter 36000 Done. | loss: 0.1561 | lr: 0.001000
[11.26.22|02:23:31] 	Iter 37000 Done. | loss: 0.0098 | lr: 0.001000
[11.26.22|02:24:35] 	Iter 38000 Done. | loss: 0.2210 | lr: 0.001000
[11.26.22|02:25:39] 	Iter 39000 Done. | loss: 0.0154 | lr: 0.001000
[11.26.22|02:26:43] 	Iter 40000 Done. | loss: 0.0003 | lr: 0.001000
[11.26.22|02:27:47] 	Iter 41000 Done. | loss: 0.0007 | lr: 0.001000
[11.26.22|02:28:51] 	Iter 42000 Done. | loss: 0.1254 | lr: 0.001000
[11.26.22|02:29:56] 	Iter 43000 Done. | loss: 0.0012 | lr: 0.001000
[11.26.22|02:30:21] 	mean_loss: 0.05974996159755121
[11.26.22|02:30:21] Time consumption:
===> loss: 0.05974996159755121
===> f1: [0.83706461 0.89438894 0.93915312 0.91653393 0.87920987 0.90950751
 0.97631685 0.86370018]
===> acc: [0.98365057 0.99041386 0.9800212  0.98484883 0.98872016 0.97454835
 0.98617384 0.9800212 ]
===> TP: [ 3645.  3523. 13382.  7220.  3563. 11101. 24735.  5494.]
===> TN: [81728. 82437. 71676. 78257. 82250. 73482. 60857. 79564.]
===> FN: [1015.  593. 1085.  747.  692. 1232.  662. 1137.]
===> FP: [404. 239. 649. 568. 287. 977. 538. 597.]
===> rec: [0.78218884 0.85592809 0.92500173 0.90623823 0.8373678  0.90010541
 0.97393393 0.82853265]
===> prec: [0.90022228 0.93646996 0.95374528 0.92706728 0.92545455 0.91910912
 0.97871246 0.90198654]
===> average f1: 0.9019843754823609
===> average acc: 0.9835497511291363
[11.26.22|02:30:26] Done.
[11.26.22|02:30:26] Eval epoch: 1
[11.26.22|02:33:33] 	mean_loss: 0.13470738443158958
===> loss: 0.13470738443158958
===> f1: [0.55240853 0.4984307  0.63386204 0.394401   0.35402106 0.6760809
 0.92872937 0.57755334]
===> acc: [0.97206665 0.97431601 0.88301047 0.93346034 0.95317664 0.933139
 0.96607602 0.90185457]
===> TP: [ 751.  556. 4412.  944.  559. 3040. 9630. 2923.]
===> TN: [41600. 41893. 34059. 39725. 40969. 37615. 32460. 36369.]
===> FN: [1084.  565.  707. 1416.  659. 1463. 1220. 1979.]
===> FP: [ 133.  554. 4390. 1483. 1381. 1450.  258. 2297.]
===> rec: [0.40926431 0.49598573 0.86188709 0.4        0.4589491  0.67510549
 0.8875576  0.59628723]
===> prec: [0.84954751 0.5009009  0.50124972 0.38895756 0.28814433 0.67706013
 0.97390777 0.55996169]
===> average f1: 0.5769358684995713
===> average acc: 0.9396374632757988
[11.26.22|02:33:35] Done.
[11.26.22|02:33:35] Training epoch: 2
[11.26.22|02:34:11] 	Iter 44000 Done. | loss: 0.0025 | lr: 0.001000
[11.26.22|02:35:11] 	Iter 45000 Done. | loss: 0.1280 | lr: 0.001000
[11.26.22|02:36:11] 	Iter 46000 Done. | loss: 0.3189 | lr: 0.001000
[11.26.22|02:37:14] 	Iter 47000 Done. | loss: 0.0485 | lr: 0.001000
[11.26.22|02:38:18] 	Iter 48000 Done. | loss: 0.1515 | lr: 0.001000
[11.26.22|02:39:23] 	Iter 49000 Done. | loss: 0.0013 | lr: 0.001000
[11.26.22|02:40:31] 	Iter 50000 Done. | loss: 0.0114 | lr: 0.001000
[11.26.22|02:41:37] 	Iter 51000 Done. | loss: 0.0100 | lr: 0.001000
[11.26.22|02:42:41] 	Iter 52000 Done. | loss: 0.3283 | lr: 0.001000
[11.26.22|02:43:46] 	Iter 53000 Done. | loss: 0.0705 | lr: 0.001000
[11.26.22|02:44:51] 	Iter 54000 Done. | loss: 0.0197 | lr: 0.001000
[11.26.22|02:45:56] 	Iter 55000 Done. | loss: 0.0051 | lr: 0.001000
[11.26.22|02:47:00] 	Iter 56000 Done. | loss: 0.0304 | lr: 0.001000
[11.26.22|02:48:05] 	Iter 57000 Done. | loss: 0.0089 | lr: 0.001000
[11.26.22|02:49:11] 	Iter 58000 Done. | loss: 0.0004 | lr: 0.001000
[11.26.22|02:50:16] 	Iter 59000 Done. | loss: 0.0016 | lr: 0.001000
[11.26.22|02:51:21] 	Iter 60000 Done. | loss: 0.0068 | lr: 0.001000
[11.26.22|02:52:27] 	Iter 61000 Done. | loss: 0.0023 | lr: 0.001000
[11.26.22|02:53:33] 	Iter 62000 Done. | loss: 0.0031 | lr: 0.001000
[11.26.22|02:54:42] 	Iter 63000 Done. | loss: 0.0343 | lr: 0.001000
[11.26.22|02:55:53] 	Iter 64000 Done. | loss: 0.1094 | lr: 0.001000
[11.26.22|02:57:04] 	Iter 65000 Done. | loss: 0.1275 | lr: 0.001000
[11.26.22|02:57:10] 	mean_loss: 0.04377854875180467
[11.26.22|02:57:10] Time consumption:
===> loss: 0.04377854875180467
===> f1: [0.89624576 0.92648112 0.95424969 0.9356831  0.91529905 0.9343382
 0.98103038 0.9001619 ]
===> acc: [0.98920407 0.99322518 0.98490644 0.98827081 0.99196931 0.98143838
 0.98891603 0.98512536]
===> TP: [ 4047.  3705. 13662.  7405.  3766. 11462. 24876.  5820.]
===> TN: [81808. 82499. 71820. 78369. 82329. 73719. 60954. 79681.]
===> FN: [613. 411. 805. 562. 489. 871. 521. 811.]
===> FP: [324. 177. 505. 456. 208. 740. 441. 480.]
===> rec: [0.86845494 0.90014577 0.94435612 0.92945902 0.88507638 0.92937647
 0.97948577 0.87769567]
===> prec: [0.92587509 0.95440495 0.96435378 0.94199211 0.94765979 0.9393542
 0.98258087 0.92380952]
===> average f1: 0.930436150638748
===> average acc: 0.9878819476449442
[11.26.22|02:57:15] Done.
[11.26.22|02:57:15] Eval epoch: 2
[11.26.22|03:00:27] 	mean_loss: 0.12907422392301704
===> loss: 0.12907422392301704
===> f1: [0.65064272 0.66609318 0.63107323 0.36700062 0.38164072 0.6885648
 0.94337627 0.55850291]
===> acc: [0.97631289 0.98216581 0.88532868 0.9348375  0.94897631 0.93667371
 0.97227323 0.91062248]
===> TP: [  961.   775.  4273.   823.   686.  3050. 10063.  2463.]
===> TN: [41575. 42016. 34299. 39906. 40659. 37759. 32297. 37211.]
===> FN: [ 874.  346.  846. 1537.  532. 1453.  787. 2439.]
===> FP: [ 158.  431. 4150. 1302. 1691. 1306.  421. 1455.]
===> rec: [0.52370572 0.69134701 0.83473335 0.34872881 0.56321839 0.67732623
 0.92746544 0.50244798]
===> prec: [0.8588025  0.64262023 0.50730144 0.38729412 0.28859907 0.70018365
 0.95984357 0.62863706]
===> average f1: 0.6108618060845661
===> average acc: 0.94339882482556
[11.26.22|03:00:29] Done.
[11.26.22|03:00:29] Training epoch: 3
[11.26.22|03:01:26] 	Iter 66000 Done. | loss: 0.0007 | lr: 0.001000
[11.26.22|03:02:32] 	Iter 67000 Done. | loss: 0.0302 | lr: 0.001000
[11.26.22|03:03:37] 	Iter 68000 Done. | loss: 0.0020 | lr: 0.001000
[11.26.22|03:04:41] 	Iter 69000 Done. | loss: 0.0016 | lr: 0.001000
[11.26.22|03:05:49] 	Iter 70000 Done. | loss: 0.0009 | lr: 0.001000
[11.26.22|03:06:55] 	Iter 71000 Done. | loss: 0.0187 | lr: 0.001000
[11.26.22|03:07:58] 	Iter 72000 Done. | loss: 0.0428 | lr: 0.001000
[11.26.22|03:09:02] 	Iter 73000 Done. | loss: 0.0005 | lr: 0.001000
[11.26.22|03:10:06] 	Iter 74000 Done. | loss: 0.0015 | lr: 0.001000
[11.26.22|03:11:10] 	Iter 75000 Done. | loss: 0.0063 | lr: 0.001000
[11.26.22|03:12:15] 	Iter 76000 Done. | loss: 0.1045 | lr: 0.001000
[11.26.22|03:13:20] 	Iter 77000 Done. | loss: 0.0202 | lr: 0.001000
[11.26.22|03:14:24] 	Iter 78000 Done. | loss: 0.0019 | lr: 0.001000
[11.26.22|03:15:26] 	Iter 79000 Done. | loss: 0.0023 | lr: 0.001000
[11.26.22|03:16:31] 	Iter 80000 Done. | loss: 0.0854 | lr: 0.001000
[11.26.22|03:17:39] 	Iter 81000 Done. | loss: 0.0029 | lr: 0.001000
[11.26.22|03:18:48] 	Iter 82000 Done. | loss: 0.0012 | lr: 0.001000
[11.26.22|03:19:52] 	Iter 83000 Done. | loss: 0.0881 | lr: 0.001000
[11.26.22|03:20:57] 	Iter 84000 Done. | loss: 0.1492 | lr: 0.001000
[11.26.22|03:22:02] 	Iter 85000 Done. | loss: 0.1296 | lr: 0.001000
[11.26.22|03:23:06] 	Iter 86000 Done. | loss: 0.0026 | lr: 0.001000
[11.26.22|03:23:59] 	mean_loss: 0.03678710590138464
[11.26.22|03:23:59] Time consumption:
===> loss: 0.03678710590138464
===> f1: [0.91655695 0.93567201 0.96004965 0.94456657 0.93169448 0.94662219
 0.9824183  0.91782037]
===> acc: [0.99119735 0.99404323 0.9867845  0.98987234 0.99346714 0.98489492
 0.98972256 0.98769472]
===> TP: [ 4196.  3760. 13782.  7489.  3867. 11625. 24922.  5964.]
===> TN: [81832. 82515. 71863. 78424. 82358. 73856. 60978. 79760.]
===> FN: [464. 356. 685. 478. 388. 708. 475. 667.]
===> FP: [300. 161. 462. 401. 179. 603. 417. 401.]
===> rec: [0.90042918 0.91350826 0.95265086 0.94000251 0.90881316 0.94259304
 0.981297   0.89941185]
===> prec: [0.93327402 0.95893905 0.96756529 0.94917617 0.95575877 0.95068695
 0.98354315 0.93699921]
===> average f1: 0.9419250651566805
===> average acc: 0.9897095930500507
[11.26.22|03:24:04] Done.
[11.26.22|03:24:04] Eval epoch: 3
[11.26.22|03:27:10] 	mean_loss: 0.12795407658794355
===> loss: 0.12795407658794355
===> f1: [0.69924517 0.5524398  0.66231242 0.420337   0.50294861 0.69219169
 0.94280384 0.56882221]
===> acc: [0.97895244 0.98021484 0.89437202 0.9392903  0.97872292 0.93412596
 0.97229618 0.89366048]
===> TP: [1066.  532. 4513.  959.  469. 3227. 9948. 3056.]
===> TN: [41585. 42174. 34453. 39964. 42172. 37471. 32413. 35879.]
===> FN: [ 769.  589.  606. 1401.  749. 1276.  902. 1846.]
===> FP: [ 148.  273. 3996. 1244.  178. 1594.  305. 2787.]
===> rec: [0.58092643 0.47457627 0.8816175  0.40635593 0.38505747 0.71663336
 0.91686636 0.62341901]
===> prec: [0.87808896 0.66086956 0.5303796  0.43531548 0.72488408 0.6693632
 0.97025261 0.523019  ]
===> average f1: 0.6301375933244494
===> average acc: 0.9464543931325744
[11.26.22|03:27:12] Done.
[11.26.22|03:27:12] Training epoch: 4
[11.26.22|03:27:25] 	Iter 87000 Done. | loss: 0.0015 | lr: 0.001000
[11.26.22|03:28:27] 	Iter 88000 Done. | loss: 0.0100 | lr: 0.001000
[11.26.22|03:29:40] 	Iter 89000 Done. | loss: 0.1280 | lr: 0.001000
[11.26.22|03:30:47] 	Iter 90000 Done. | loss: 0.0022 | lr: 0.001000
[11.26.22|03:31:53] 	Iter 91000 Done. | loss: 0.0014 | lr: 0.001000
[11.26.22|03:32:57] 	Iter 92000 Done. | loss: 0.0783 | lr: 0.001000
[11.26.22|03:34:08] 	Iter 93000 Done. | loss: 0.0015 | lr: 0.001000
[11.26.22|03:35:12] 	Iter 94000 Done. | loss: 0.0163 | lr: 0.001000
[11.26.22|03:36:17] 	Iter 95000 Done. | loss: 0.0013 | lr: 0.001000
[11.26.22|03:37:22] 	Iter 96000 Done. | loss: 0.0145 | lr: 0.001000
[11.26.22|03:38:26] 	Iter 97000 Done. | loss: 0.0132 | lr: 0.001000
[11.26.22|03:39:30] 	Iter 98000 Done. | loss: 0.0492 | lr: 0.001000
[11.26.22|03:40:34] 	Iter 99000 Done. | loss: 0.0295 | lr: 0.001000
[11.26.22|03:41:40] 	Iter 100000 Done. | loss: 0.0002 | lr: 0.001000
[11.26.22|03:42:45] 	Iter 101000 Done. | loss: 0.0011 | lr: 0.001000
[11.26.22|03:43:51] 	Iter 102000 Done. | loss: 0.0875 | lr: 0.001000
[11.26.22|03:45:02] 	Iter 103000 Done. | loss: 0.0016 | lr: 0.001000
[11.26.22|03:46:15] 	Iter 104000 Done. | loss: 0.0189 | lr: 0.001000
[11.26.22|03:47:22] 	Iter 105000 Done. | loss: 0.0543 | lr: 0.001000
[11.26.22|03:48:34] 	Iter 106000 Done. | loss: 0.0005 | lr: 0.001000
[11.26.22|03:49:40] 	Iter 107000 Done. | loss: 0.0094 | lr: 0.001000
[11.26.22|03:50:50] 	Iter 108000 Done. | loss: 0.0002 | lr: 0.001000
[11.26.22|03:51:22] 	mean_loss: 0.03187548792334142
[11.26.22|03:51:22] Time consumption:
===> loss: 0.03187548792334142
===> f1: [0.93956472 0.94557521 0.96417206 0.9526324  0.94347672 0.95346332
 0.98393374 0.93169265]
===> acc: [0.99359388 0.99491889 0.98814407 0.99133561 0.99453867 0.98679602
 0.99060973 0.98969951]
===> TP: [ 4322.  3831. 13846.  7562.  3956. 11740. 24957.  6097.]
===> TN: [81914. 82520. 71917. 78478. 82362. 73906. 61020. 79801.]
===> FN: [338. 285. 621. 405. 299. 593. 440. 534.]
===> FP: [218. 156. 408. 347. 175. 553. 375. 360.]
===> rec: [0.92746781 0.93075802 0.95707472 0.94916531 0.92972973 0.95191762
 0.98267512 0.91946916]
===> prec: [0.95198238 0.96087284 0.97137646 0.95612593 0.95763738 0.95501505
 0.98519659 0.94424655]
===> average f1: 0.9518138533961383
===> average acc: 0.9912045465019816
[11.26.22|03:51:27] Done.
[11.26.22|03:51:27] The model has been saved as ./work_dir/train/disfa/exp9/2/epoch5_model.pt.
[11.26.22|03:51:27] Eval epoch: 4
[11.26.22|03:54:32] 	mean_loss: 0.14582315787941502
===> loss: 0.14582315787941502
===> f1: [0.66730782 0.50692614 0.63876886 0.29056641 0.33352522 0.60872161
 0.94657017 0.57964718]
===> acc: [0.97619813 0.97794253 0.88250551 0.92905343 0.94697943 0.91144877
 0.97410944 0.89703452]
===> TP: [1040.  494. 4526.  633.  578. 3001. 9992. 3093.]
===> TN: [41491. 42113. 33923. 39844. 40680. 36709. 32448. 35989.]
===> FN: [ 795.  627.  593. 1727.  640. 1502.  858. 1809.]
===> FP: [ 242.  334. 4526. 1364. 1670. 2356.  270. 2677.]
===> rec: [0.56675749 0.44067797 0.88415706 0.26822034 0.47454844 0.66644459
 0.92092166 0.63096695]
===> prec: [0.81123245 0.59661836 0.5        0.31697546 0.25711744 0.56020161
 0.97368934 0.53604853]
===> average f1: 0.5715041767462365
===> average acc: 0.936908969886155
[11.26.22|03:54:35] Done.
[11.26.22|03:54:35] Training epoch: 5
[11.26.22|03:55:05] 	Iter 109000 Done. | loss: 0.0048 | lr: 0.001000
[11.26.22|03:56:07] 	Iter 110000 Done. | loss: 0.0111 | lr: 0.001000
[11.26.22|03:57:11] 	Iter 111000 Done. | loss: 0.0195 | lr: 0.001000
[11.26.22|03:58:16] 	Iter 112000 Done. | loss: 0.0685 | lr: 0.001000
[11.26.22|03:59:20] 	Iter 113000 Done. | loss: 0.3857 | lr: 0.001000
[11.26.22|04:00:24] 	Iter 114000 Done. | loss: 0.0153 | lr: 0.001000
[11.26.22|04:01:29] 	Iter 115000 Done. | loss: 0.0021 | lr: 0.001000
[11.26.22|04:02:34] 	Iter 116000 Done. | loss: 0.0031 | lr: 0.001000
[11.26.22|04:03:38] 	Iter 117000 Done. | loss: 0.0016 | lr: 0.001000
[11.26.22|04:04:43] 	Iter 118000 Done. | loss: 0.0896 | lr: 0.001000
[11.26.22|04:05:47] 	Iter 119000 Done. | loss: 0.1746 | lr: 0.001000
[11.26.22|04:06:53] 	Iter 120000 Done. | loss: 0.0033 | lr: 0.001000
[11.26.22|04:07:58] 	Iter 121000 Done. | loss: 0.0004 | lr: 0.001000
[11.26.22|04:09:03] 	Iter 122000 Done. | loss: 0.0428 | lr: 0.001000
[11.26.22|04:10:08] 	Iter 123000 Done. | loss: 0.0065 | lr: 0.001000
[11.26.22|04:11:13] 	Iter 124000 Done. | loss: 0.0328 | lr: 0.001000
[11.26.22|04:12:17] 	Iter 125000 Done. | loss: 0.1218 | lr: 0.001000
[11.26.22|04:13:25] 	Iter 126000 Done. | loss: 0.1267 | lr: 0.001000
[11.26.22|04:14:29] 	Iter 127000 Done. | loss: 0.0050 | lr: 0.001000
[11.26.22|04:15:34] 	Iter 128000 Done. | loss: 0.1676 | lr: 0.001000
[11.26.22|04:16:39] 	Iter 129000 Done. | loss: 0.0073 | lr: 0.001000
[11.26.22|04:17:44] 	Iter 130000 Done. | loss: 0.0003 | lr: 0.001000
[11.26.22|04:17:56] 	mean_loss: 0.02918794521370404
[11.26.22|04:17:56] Time consumption:
===> loss: 0.02918794521370404
===> f1: [0.93888116 0.95054827 0.96623778 0.9561763  0.95227896 0.95679339
 0.98496354 0.93416878]
===> acc: [0.99350171 0.99537976 0.98880081 0.99198083 0.99535671 0.98775233
 0.99120887 0.99007973]
===> TP: [ 4332.  3854. 13909.  7593.  4021. 11770. 24991.  6109.]
===> TN: [81896. 82537. 71911. 78503. 82368. 73959. 61038. 79822.]
===> FN: [328. 262. 558. 374. 234. 563. 406. 522.]
===> FP: [236. 139. 414. 322. 169. 500. 357. 339.]
===> rec: [0.92961373 0.93634597 0.96142946 0.95305636 0.94500588 0.95435012
 0.98401386 0.92127884]
===> prec: [0.94833625 0.96518908 0.97109544 0.95931775 0.95966587 0.9592502
 0.98591605 0.94742556]
===> average f1: 0.9550060219278453
===> average acc: 0.9917575928657019
[11.26.22|04:18:01] Done.
[11.26.22|04:18:01] Eval epoch: 5
[11.26.22|04:21:08] 	mean_loss: 0.142629477723283
===> loss: 0.142629477723283
===> f1: [0.68199413 0.5602513  0.62623959 0.47277993 0.38113686 0.66393029
 0.94239592 0.58642301]
===> acc: [0.97555545 0.97755233 0.87720345 0.93375872 0.94879269 0.93045354
 0.97105674 0.90630738]
===> TP: [ 1142.   623.  4482.  1294.   687.  2993. 10315.  2894.]
===> TN: [41361. 41967. 33736. 39388. 40650. 37545. 31992. 36592.]
===> FN: [ 693.  498.  637. 1066.  531. 1510.  535. 2008.]
===> FP: [ 372.  480. 4713. 1820. 1700. 1520.  726. 2074.]
===> rec: [0.62234332 0.55575379 0.87556163 0.54830508 0.56403941 0.664668
 0.95069124 0.59037128]
===> prec: [0.75429326 0.56482321 0.48743883 0.41554271 0.28780897 0.66319521
 0.93424509 0.58252818]
===> average f1: 0.6143938768336025
===> average acc: 0.9400850394785163
[11.26.22|04:21:10] Done.
[11.26.22|04:21:10] Training epoch: 6
[11.26.22|04:22:04] 	Iter 131000 Done. | loss: 0.0052 | lr: 0.001000
[11.26.22|04:23:08] 	Iter 132000 Done. | loss: 0.0007 | lr: 0.001000
[11.26.22|04:24:21] 	Iter 133000 Done. | loss: 0.0023 | lr: 0.001000
[11.26.22|04:25:33] 	Iter 134000 Done. | loss: 0.1680 | lr: 0.001000
[11.26.22|04:26:41] 	Iter 135000 Done. | loss: 0.0016 | lr: 0.001000
[11.26.22|04:27:41] 	Iter 136000 Done. | loss: 0.0103 | lr: 0.001000
[11.26.22|04:28:40] 	Iter 137000 Done. | loss: 0.0043 | lr: 0.001000
[11.26.22|04:29:45] 	Iter 138000 Done. | loss: 0.0005 | lr: 0.001000
[11.26.22|04:30:51] 	Iter 139000 Done. | loss: 0.0002 | lr: 0.001000
[11.26.22|04:31:56] 	Iter 140000 Done. | loss: 0.0040 | lr: 0.001000
[11.26.22|04:33:00] 	Iter 141000 Done. | loss: 0.0011 | lr: 0.001000
[11.26.22|04:34:05] 	Iter 142000 Done. | loss: 0.0935 | lr: 0.001000
[11.26.22|04:35:10] 	Iter 143000 Done. | loss: 0.1175 | lr: 0.001000
[11.26.22|04:36:14] 	Iter 144000 Done. | loss: 0.0045 | lr: 0.001000
[11.26.22|04:37:19] 	Iter 145000 Done. | loss: 0.1017 | lr: 0.001000
[11.26.22|04:38:30] 	Iter 146000 Done. | loss: 0.0015 | lr: 0.001000
[11.26.22|04:39:35] 	Iter 147000 Done. | loss: 0.0029 | lr: 0.001000
[11.26.22|04:40:40] 	Iter 148000 Done. | loss: 0.0266 | lr: 0.001000
[11.26.22|04:41:46] 	Iter 149000 Done. | loss: 0.0064 | lr: 0.001000
[11.26.22|04:42:51] 	Iter 150000 Done. | loss: 0.1277 | lr: 0.001000
[11.26.22|04:44:01] 	Iter 151000 Done. | loss: 0.0060 | lr: 0.001000
[11.26.22|04:44:58] 	mean_loss: 0.027697901152193723
[11.26.22|04:44:58] Time consumption:
===> loss: 0.027697901152193723
===> f1: [0.94614751 0.95592169 0.97007769 0.95906897 0.95233528 0.95979482
 0.98477628 0.93635415]
===> acc: [0.99427367 0.9958752  0.99007973 0.99249931 0.99536824 0.98859342
 0.99110517 0.99035625]
===> TP: [ 4366.  3882. 13957.  7627.  4016. 11817. 24970.  6157.]
===> TN: [81929. 82552. 71974. 78514. 82374. 73985. 61050. 79798.]
===> FN: [294. 234. 510. 340. 239. 516. 427. 474.]
===> FP: [203. 124. 351. 311. 163. 474. 345. 363.]
===> rec: [0.93690987 0.94314869 0.96474736 0.95732396 0.94383079 0.95816103
 0.98318699 0.92851757]
===> prec: [0.95557015 0.96904643 0.97546827 0.96082137 0.96099545 0.9614352
 0.98637172 0.94432515]
===> average f1: 0.9580595499748934
===> average acc: 0.992268872707162
[11.26.22|04:45:04] Done.
[11.26.22|04:45:04] Eval epoch: 6
[11.26.22|04:48:09] 	mean_loss: 0.12184237561915173
===> loss: 0.12184237561915173
===> f1: [0.7158715  0.65108821 0.67491808 0.36802365 0.26054846 0.64980809
 0.93059261 0.49838809]
===> acc: [0.98003122 0.98492012 0.90837312 0.9422971  0.95857051 0.92021667
 0.96465296 0.89997246]
===> TP: [ 1096.   613.  4144.   732.   318.  3225. 10324.  2165.]
===> TN: [41602. 42298. 35432. 40322. 41445. 36867. 31704. 37045.]
===> FN: [ 739.  508.  975. 1628.  900. 1278.  526. 2737.]
===> FP: [ 131.  149. 3017.  886.  905. 2198. 1014. 1621.]
===> rec: [0.5972752  0.54683318 0.80953311 0.31016949 0.26108374 0.71618921
 0.95152074 0.44165647]
===> prec: [0.89323553 0.80446194 0.57869013 0.45241038 0.26001635 0.59468929
 0.91056624 0.57184363]
===> average f1: 0.5936548352477974
===> average acc: 0.9448792691883952
[11.26.22|04:48:11] Done.
[11.26.22|04:48:11] Training epoch: 7
[11.26.22|04:48:18] 	Iter 152000 Done. | loss: 0.0007 | lr: 0.001000
[11.26.22|04:49:22] 	Iter 153000 Done. | loss: 0.0028 | lr: 0.001000
[11.26.22|04:50:27] 	Iter 154000 Done. | loss: 0.0042 | lr: 0.001000
[11.26.22|04:51:36] 	Iter 155000 Done. | loss: 0.0115 | lr: 0.001000
[11.26.22|04:52:40] 	Iter 156000 Done. | loss: 0.0056 | lr: 0.001000
[11.26.22|04:53:45] 	Iter 157000 Done. | loss: 0.1341 | lr: 0.001000
[11.26.22|04:54:49] 	Iter 158000 Done. | loss: 0.0016 | lr: 0.001000
[11.26.22|04:55:54] 	Iter 159000 Done. | loss: 0.0402 | lr: 0.001000
[11.26.22|04:56:58] 	Iter 160000 Done. | loss: 0.0023 | lr: 0.001000
[11.26.22|04:58:02] 	Iter 161000 Done. | loss: 0.0460 | lr: 0.001000
[11.26.22|04:59:08] 	Iter 162000 Done. | loss: 0.0727 | lr: 0.001000
[11.26.22|05:00:21] 	Iter 163000 Done. | loss: 0.0244 | lr: 0.001000
[11.26.22|05:01:34] 	Iter 164000 Done. | loss: 0.0285 | lr: 0.001000
[11.26.22|05:02:43] 	Iter 165000 Done. | loss: 0.0006 | lr: 0.001000
[11.26.22|05:03:47] 	Iter 166000 Done. | loss: 0.0321 | lr: 0.001000
[11.26.22|05:04:55] 	Iter 167000 Done. | loss: 0.0194 | lr: 0.001000
[11.26.22|05:06:02] 	Iter 168000 Done. | loss: 0.0337 | lr: 0.001000
[11.26.22|05:07:07] 	Iter 169000 Done. | loss: 0.0346 | lr: 0.001000
[11.26.22|05:08:24] 	Iter 170000 Done. | loss: 0.0004 | lr: 0.001000
[11.26.22|05:09:37] 	Iter 171000 Done. | loss: 0.0224 | lr: 0.001000
[11.26.22|05:10:49] 	Iter 172000 Done. | loss: 0.1192 | lr: 0.001000
[11.26.22|05:12:02] 	Iter 173000 Done. | loss: 0.0007 | lr: 0.001000
[11.26.22|05:12:41] 	mean_loss: 0.02679080010352569
[11.26.22|05:12:41] Time consumption:
===> loss: 0.02679080010352569
===> f1: [0.94780021 0.95117402 0.97172616 0.96068994 0.95640793 0.95911122
 0.98521243 0.94093419]
===> acc: [0.99443497 0.99542585 0.99063278 0.9928104  0.99575998 0.9883745
 0.99135865 0.99105908]
===> TP: [ 4385.  3867. 13971.  7625.  4037. 11834. 24985.  6181.]
===> TN: [81924. 82528. 72008. 78543. 82387. 73949. 61057. 79835.]
===> FN: [275. 249. 496. 342. 218. 499. 412. 450.]
===> FP: [208. 148. 317. 282. 150. 510. 338. 326.]
===> rec: [0.94098712 0.93950437 0.96571508 0.95707293 0.94876616 0.95953945
 0.98377761 0.93213693]
===> prec: [0.95471369 0.96313823 0.97781355 0.9643354  0.96417483 0.95868438
 0.98665245 0.94990011]
===> average f1: 0.9591320135174026
===> average acc: 0.992482025993179
[11.26.22|05:12:46] Done.
[11.26.22|05:12:46] Eval epoch: 7
[11.26.22|05:16:17] 	mean_loss: 0.17262185572028083
===> loss: 0.17262185572028083
===> f1: [0.50215833 0.63885217 0.531973   0.48334442 0.42212371 0.65288373
 0.92027504 0.53312438]
===> acc: [0.93118803 0.98092637 0.81252295 0.93164708 0.96091168 0.92099706
 0.9620134  0.89033235]
===> TP: [1512.  735. 4642. 1393.  622. 3237. 9552. 2728.]
===> TN: [39058. 42002. 30758. 39197. 41243. 36889. 32361. 36062.]
===> FN: [ 323.  386.  477.  967.  596. 1266. 1298. 2174.]
===> FP: [2675.  445. 7691. 2011. 1107. 2176.  357. 2604.]
===> rec: [0.8239782  0.65566459 0.90681774 0.59025424 0.51067323 0.7188541
 0.88036866 0.55650755]
===> prec: [0.36111775 0.62288136 0.37638855 0.40922444 0.35974552 0.5980048
 0.96397215 0.51162791]
===> average f1: 0.5855918471972785
===> average acc: 0.9238173659566654
[11.26.22|05:16:19] Done.
[11.26.22|05:16:19] Training epoch: 8
[11.26.22|05:16:47] 	Iter 174000 Done. | loss: 0.0031 | lr: 0.001000
[11.26.22|05:17:55] 	Iter 175000 Done. | loss: 0.0010 | lr: 0.001000
[11.26.22|05:19:02] 	Iter 176000 Done. | loss: 0.1184 | lr: 0.001000
[11.26.22|05:20:06] 	Iter 177000 Done. | loss: 0.0091 | lr: 0.001000
[11.26.22|05:21:11] 	Iter 178000 Done. | loss: 0.0007 | lr: 0.001000
[11.26.22|05:22:18] 	Iter 179000 Done. | loss: 0.1047 | lr: 0.001000
[11.26.22|05:23:24] 	Iter 180000 Done. | loss: 0.0060 | lr: 0.001000
[11.26.22|05:24:28] 	Iter 181000 Done. | loss: 0.0094 | lr: 0.001000
[11.26.22|05:25:33] 	Iter 182000 Done. | loss: 0.0057 | lr: 0.001000
[11.26.22|05:26:35] 	Iter 183000 Done. | loss: 0.0843 | lr: 0.001000
[11.26.22|05:27:34] 	Iter 184000 Done. | loss: 0.0034 | lr: 0.001000
[11.26.22|05:28:36] 	Iter 185000 Done. | loss: 0.0002 | lr: 0.001000
[11.26.22|05:29:40] 	Iter 186000 Done. | loss: 0.0002 | lr: 0.001000
[11.26.22|05:30:50] 	Iter 187000 Done. | loss: 0.0533 | lr: 0.001000
[11.26.22|05:31:56] 	Iter 188000 Done. | loss: 0.0078 | lr: 0.001000
[11.26.22|05:33:00] 	Iter 189000 Done. | loss: 0.0057 | lr: 0.001000
[11.26.22|05:34:11] 	Iter 190000 Done. | loss: 0.0022 | lr: 0.001000
[11.26.22|05:35:17] 	Iter 191000 Done. | loss: 0.0291 | lr: 0.001000
[11.26.22|05:36:27] 	Iter 192000 Done. | loss: 0.0007 | lr: 0.001000
[11.26.22|05:37:32] 	Iter 193000 Done. | loss: 0.0086 | lr: 0.001000
[11.26.22|05:38:37] 	Iter 194000 Done. | loss: 0.0009 | lr: 0.001000
[11.26.22|05:39:42] 	Iter 195000 Done. | loss: 0.0003 | lr: 0.001000
[11.26.22|05:40:02] 	mean_loss: 0.026152107629266994
[11.26.22|05:40:02] Time consumption:
===> loss: 0.026152107629266994
===> f1: [0.9483553  0.95707735 0.9700061  0.96027649 0.95760961 0.96364842
 0.98553074 0.94206269]
===> acc: [0.99448106 0.99597889 0.99005669 0.99272974 0.99586367 0.98968799
 0.991543   0.99123191]
===> TP: [ 4398.  3891. 13955.  7627.  4055. 11863. 24998.  6187.]
===> TN: [81915. 82552. 71974. 78534. 82378. 74034. 61060. 79844.]
===> FN: [262. 225. 512. 340. 200. 470. 399. 444.]
===> FP: [217. 124. 351. 291. 159. 425. 335. 317.]
===> rec: [0.94377682 0.94533528 0.96460911 0.95732396 0.95299647 0.96189086
 0.98428948 0.93304177]
===> prec: [0.95297941 0.96911582 0.97546484 0.96324829 0.96226863 0.96541341
 0.98677614 0.95126076]
===> average f1: 0.9605708372603345
===> average acc: 0.9926966195041018
[11.26.22|05:40:07] Done.
[11.26.22|05:40:07] Eval epoch: 8
[11.26.22|05:43:14] 	mean_loss: 0.13965367826794514
===> loss: 0.13965367826794514
===> f1: [0.68989024 0.50626821 0.58410356 0.44332554 0.28336936 0.67849074
 0.94294104 0.6692609 ]
===> acc: [0.97915902 0.98101818 0.857556   0.94160852 0.93986412 0.93426368
 0.97206665 0.91418013]
===> TP: [ 1010.   424.  4358.  1013.   518.  3022. 10056.  3783.]
===> TN: [41650. 42317. 33004. 40011. 40430. 37682. 32295. 36046.]
===> FN: [ 825.  697.  761. 1347.  700. 1481.  794. 1119.]
===> FP: [  83.  130. 5445. 1197. 1920. 1383.  423. 2620.]
===> rec: [0.55040872 0.37823372 0.85133815 0.42923729 0.42528736 0.67110815
 0.92682028 0.77172583]
===> prec: [0.92406221 0.76534296 0.44455779 0.45837104 0.21246924 0.68603859
 0.95963355 0.5908168 ]
===> average f1: 0.5997061984537845
===> average acc: 0.9399645381931693
[11.26.22|05:43:16] Done.
[11.26.22|05:43:16] Training epoch: 9
[11.26.22|05:44:07] 	Iter 196000 Done. | loss: 0.1206 | lr: 0.001000
[11.26.22|05:45:19] 	Iter 197000 Done. | loss: 0.0007 | lr: 0.001000
[11.26.22|05:46:27] 	Iter 198000 Done. | loss: 0.0223 | lr: 0.001000
[11.26.22|05:47:33] 	Iter 199000 Done. | loss: 0.0083 | lr: 0.001000
[11.26.22|05:48:40] 	Iter 200000 Done. | loss: 0.0298 | lr: 0.001000
[11.26.22|05:49:47] 	Iter 201000 Done. | loss: 0.0014 | lr: 0.001000
[11.26.22|05:50:52] 	Iter 202000 Done. | loss: 0.0006 | lr: 0.001000
[11.26.22|05:51:58] 	Iter 203000 Done. | loss: 0.0295 | lr: 0.001000
[11.26.22|05:53:02] 	Iter 204000 Done. | loss: 0.0003 | lr: 0.001000
[11.26.22|05:54:07] 	Iter 205000 Done. | loss: 0.0002 | lr: 0.001000
[11.26.22|05:55:11] 	Iter 206000 Done. | loss: 0.0321 | lr: 0.001000
[11.26.22|05:56:16] 	Iter 207000 Done. | loss: 0.0008 | lr: 0.001000
[11.26.22|05:57:19] 	Iter 208000 Done. | loss: 0.1234 | lr: 0.001000
[11.26.22|05:58:24] 	Iter 209000 Done. | loss: 0.0076 | lr: 0.001000
[11.26.22|05:59:29] 	Iter 210000 Done. | loss: 0.0196 | lr: 0.001000
[11.26.22|06:00:34] 	Iter 211000 Done. | loss: 0.0423 | lr: 0.001000
[11.26.22|06:01:39] 	Iter 212000 Done. | loss: 0.1205 | lr: 0.001000
[11.26.22|06:02:43] 	Iter 213000 Done. | loss: 0.0048 | lr: 0.001000
[11.26.22|06:03:47] 	Iter 214000 Done. | loss: 0.0004 | lr: 0.001000
[11.26.22|06:04:52] 	Iter 215000 Done. | loss: 0.0020 | lr: 0.001000
[11.26.22|06:05:57] 	Iter 216000 Done. | loss: 0.0003 | lr: 0.001000
[11.26.22|06:06:59] 	mean_loss: 0.025927188678650678
[11.26.22|06:06:59] Time consumption:
===> loss: 0.025927188678650678
===> f1: [0.94572923 0.95391372 0.97063781 0.96201525 0.95943346 0.96325718
 0.98567014 0.9428958 ]
===> acc: [0.99421606 0.99567933 0.99026408 0.99305236 0.9960365  0.98957277
 0.99162365 0.99135865]
===> TP: [ 4374.  3881. 13967.  7636.  4068. 11863. 25004.  6192.]
===> TN: [81916. 82536. 71980. 78553. 82380. 74024. 61061. 79850.]
===> FN: [286. 235. 500. 331. 187. 470. 393. 439.]
===> FP: [216. 140. 345. 272. 157. 435. 334. 311.]
===> rec: [0.93862661 0.94290573 0.96543858 0.95845362 0.9560517  0.96189086
 0.98452573 0.93379581]
===> prec: [0.95294118 0.96518279 0.97589435 0.96560445 0.96284024 0.96462839
 0.98681822 0.95217592]
===> average f1: 0.9604440744947794
===> average acc: 0.9927254240022121
[11.26.22|06:07:04] Done.
[11.26.22|06:07:04] The model has been saved as ./work_dir/train/disfa/exp9/2/epoch10_model.pt.
[11.26.22|06:07:04] Eval epoch: 9
[11.26.22|06:10:29] 	mean_loss: 0.13039574356180741
===> loss: 0.13039574356180741
===> f1: [0.6664538  0.57265725 0.58311476 0.40969296 0.09474334 0.6696566
 0.94331778 0.59626617]
===> acc: [0.9759686  0.97948035 0.87203911 0.93458502 0.96798109 0.923935
 0.9729159  0.91312431]
===> TP: [1046.  599. 3899.  989.   73. 3359. 9819. 2795.]
===> TN: [41475. 42075. 34094. 39729. 42100. 36895. 32569. 36988.]
===> FN: [ 789.  522. 1220. 1371. 1145. 1144. 1031. 2107.]
===> FP: [ 258.  372. 4355. 1479.  250. 2170.  149. 1678.]
===> rec: [0.57002725 0.53434434 0.7616722  0.4190678  0.05993432 0.74594715
 0.90497696 0.57017544]
===> prec: [0.80214724 0.6168898  0.47237703 0.40072934 0.22600619 0.60752396
 0.98505217 0.62486027]
===> average f1: 0.5669878317955774
===> average acc: 0.942503672420125
[11.26.22|06:10:31] Done.
[11.26.22|06:10:31] Training epoch: 10
[11.26.22|06:10:32] 	Iter 217000 Done. | loss: 0.0024 | lr: 0.001000
[11.26.22|06:11:36] 	Iter 218000 Done. | loss: 0.0003 | lr: 0.001000
[11.26.22|06:12:41] 	Iter 219000 Done. | loss: 0.0385 | lr: 0.001000
[11.26.22|06:13:47] 	Iter 220000 Done. | loss: 0.0037 | lr: 0.001000
[11.26.22|06:14:54] 	Iter 221000 Done. | loss: 0.0023 | lr: 0.001000
[11.26.22|06:16:01] 	Iter 222000 Done. | loss: 0.0004 | lr: 0.001000
[11.26.22|06:17:06] 	Iter 223000 Done. | loss: 0.0014 | lr: 0.001000
[11.26.22|06:18:11] 	Iter 224000 Done. | loss: 0.0004 | lr: 0.001000
[11.26.22|06:19:16] 	Iter 225000 Done. | loss: 0.0024 | lr: 0.001000
[11.26.22|06:20:22] 	Iter 226000 Done. | loss: 0.0024 | lr: 0.001000
[11.26.22|06:21:26] 	Iter 227000 Done. | loss: 0.0019 | lr: 0.001000
[11.26.22|06:22:33] 	Iter 228000 Done. | loss: 0.0011 | lr: 0.001000
[11.26.22|06:23:39] 	Iter 229000 Done. | loss: 0.0006 | lr: 0.001000
[11.26.22|06:24:43] 	Iter 230000 Done. | loss: 0.0002 | lr: 0.001000
[11.26.22|06:25:47] 	Iter 231000 Done. | loss: 0.0098 | lr: 0.001000
[11.26.22|06:26:48] 	Iter 232000 Done. | loss: 0.0045 | lr: 0.001000
[11.26.22|06:27:53] 	Iter 233000 Done. | loss: 0.0003 | lr: 0.001000
[11.26.22|06:28:57] 	Iter 234000 Done. | loss: 0.0003 | lr: 0.001000
[11.26.22|06:30:04] 	Iter 235000 Done. | loss: 0.0527 | lr: 0.001000
[11.26.22|06:31:14] 	Iter 236000 Done. | loss: 0.0442 | lr: 0.001000
[11.26.22|06:32:20] 	Iter 237000 Done. | loss: 0.0033 | lr: 0.001000
[11.26.22|06:33:25] 	Iter 238000 Done. | loss: 0.0167 | lr: 0.001000
[11.26.22|06:34:10] 	mean_loss: 0.025408397066840425
[11.26.22|06:34:10] Time consumption:
===> loss: 0.025408397066840425
===> f1: [0.95088995 0.95779091 0.97185248 0.96189224 0.95727255 0.9621963
 0.98616099 0.94598246]
===> acc: [0.99475758 0.9960365  0.99065582 0.99304083 0.99584063 0.98926168
 0.9919117  0.99181952]
===> TP: [ 4405.  3903. 14001.  7623.  4044. 11861. 25013.  6217.]
===> TN: [81932. 82545. 71980. 78565. 82387. 73999. 61077. 79865.]
===> FN: [255. 213. 466. 344. 211. 472. 384. 414.]
===> FP: [200. 131. 345. 260. 150. 460. 318. 296.]
===> rec: [0.94527897 0.94825073 0.96778876 0.95682189 0.95041128 0.9617287
 0.9848801  0.93756598]
===> prec: [0.95656895 0.96752603 0.97595148 0.96701763 0.96423462 0.96266537
 0.98744621 0.95455243]
===> average f1: 0.9617547358290544
===> average acc: 0.9929155336897411
[11.26.22|06:34:15] Done.
[11.26.22|06:34:15] Eval epoch: 10
[11.26.22|06:37:22] 	mean_loss: 0.1404342913448764
===> loss: 0.1404342913448764
===> f1: [0.67151661 0.64376421 0.56871705 0.43226676 0.3601727  0.69664177
 0.939315   0.52043221]
===> acc: [0.97202075 0.98262486 0.83829875 0.93603103 0.94911403 0.94007069
 0.97094198 0.90841902]
===> TP: [1246.  684. 4645. 1061.  624. 2998. 9798. 2165.]
===> TN: [41103. 42127. 31878. 39720. 40727. 37959. 32504. 37413.]
===> FN: [ 589.  437.  474. 1299.  594. 1505. 1052. 2737.]
===> FP: [ 630.  320. 6571. 1488. 1623. 1106.  214. 1253.]
===> rec: [0.67901907 0.61016949 0.90740379 0.44957627 0.51231527 0.66577837
 0.90304147 0.44165647]
===> prec: [0.6641791  0.6812749  0.41414051 0.41624166 0.2777036  0.73050682
 0.97862565 0.63341135]
===> average f1: 0.6041032893030761
===> average acc: 0.9371901395519647
[11.26.22|06:37:24] Done.
[11.26.22|06:37:24] Training epoch: 11
[11.26.22|06:37:44] 	Iter 239000 Done. | loss: 0.0060 | lr: 0.001000
[11.26.22|06:38:46] 	Iter 240000 Done. | loss: 0.0056 | lr: 0.001000
[11.26.22|06:39:47] 	Iter 241000 Done. | loss: 0.0002 | lr: 0.001000
[11.26.22|06:40:52] 	Iter 242000 Done. | loss: 0.0009 | lr: 0.001000
[11.26.22|06:41:56] 	Iter 243000 Done. | loss: 0.0436 | lr: 0.001000
[11.26.22|06:43:01] 	Iter 244000 Done. | loss: 0.0205 | lr: 0.001000
[11.26.22|06:44:05] 	Iter 245000 Done. | loss: 0.0049 | lr: 0.001000
[11.26.22|06:45:10] 	Iter 246000 Done. | loss: 0.0006 | lr: 0.001000
[11.26.22|06:46:17] 	Iter 247000 Done. | loss: 0.0008 | lr: 0.001000
[11.26.22|06:47:28] 	Iter 248000 Done. | loss: 0.0158 | lr: 0.001000
[11.26.22|06:48:33] 	Iter 249000 Done. | loss: 0.0018 | lr: 0.001000
[11.26.22|06:49:39] 	Iter 250000 Done. | loss: 0.0002 | lr: 0.001000
[11.26.22|06:50:48] 	Iter 251000 Done. | loss: 0.0017 | lr: 0.001000
[11.26.22|06:51:59] 	Iter 252000 Done. | loss: 0.0364 | lr: 0.001000
[11.26.22|06:53:09] 	Iter 253000 Done. | loss: 0.0002 | lr: 0.001000
[11.26.22|06:54:20] 	Iter 254000 Done. | loss: 0.0570 | lr: 0.001000
[11.26.22|06:55:29] 	Iter 255000 Done. | loss: 0.0131 | lr: 0.001000
[11.26.22|06:56:36] 	Iter 256000 Done. | loss: 0.1444 | lr: 0.001000
[11.26.22|06:57:40] 	Iter 257000 Done. | loss: 0.0014 | lr: 0.001000
[11.26.22|06:58:46] 	Iter 258000 Done. | loss: 0.0004 | lr: 0.001000
[11.26.22|06:59:52] 	Iter 259000 Done. | loss: 0.0133 | lr: 0.001000
[11.26.22|07:00:56] 	Iter 260000 Done. | loss: 0.0690 | lr: 0.001000
[11.26.22|07:01:19] 	mean_loss: 0.026264451871444366
[11.26.22|07:01:19] Time consumption:
===> loss: 0.026264451871444366
===> f1: [0.95004275 0.95772867 0.96888097 0.96073562 0.95518455 0.96183156
 0.98595223 0.94051287]
===> acc: [0.99467693 0.9960365  0.98968799 0.99282192 0.99563324 0.98916951
 0.99179648 0.99100147]
===> TP: [ 4393.  3897. 13933.  7622.  4039. 11844. 24987.  6174.]
===> TN: [81937. 82551. 71964. 78547. 82374. 74008. 61093. 79837.]
===> FN: [267. 219. 534. 345. 216. 489. 410. 457.]
===> FP: [195. 125. 361. 278. 163. 451. 302. 324.]
===> rec: [0.94270386 0.946793   0.96308841 0.95669637 0.94923619 0.96035028
 0.98385636 0.93108128]
===> prec: [0.95749782 0.96892093 0.97474465 0.96481013 0.96120895 0.96331842
 0.98805805 0.9501385 ]
===> average f1: 0.9601086531549774
===> average acc: 0.9926030048852429
[11.26.22|07:01:25] Done.
[11.26.22|07:01:25] Eval epoch: 11
[11.26.22|07:04:31] 	mean_loss: 0.13684491650070182
===> loss: 0.13684491650070182
===> f1: [0.68149599 0.61842742 0.63438247 0.47410374 0.34163653 0.66198886
 0.94339215 0.51539428]
===> acc: [0.97830977 0.98317573 0.89446383 0.92285622 0.95329141 0.93144051
 0.97261752 0.89053893]
===> TP: [1011.  594. 3989. 1515.  528. 2925. 9941. 2536.]
===> TN: [41612. 42241. 34981. 38692. 41005. 37656. 32434. 36263.]
===> FN: [ 824.  527. 1130.  845.  690. 1578.  909. 2366.]
===> FP: [ 121.  206. 3468. 2516. 1345. 1409.  284. 2403.]
===> rec: [0.55095368 0.52988403 0.77925376 0.64194915 0.43349754 0.64956696
 0.9162212  0.51733986]
===> prec: [0.89310954 0.7425     0.53493362 0.37583726 0.28190069 0.67489617
 0.97222494 0.51346426]
===> average f1: 0.6088526794217409
===> average acc: 0.9408367379728241
[11.26.22|07:04:33] Done.
[11.26.22|07:04:33] Training epoch: 12
[11.26.22|07:05:10] 	Iter 261000 Done. | loss: 0.0002 | lr: 0.001000
[11.26.22|07:06:13] 	Iter 262000 Done. | loss: 0.0021 | lr: 0.001000
[11.26.22|07:07:17] 	Iter 263000 Done. | loss: 0.0012 | lr: 0.001000
[11.26.22|07:08:22] 	Iter 264000 Done. | loss: 0.0023 | lr: 0.001000
[11.26.22|07:09:28] 	Iter 265000 Done. | loss: 0.0003 | lr: 0.001000
[11.26.22|07:10:37] 	Iter 266000 Done. | loss: 0.0075 | lr: 0.001000
[11.26.22|07:11:41] 	Iter 267000 Done. | loss: 0.0270 | lr: 0.001000
[11.26.22|07:12:47] 	Iter 268000 Done. | loss: 0.0010 | lr: 0.001000
[11.26.22|07:13:52] 	Iter 269000 Done. | loss: 0.0008 | lr: 0.001000
[11.26.22|07:14:56] 	Iter 270000 Done. | loss: 0.0003 | lr: 0.001000
[11.26.22|07:16:00] 	Iter 271000 Done. | loss: 0.0216 | lr: 0.001000
[11.26.22|07:17:05] 	Iter 272000 Done. | loss: 0.0188 | lr: 0.001000
[11.26.22|07:18:09] 	Iter 273000 Done. | loss: 0.0177 | lr: 0.001000
[11.26.22|07:19:13] 	Iter 274000 Done. | loss: 0.0023 | lr: 0.001000
[11.26.22|07:20:19] 	Iter 275000 Done. | loss: 0.0581 | lr: 0.001000
[11.26.22|07:21:23] 	Iter 276000 Done. | loss: 0.0006 | lr: 0.001000
[11.26.22|07:22:27] 	Iter 277000 Done. | loss: 0.0096 | lr: 0.001000
[11.26.22|07:23:31] 	Iter 278000 Done. | loss: 0.1041 | lr: 0.001000
[11.26.22|07:24:38] 	Iter 279000 Done. | loss: 0.0002 | lr: 0.001000
[11.26.22|07:25:49] 	Iter 280000 Done. | loss: 0.0010 | lr: 0.001000
[11.26.22|07:26:57] 	Iter 281000 Done. | loss: 0.0024 | lr: 0.001000
[11.26.22|07:28:02] 	Iter 282000 Done. | loss: 0.0307 | lr: 0.001000
[11.26.22|07:28:07] 	mean_loss: 0.025074524970489363
[11.26.22|07:28:07] Time consumption:
===> loss: 0.025074524970489363
===> f1: [0.94890303 0.95596348 0.97178111 0.96288779 0.95974376 0.96365946
 0.98642074 0.94566406]
===> acc: [0.99455019 0.99588672 0.99063278 0.99321366 0.99608259 0.98967647
 0.99206148 0.99176191]
===> TP: [ 4392.  3875. 13999.  7641.  4053. 11880. 25026.  6222.]
===> TN: [81927. 82560. 71980. 78562. 82399. 74016. 61077. 79855.]
===> FN: [268. 241. 468. 326. 202. 453. 371. 409.]
===> FP: [205. 116. 345. 263. 138. 443. 318. 306.]
===> rec: [0.94248927 0.94144801 0.96765051 0.95908121 0.95252644 0.96326928
 0.98539198 0.93832001]
===> prec: [0.9554057  0.9709346  0.97594813 0.96672571 0.9670723  0.96405096
 0.98745265 0.953125  ]
===> average f1: 0.9618779290015333
===> average acc: 0.9929832242603005
[11.26.22|07:28:12] Done.
[11.26.22|07:28:12] Eval epoch: 12
[11.26.22|07:31:17] 	mean_loss: 0.1079931215636777
===> loss: 0.1079931215636777
===> f1: [0.75316406 0.58333283 0.75471968 0.49165152 0.35674536 0.76524453
 0.94464929 0.49864336]
===> acc: [0.98030665 0.97980169 0.93350624 0.94688762 0.97078131 0.95590801
 0.97284704 0.88968968]
===> TP: [ 1309.   616.  4457.  1119.   353.  3131. 10095.  2390.]
===> TN: [41401. 42072. 36214. 40135. 41942. 38516. 32290. 36372.]
===> FN: [ 526.  505.  662. 1241.  865. 1372.  755. 2512.]
===> FP: [ 332.  375. 2235. 1073.  408.  549.  428. 2294.]
===> rec: [0.7133515  0.54950937 0.87067787 0.47415254 0.28981938 0.69531423
 0.93041475 0.4875561 ]
===> prec: [0.79768434 0.62159435 0.66601913 0.5104927  0.46386334 0.85081522
 0.95932719 0.51024765]
===> average f1: 0.643518828795769
===> average acc: 0.953716030113845
[11.26.22|07:31:20] Done.
[11.26.22|07:31:20] Training epoch: 13
[11.26.22|07:32:20] 	Iter 283000 Done. | loss: 0.0079 | lr: 0.001000
[11.26.22|07:33:24] 	Iter 284000 Done. | loss: 0.0024 | lr: 0.001000
[11.26.22|07:34:36] 	Iter 285000 Done. | loss: 0.0095 | lr: 0.001000
[11.26.22|07:35:46] 	Iter 286000 Done. | loss: 0.0047 | lr: 0.001000
[11.26.22|07:36:50] 	Iter 287000 Done. | loss: 0.0005 | lr: 0.001000
[11.26.22|07:37:54] 	Iter 288000 Done. | loss: 0.0007 | lr: 0.001000
[11.26.22|07:38:58] 	Iter 289000 Done. | loss: 0.0153 | lr: 0.001000
[11.26.22|07:40:03] 	Iter 290000 Done. | loss: 0.0187 | lr: 0.001000
[11.26.22|07:41:09] 	Iter 291000 Done. | loss: 0.0308 | lr: 0.001000
[11.26.22|07:42:16] 	Iter 292000 Done. | loss: 0.0211 | lr: 0.001000
[11.26.22|07:43:26] 	Iter 293000 Done. | loss: 0.0047 | lr: 0.001000
[11.26.22|07:44:31] 	Iter 294000 Done. | loss: 0.0399 | lr: 0.001000
[11.26.22|07:45:30] 	Iter 295000 Done. | loss: 0.0024 | lr: 0.001000
[11.26.22|07:46:36] 	Iter 296000 Done. | loss: 0.0024 | lr: 0.001000
[11.26.22|07:47:41] 	Iter 297000 Done. | loss: 0.0008 | lr: 0.001000
[11.26.22|07:48:47] 	Iter 298000 Done. | loss: 0.0003 | lr: 0.001000
[11.26.22|07:49:52] 	Iter 299000 Done. | loss: 0.0104 | lr: 0.001000
[11.26.22|07:51:03] 	Iter 300000 Done. | loss: 0.0102 | lr: 0.001000
[11.26.22|07:52:09] 	Iter 301000 Done. | loss: 0.0030 | lr: 0.001000
[11.26.22|07:53:13] 	Iter 302000 Done. | loss: 0.0102 | lr: 0.001000
[11.26.22|07:54:17] 	Iter 303000 Done. | loss: 0.0340 | lr: 0.001000
[11.26.22|07:55:11] 	mean_loss: 0.025861769220182223
[11.26.22|07:55:11] Time consumption:
===> loss: 0.025861769220182223
===> f1: [0.9460737  0.95382666 0.97139236 0.966461   0.95129705 0.96289028
 0.98596939 0.94444817]
===> acc: [0.9942391  0.99569085 0.99050604 0.99384736 0.99526454 0.98946908
 0.99179648 0.99157756]
===> TP: [ 4386.  3863. 13990.  7694.  4014. 11858. 25018.  6214.]
===> TN: [81906. 82555. 71978. 78564. 82367. 74020. 61062. 79847.]
===> FN: [274. 253. 477. 273. 241. 475. 379. 417.]
===> FP: [226. 121. 347. 261. 170. 439. 333. 314.]
===> rec: [0.94120172 0.93853256 0.96702841 0.96573365 0.94336075 0.96148545
 0.98507698 0.93711356]
===> prec: [0.9509974  0.96962851 0.97579689 0.96719045 0.95936902 0.96430024
 0.98686442 0.95189951]
===> average f1: 0.9602948264282656
===> average acc: 0.9927988754723938
[11.26.22|07:55:16] Done.
[11.26.22|07:55:16] Eval epoch: 13
[11.26.22|07:58:22] 	mean_loss: 0.13602888872614186
===> loss: 0.13602888872614186
===> f1: [0.74984547 0.61105577 0.5880409  0.4435375  0.45204942 0.66894771
 0.93182293 0.42689075]
===> acc: [0.98136247 0.98191333 0.85087679 0.94050679 0.96472181 0.93339148
 0.96614488 0.90157914]
===> TP: [ 1217.   619.  4637.  1033.   634.  2932. 10080.  1597.]
===> TN: [41539. 42161. 32434. 39943. 41397. 37734. 32013. 37683.]
===> FN: [ 618.  502.  482. 1327.  584. 1571.  770. 3305.]
===> FP: [ 194.  286. 6015. 1265.  953. 1331.  705.  983.]
===> rec: [0.66321526 0.55218555 0.90584098 0.43771186 0.52052545 0.65112147
 0.92903226 0.32578539]
===> prec: [0.86250886 0.6839779  0.43531731 0.44952132 0.3994959  0.68777856
 0.93463143 0.61899225]
===> average f1: 0.6090238081656263
===> average acc: 0.9400620868527361
[11.26.22|07:58:24] Done.
[11.26.22|07:58:24] Training epoch: 14
[11.26.22|07:58:38] 	Iter 304000 Done. | loss: 0.1158 | lr: 0.001000
[11.26.22|07:59:42] 	Iter 305000 Done. | loss: 0.0006 | lr: 0.001000
[11.26.22|08:00:47] 	Iter 306000 Done. | loss: 0.0005 | lr: 0.001000
[11.26.22|08:01:51] 	Iter 307000 Done. | loss: 0.0609 | lr: 0.001000
[11.26.22|08:03:05] 	Iter 308000 Done. | loss: 0.0069 | lr: 0.001000
[11.26.22|08:04:11] 	Iter 309000 Done. | loss: 0.0238 | lr: 0.001000
[11.26.22|08:05:20] 	Iter 310000 Done. | loss: 0.0544 | lr: 0.001000
[11.26.22|08:06:26] 	Iter 311000 Done. | loss: 0.0115 | lr: 0.001000
[11.26.22|08:07:31] 	Iter 312000 Done. | loss: 0.0116 | lr: 0.001000
[11.26.22|08:08:36] 	Iter 313000 Done. | loss: 0.1158 | lr: 0.001000
[11.26.22|08:09:40] 	Iter 314000 Done. | loss: 0.0118 | lr: 0.001000
[11.26.22|08:10:45] 	Iter 315000 Done. | loss: 0.0114 | lr: 0.001000
[11.26.22|08:11:49] 	Iter 316000 Done. | loss: 0.0006 | lr: 0.001000
[11.26.22|08:12:54] 	Iter 317000 Done. | loss: 0.0178 | lr: 0.001000
[11.26.22|08:14:01] 	Iter 318000 Done. | loss: 0.0004 | lr: 0.001000
[11.26.22|08:15:05] 	Iter 319000 Done. | loss: 0.0108 | lr: 0.001000
[11.26.22|08:16:09] 	Iter 320000 Done. | loss: 0.0139 | lr: 0.001000
[11.26.22|08:17:12] 	Iter 321000 Done. | loss: 0.0098 | lr: 0.001000
[11.26.22|08:18:17] 	Iter 322000 Done. | loss: 0.0002 | lr: 0.001000
[11.26.22|08:19:21] 	Iter 323000 Done. | loss: 0.0057 | lr: 0.001000
[11.26.22|08:20:26] 	Iter 324000 Done. | loss: 0.0959 | lr: 0.001000
[11.26.22|08:21:30] 	Iter 325000 Done. | loss: 0.0029 | lr: 0.001000
[11.26.22|08:22:01] 	mean_loss: 0.02547855722168155
[11.26.22|08:22:01] Time consumption:
===> loss: 0.02547855722168155
===> f1: [0.95170282 0.95625411 0.97038659 0.96154522 0.95968741 0.96222921
 0.98570787 0.94566987]
===> acc: [0.99483823 0.99589824 0.99017191 0.99296018 0.99607107 0.9892732
 0.9916467  0.99177344]
===> TP: [ 4414.  3891. 13976.  7639.  4059. 11859. 25002.  6214.]
===> TN: [81930. 82545. 71963. 78542. 82392. 74002. 61065. 79864.]
===> FN: [246. 225. 491. 328. 196. 474. 395. 417.]
===> FP: [202. 131. 362. 283. 145. 457. 330. 297.]
===> rec: [0.9472103  0.94533528 0.96606069 0.95883017 0.95393655 0.96156653
 0.98444698 0.93711356]
===> prec: [0.95623917 0.96742914 0.97475241 0.9642767  0.96550904 0.9628938
 0.986973   0.95438489]
===> average f1: 0.9616478862765071
===> average acc: 0.9928291201954098
[11.26.22|08:22:07] Done.
[11.26.22|08:22:07] The model has been saved as ./work_dir/train/disfa/exp9/2/epoch15_model.pt.
[11.26.22|08:22:07] Eval epoch: 14
[11.26.22|08:25:14] 	mean_loss: 0.13313211490248322
===> loss: 0.13313211490248322
===> f1: [0.6660233  0.59225692 0.65725455 0.53975931 0.33479648 0.6599087
 0.92734012 0.5027347 ]
===> acc: [0.97615222 0.98138542 0.91585567 0.9305224  0.94436284 0.92606959
 0.96293151 0.91445556]
===> TP: [ 1036.   589.  3515.  1775.   610.  3125. 10306.  1884.]
===> TN: [41493. 42168. 36387. 38766. 40534. 37222. 31647. 37957.]
===> FN: [ 799.  532. 1604.  585.  608. 1378.  544. 3018.]
===> FP: [ 240.  279. 2062. 2442. 1816. 1843. 1071.  709.]
===> rec: [0.56457766 0.52542373 0.68665755 0.75211864 0.50082102 0.69398179
 0.94986175 0.38433293]
===> prec: [0.81191223 0.67857143 0.63026717 0.42091534 0.2514427  0.62902576
 0.90586271 0.72657154]
===> average f1: 0.6100092611650619
===> average acc: 0.9439669023136247
[11.26.22|08:25:16] Done.
